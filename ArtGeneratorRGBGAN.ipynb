{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/The3seus/ArtGeneratorRGB/blob/main/ArtGeneratorRGBGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVnF24NFcuQ6"
      },
      "source": [
        "## **Mount Google Drive to store files & data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzVT_cB7cZFp",
        "outputId": "c0f78eeb-2069-485b-d7a7-751b0916596e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G0W_asugimDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJp-D51g0IDd"
      },
      "source": [
        "## **1) Importing Python Packages for GAN**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k5mFBuzzl2a"
      },
      "source": [
        "# from keras.datasets import cifar10, mnist\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D, Dense, Conv2DTranspose\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.optimizers import Adam \n",
        "import numpy as np\n",
        "!mkdir generated_images resized_images"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoRqPt1DwtD_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "523627af-7a41-47af-fa6e-a7651441b990"
      },
      "source": [
        "#!mkdir finalart\n",
        "!tar -xvf digitalcyber.tar.gz -C /content/drive/MyDrive/ColabNotebooks/Datasets/\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "digitalcyber/\n",
            "digitalcyber/images240.jpg\n",
            "digitalcyber/images307.jpg\n",
            "digitalcyber/images315.jpg\n",
            "digitalcyber/images145.jpg\n",
            "digitalcyber/images127.jpg\n",
            "digitalcyber/image19.jpeg\n",
            "digitalcyber/images15.jpg\n",
            "digitalcyber/images360.jpg\n",
            "digitalcyber/images558.jpg\n",
            "digitalcyber/images533.jpg\n",
            "digitalcyber/images262.jpg\n",
            "digitalcyber/cyberpunk-neon-girl-digital-art-82.jpg\n",
            "digitalcyber/images517.jpg\n",
            "digitalcyber/4-8.jpg\n",
            "digitalcyber/images135.jpg\n",
            "digitalcyber/images531.jpg\n",
            "digitalcyber/images81.jpg\n",
            "digitalcyber/images527.jpg\n",
            "digitalcyber/images30.jpg\n",
            "digitalcyber/1111-4.jpg\n",
            "digitalcyber/images416.jpg\n",
            "digitalcyber/images356.jpg\n",
            "digitalcyber/images455.jpg\n",
            "digitalcyber/images496.jpg\n",
            "digitalcyber/images88.jpg\n",
            "digitalcyber/images323.jpg\n",
            "digitalcyber/0aop33lsvad9ckrnalurxkys.png\n",
            "digitalcyber/images54.jpg\n",
            "digitalcyber/images138.jpg\n",
            "digitalcyber/images335.jpg\n",
            "digitalcyber/cyberpunk-girl-digital-art-lw.jpg\n",
            "digitalcyber/images514.jpg\n",
            "digitalcyber/images504.jpg\n",
            "digitalcyber/images544.jpg\n",
            "digitalcyber/images620.jpg\n",
            "digitalcyber/images312.jpg\n",
            "digitalcyber/images182.jpg\n",
            "digitalcyber/images468.jpg\n",
            "digitalcyber/images2.jpg\n",
            "digitalcyber/images355.jpg\n",
            "digitalcyber/image5.jpeg\n",
            "digitalcyber/images373.jpg\n",
            "digitalcyber/images204.jpg\n",
            "digitalcyber/images411.jpg\n",
            "digitalcyber/images565.jpg\n",
            "digitalcyber/images471.jpg\n",
            "digitalcyber/images277.jpg\n",
            "digitalcyber/images109.jpg\n",
            "digitalcyber/images501.jpg\n",
            "digitalcyber/images534.jpg\n",
            "digitalcyber/images434.jpg\n",
            "digitalcyber/images24.jpg\n",
            "digitalcyber/images196.jpg\n",
            "digitalcyber/images401.jpg\n",
            "digitalcyber/images418.jpg\n",
            "digitalcyber/images566.jpg\n",
            "digitalcyber/images511.jpg\n",
            "digitalcyber/images598.jpg\n",
            "digitalcyber/images263.jpg\n",
            "digitalcyber/images293.jpg\n",
            "digitalcyber/images425.jpg\n",
            "digitalcyber/images543.jpg\n",
            "digitalcyber/images17.jpg\n",
            "digitalcyber/images585.jpg\n",
            "digitalcyber/images394.jpg\n",
            "digitalcyber/images503.jpg\n",
            "digitalcyber/images48.jpg\n",
            "digitalcyber/images396.jpg\n",
            "digitalcyber/45b5597d4a39501e95ebe49b7a2cf19c.jpg\n",
            "digitalcyber/images155.jpg\n",
            "digitalcyber/images72.jpg\n",
            "digitalcyber/images226.jpg\n",
            "digitalcyber/images590.jpg\n",
            "digitalcyber/images541.jpg\n",
            "digitalcyber/images53.jpg\n",
            "digitalcyber/images261.jpg\n",
            "digitalcyber/images3.jpg\n",
            "digitalcyber/images184.jpg\n",
            "digitalcyber/images192.jpg\n",
            "digitalcyber/images610.jpg\n",
            "digitalcyber/images170.jpg\n",
            "digitalcyber/images386.jpg\n",
            "digitalcyber/images84.jpg\n",
            "digitalcyber/images493.jpg\n",
            "digitalcyber/images423.jpg\n",
            "digitalcyber/images621.jpg\n",
            "digitalcyber/images497.jpg\n",
            "digitalcyber/images578.jpg\n",
            "digitalcyber/images609.jpg\n",
            "digitalcyber/images549.jpg\n",
            "digitalcyber/images152.jpg\n",
            "digitalcyber/images165.jpg\n",
            "digitalcyber/images557.jpg\n",
            "digitalcyber/images580.jpg\n",
            "digitalcyber/images171.jpg\n",
            "digitalcyber/images392.jpg\n",
            "digitalcyber/images301.jpg\n",
            "digitalcyber/images611.jpg\n",
            "digitalcyber/images12.jpg\n",
            "digitalcyber/images510.jpg\n",
            "digitalcyber/images607.jpg\n",
            "digitalcyber/images365.jpg\n",
            "digitalcyber/images29.jpg\n",
            "digitalcyber/cyberpunk-scifi-gravity-sketch-digital-art-zz.jpg\n",
            "digitalcyber/images412.jpg\n",
            "digitalcyber/images325.jpg\n",
            "digitalcyber/images160.jpg\n",
            "digitalcyber/images274.jpg\n",
            "digitalcyber/images535.jpg\n",
            "digitalcyber/images354.jpg\n",
            "digitalcyber/images490.jpg\n",
            "digitalcyber/images333.jpg\n",
            "digitalcyber/images628.jpg\n",
            "digitalcyber/images130.jpg\n",
            "digitalcyber/colorful-cyberpunk-metaverse-city-background-concept-art-digital-painting_743201-957.jpg\n",
            "digitalcyber/images431.jpg\n",
            "digitalcyber/images513.jpg\n",
            "digitalcyber/images9.jpg\n",
            "digitalcyber/images71.jpg\n",
            "digitalcyber/bc6366d404f9d6fb4fc4a1652e4753e8-1-819x1024.jpg\n",
            "digitalcyber/wlop-civilization-girl-brunette-car-motorcycle-train-carriag.jpg\n",
            "digitalcyber/images7.jpg\n",
            "digitalcyber/images96.jpg\n",
            "digitalcyber/images439.jpg\n",
            "digitalcyber/images68.jpg\n",
            "digitalcyber/images594.jpg\n",
            "digitalcyber/images599.jpg\n",
            "digitalcyber/images191.jpg\n",
            "digitalcyber/images119.jpg\n",
            "digitalcyber/images375.jpg\n",
            "digitalcyber/images546.jpg\n",
            "digitalcyber/images447.jpg\n",
            "digitalcyber/images400.jpg\n",
            "digitalcyber/images164.jpg\n",
            "digitalcyber/images265.jpg\n",
            "digitalcyber/images593.jpg\n",
            "digitalcyber/images362.jpg\n",
            "digitalcyber/images473.jpg\n",
            "digitalcyber/images589.jpg\n",
            "digitalcyber/images27.jpg\n",
            "digitalcyber/images488.jpg\n",
            "digitalcyber/images154.jpg\n",
            "digitalcyber/images34.jpg\n",
            "digitalcyber/image31.jpeg\n",
            "digitalcyber/uristic-city-futuristic-artwork-fan-art-digital-art-digital-painting-1930713.jpg\n",
            "digitalcyber/images102.jpg\n",
            "digitalcyber/images326.jpg\n",
            "digitalcyber/images231.jpg\n",
            "digitalcyber/images52.jpg\n",
            "digitalcyber/images603.jpg\n",
            "digitalcyber/images66.jpg\n",
            "digitalcyber/images515.jpg\n",
            "digitalcyber/images62.jpg\n",
            "digitalcyber/images498.jpg\n",
            "digitalcyber/images369.jpg\n",
            "digitalcyber/cyborg-armor-futuristic-fantasy-art-artwork-digital-art-cybe.jpg\n",
            "digitalcyber/f6122f145779407.62a72f491b8cd.jpg\n",
            "digitalcyber/images539.jpg\n",
            "digitalcyber/images341.jpg\n",
            "digitalcyber/images110.jpg\n",
            "digitalcyber/images50.jpg\n",
            "digitalcyber/images289.jpg\n",
            "digitalcyber/images137.jpg\n",
            "digitalcyber/images5.jpg\n",
            "digitalcyber/image13.jpeg\n",
            "digitalcyber/images220.jpg\n",
            "digitalcyber/images436.jpg\n",
            "digitalcyber/images39.jpg\n",
            "digitalcyber/images163.jpg\n",
            "digitalcyber/images150.jpg\n",
            "digitalcyber/images168.jpg\n",
            "digitalcyber/images460.jpg\n",
            "digitalcyber/images486.jpg\n",
            "digitalcyber/digital-art-artwork-cyber-cyberpunk-neon-hd-wallpaper-preview.jpg\n",
            "digitalcyber/the-digital-art-of-soufiane-idrassi-01.jpg\n",
            "digitalcyber/images232.jpg\n",
            "digitalcyber/83942-cyberpunk-city-artist-artwork-digital-art-hd-deviantart.jpg\n",
            "digitalcyber/images174.jpg\n",
            "digitalcyber/images304.jpg\n",
            "digitalcyber/images188.jpg\n",
            "digitalcyber/images406.jpg\n",
            "digitalcyber/images627.jpg\n",
            "digitalcyber/digital-art-futuristic-video-game-art-cyberpunk-cyberpunk-2077-original-imafzhdqk7syyksm.jpeg\n",
            "digitalcyber/images249.jpg\n",
            "digitalcyber/images481.jpg\n",
            "digitalcyber/86586af111504884d1bc689738f69318.png\n",
            "digitalcyber/images28.jpg\n",
            "digitalcyber/images90.jpg\n",
            "digitalcyber/images461.jpg\n",
            "digitalcyber/images139.jpg\n",
            "digitalcyber/image15.jpeg\n",
            "digitalcyber/images555.jpg\n",
            "digitalcyber/1-8.jpg\n",
            "digitalcyber/images298.jpg\n",
            "digitalcyber/images494.jpg\n",
            "digitalcyber/images361.jpg\n",
            "digitalcyber/images105.jpg\n",
            "digitalcyber/images398.jpg\n",
            "digitalcyber/images121.jpg\n",
            "digitalcyber/images407.jpg\n",
            "digitalcyber/images545.jpg\n",
            "digitalcyber/images4.jpg\n",
            "digitalcyber/cyberpunk-sci-fi-digital-art-uhdpaper.com-4K-136.jpg\n",
            "digitalcyber/images302.jpg\n",
            "digitalcyber/images214.jpg\n",
            "digitalcyber/colorful-futuristic-cyberpunk-metaverse-city-background-concept-art-digital-painting_743201-1053.jpg\n",
            "digitalcyber/17-cyberpunk-2077-trang-vo.jpg\n",
            "digitalcyber/images283.jpg\n",
            "digitalcyber/images340.jpg\n",
            "digitalcyber/images367.jpg\n",
            "digitalcyber/images523.jpg\n",
            "digitalcyber/images126.jpg\n",
            "digitalcyber/images368.jpg\n",
            "digitalcyber/images252.jpg\n",
            "digitalcyber/images306.jpg\n",
            "digitalcyber/images445.jpg\n",
            "digitalcyber/images358.jpg\n",
            "digitalcyber/images573.jpg\n",
            "digitalcyber/images584.jpg\n",
            "digitalcyber/images505.jpg\n",
            "digitalcyber/images13.jpg\n",
            "digitalcyber/images404.jpg\n",
            "digitalcyber/images521.jpg\n",
            "digitalcyber/images614.jpg\n",
            "digitalcyber/images617.jpg\n",
            "digitalcyber/images65.jpg\n",
            "digitalcyber/468b5bc544590310858454ce3757b67e.jpg\n",
            "digitalcyber/The-Art-Of-Cyberpunk-2077-11.jpg\n",
            "digitalcyber/images118.jpg\n",
            "digitalcyber/image14.jpeg\n",
            "digitalcyber/images552.jpg\n",
            "digitalcyber/images183.jpg\n",
            "digitalcyber/images133.jpg\n",
            "digitalcyber/image7.jpeg\n",
            "digitalcyber/images98.jpg\n",
            "digitalcyber/1014-980x1225.jpg\n",
            "digitalcyber/images561.jpg\n",
            "digitalcyber/images287.jpg\n",
            "digitalcyber/images487.jpg\n",
            "digitalcyber/images101.jpg\n",
            "digitalcyber/images230.jpg\n",
            "digitalcyber/images337.jpg\n",
            "digitalcyber/image28.jpeg\n",
            "digitalcyber/images327.jpg\n",
            "digitalcyber/images569.jpg\n",
            "digitalcyber/images212.jpg\n",
            "digitalcyber/image23.jpeg\n",
            "digitalcyber/images336.jpg\n",
            "digitalcyber/images73.jpg\n",
            "digitalcyber/tanding-in-the-cyberpunk-city-digital-art-style-illustration-painting-P7GF9H.jpg\n",
            "digitalcyber/images61.jpg\n",
            "digitalcyber/images35.jpg\n",
            "digitalcyber/images424.jpg\n",
            "digitalcyber/images120.jpg\n",
            "digitalcyber/images33.jpg\n",
            "digitalcyber/images43.jpg\n",
            "digitalcyber/image6.jpeg\n",
            "digitalcyber/images346.jpg\n",
            "digitalcyber/images450.jpg\n",
            "digitalcyber/images382.jpg\n",
            "digitalcyber/images246.jpg\n",
            "digitalcyber/images32.jpg\n",
            "digitalcyber/images23.jpg\n",
            "digitalcyber/25a1c5145779407.62a72f491bd91.jpg\n",
            "digitalcyber/image12.jpeg\n",
            "digitalcyber/images241.jpg\n",
            "digitalcyber/images577.jpg\n",
            "digitalcyber/images568.jpg\n",
            "digitalcyber/images80.jpg\n",
            "digitalcyber/images519.jpg\n",
            "digitalcyber/images330.jpg\n",
            "digitalcyber/images499.jpg\n",
            "digitalcyber/images605.jpg\n",
            "digitalcyber/image11.jpeg\n",
            "digitalcyber/images147.jpg\n",
            "digitalcyber/images270.jpg\n",
            "digitalcyber/city-background-concept-art-digital-painting-fantasy-illustration_743201-422.jpg\n",
            "digitalcyber/images63.jpg\n",
            "digitalcyber/image21.jpeg\n",
            "digitalcyber/cyberpunk-vincent-holt.jpg\n",
            "digitalcyber/ights-neon-neon-glow-neon-lights-stores-cityscape-Sergii-Golotovskiy-1784379.jpg\n",
            "digitalcyber/girl-cyberpunk-digital-art.jpg\n",
            "digitalcyber/images106.jpg\n",
            "digitalcyber/images113.jpg\n",
            "digitalcyber/images6.jpg\n",
            "digitalcyber/images108.jpg\n",
            "digitalcyber/images185.jpg\n",
            "digitalcyber/123984-cyberpunk-circle-women-digital-art-digital-artwork-lines-Natalia-Bielawska.jpg\n",
            "digitalcyber/images190.jpg\n",
            "digitalcyber/images311.jpg\n",
            "digitalcyber/images211.jpg\n",
            "digitalcyber/images587.jpg\n",
            "digitalcyber/images579.jpg\n",
            "digitalcyber/images454.jpg\n",
            "digitalcyber/images381.jpg\n",
            "digitalcyber/image32.jpeg\n",
            "digitalcyber/images595.jpg\n",
            "digitalcyber/image20.jpeg\n",
            "digitalcyber/Cyber-Punk-Digital-art-NFT.jpg\n",
            "digitalcyber/images506.jpg\n",
            "digitalcyber/images199.jpg\n",
            "digitalcyber/images243.jpg\n",
            "digitalcyber/images441.jpg\n",
            "digitalcyber/images296.jpg\n",
            "digitalcyber/images563.jpg\n",
            "digitalcyber/images266.jpg\n",
            "digitalcyber/images229.jpg\n",
            "digitalcyber/images222.jpg\n",
            "digitalcyber/images339.jpg\n",
            "digitalcyber/images158.jpg\n",
            "digitalcyber/images205.jpg\n",
            "digitalcyber/images129.jpg\n",
            "digitalcyber/images107.jpg\n",
            "digitalcyber/images459.jpg\n",
            "digitalcyber/images516.jpg\n",
            "digitalcyber/images532.jpg\n",
            "digitalcyber/images426.jpg\n",
            "digitalcyber/HD-wallpaper-cyberpunk-digital-girl-cyberpunk-artist-artwork-digital-art.jpg\n",
            "digitalcyber/images195.jpg\n",
            "digitalcyber/images203.jpg\n",
            "digitalcyber/images626.jpg\n",
            "digitalcyber/images20.jpg\n",
            "digitalcyber/images116.jpg\n",
            "digitalcyber/images444.jpg\n",
            "digitalcyber/images22.jpg\n",
            "digitalcyber/images571.jpg\n",
            "digitalcyber/images602.jpg\n",
            "digitalcyber/images548.jpg\n",
            "digitalcyber/2881005.jpg\n",
            "digitalcyber/images281.jpg\n",
            "digitalcyber/images443.jpg\n",
            "digitalcyber/images615.jpg\n",
            "digitalcyber/images148.jpg\n",
            "digitalcyber/images85.jpg\n",
            "digitalcyber/images219.jpg\n",
            "digitalcyber/images89.jpg\n",
            "digitalcyber/images509.jpg\n",
            "digitalcyber/images463.jpg\n",
            "digitalcyber/images55.jpg\n",
            "digitalcyber/images216.jpg\n",
            "digitalcyber/images349.jpg\n",
            "digitalcyber/images125.jpg\n",
            "digitalcyber/alexander-gudimov-cyberpunk.jpg\n",
            "digitalcyber/images77.jpg\n",
            "digitalcyber/images228.jpg\n",
            "digitalcyber/images606.jpg\n",
            "digitalcyber/images538.jpg\n",
            "digitalcyber/images294.jpg\n",
            "digitalcyber/images419.jpg\n",
            "digitalcyber/image8.jpeg\n",
            "digitalcyber/images338.jpg\n",
            "digitalcyber/586117-cyberpunk-artist.jpg\n",
            "digitalcyber/images376.jpg\n",
            "digitalcyber/images78.jpg\n",
            "digitalcyber/rk-video-game-art-video-game-girls-game-art-video-game-characters-artstation.jpg\n",
            "digitalcyber/images619.jpg\n",
            "digitalcyber/images178.jpg\n",
            "digitalcyber/images26.jpg\n",
            "digitalcyber/images271.jpg\n",
            "digitalcyber/image17.jpeg\n",
            "digitalcyber/images14.jpg\n",
            "digitalcyber/images19.jpg\n",
            "digitalcyber/images608.jpg\n",
            "digitalcyber/images452.jpg\n",
            "digitalcyber/images421.jpg\n",
            "digitalcyber/images331.jpg\n",
            "digitalcyber/images380.jpg\n",
            "digitalcyber/images562.jpg\n",
            "digitalcyber/images38.jpg\n",
            "digitalcyber/images251.jpg\n",
            "digitalcyber/images353.jpg\n",
            "digitalcyber/images582.jpg\n",
            "digitalcyber/images344.jpg\n",
            "digitalcyber/images470.jpg\n",
            "digitalcyber/images95.jpg\n",
            "digitalcyber/images437.jpg\n",
            "digitalcyber/images379.jpg\n",
            "digitalcyber/images484.jpg\n",
            "digitalcyber/images290.jpg\n",
            "digitalcyber/images374.jpg\n",
            "digitalcyber/images292.jpg\n",
            "digitalcyber/images41.jpg\n",
            "digitalcyber/images202.jpg\n",
            "digitalcyber/images370.jpg\n",
            "digitalcyber/images103.jpg\n",
            "digitalcyber/images59.jpg\n",
            "digitalcyber/images144.jpg\n",
            "digitalcyber/images31.jpg\n",
            "digitalcyber/455077-Klayton-Scandroid-neon-cyberpunk-cityscape-digital_art.jpg\n",
            "digitalcyber/image4.jpeg\n",
            "digitalcyber/images272.jpg\n",
            "digitalcyber/images537.jpg\n",
            "digitalcyber/images40.jpg\n",
            "digitalcyber/girl-with-a-futuristic-steel-earring-rubios-workshop.jpg\n",
            "digitalcyber/images257.jpg\n",
            "digitalcyber/images70.jpg\n",
            "digitalcyber/images111.jpg\n",
            "digitalcyber/images74.jpg\n",
            "digitalcyber/images206.jpg\n",
            "digitalcyber/images193.jpg\n",
            "digitalcyber/images520.jpg\n",
            "digitalcyber/HD-wallpaper-cyberpunk-scifi-girl-cyberpunk-scifi-artist-artwork-digital-art.jpg\n",
            "digitalcyber/images433.jpg\n",
            "digitalcyber/images348.jpg\n",
            "digitalcyber/image18.jpeg\n",
            "digitalcyber/images181.jpg\n",
            "digitalcyber/images282.jpg\n",
            "digitalcyber/images248.jpg\n",
            "digitalcyber/images173.jpg\n",
            "digitalcyber/maxresdefault.jpg\n",
            "digitalcyber/images134.jpg\n",
            "digitalcyber/88434-cyberpunk-city-artist-artwork-digital-art-hd-4k-5k-deviantart.jpg\n",
            "digitalcyber/images364.jpg\n",
            "digitalcyber/images448.jpg\n",
            "digitalcyber/images413.jpg\n",
            "digitalcyber/scifi-concept-art-neon-cyberpunk-city-towery-hill.jpg\n",
            "digitalcyber/images169.jpg\n",
            "digitalcyber/images67.jpg\n",
            "digitalcyber/images524.jpg\n",
            "digitalcyber/images45.jpg\n",
            "digitalcyber/images321.jpg\n",
            "digitalcyber/images303.jpg\n",
            "digitalcyber/images526.jpg\n",
            "digitalcyber/images51.jpg\n",
            "digitalcyber/images554.jpg\n",
            "digitalcyber/images616.jpg\n",
            "digitalcyber/images280.jpg\n",
            "digitalcyber/a7f5eaf43ee312c5c13feaf5fa11d199.jpg\n",
            "digitalcyber/images600.jpg\n",
            "digitalcyber/images279.jpg\n",
            "digitalcyber/images624.jpg\n",
            "digitalcyber/images99.jpg\n",
            "digitalcyber/cyberpunk-wallpaper-2101050014288-scaled.jpg\n",
            "digitalcyber/images547.jpg\n",
            "digitalcyber/images491.jpg\n",
            "digitalcyber/images236.jpg\n",
            "digitalcyber/images305.jpg\n",
            "digitalcyber/images410.jpg\n",
            "digitalcyber/images308.jpg\n",
            "digitalcyber/images502.jpg\n",
            "digitalcyber/image24.jpeg\n",
            "digitalcyber/images405.jpg\n",
            "digitalcyber/images371.jpg\n",
            "digitalcyber/images94.jpg\n",
            "digitalcyber/images363.jpg\n",
            "digitalcyber/images395.jpg\n",
            "digitalcyber/images194.jpg\n",
            "digitalcyber/images175.jpg\n",
            "digitalcyber/image26.jpeg\n",
            "digitalcyber/images492.jpg\n",
            "digitalcyber/580393-cyberpunk-digital_art-futuristic.jpg\n",
            "digitalcyber/921270-digital-art-artwork-futuristic-cyberpunk-neon.jpg\n",
            "digitalcyber/cyberpunk_digital_art-t2.jpg\n",
            "digitalcyber/images347.jpg\n",
            "digitalcyber/images495.jpg\n",
            "digitalcyber/images592.jpg\n",
            "digitalcyber/images256.jpg\n",
            "digitalcyber/image10.jpeg\n",
            "digitalcyber/images417.jpg\n",
            "digitalcyber/569782-cyberpunk-digital_art-science_fiction-Augmentation-748x425.jpg\n",
            "digitalcyber/images467.jpg\n",
            "digitalcyber/images560.jpg\n",
            "digitalcyber/images114.jpg\n",
            "digitalcyber/images300.jpg\n",
            "digitalcyber/images285.jpg\n",
            "digitalcyber/images247.jpg\n",
            "digitalcyber/images399.jpg\n",
            "digitalcyber/images97.jpg\n",
            "digitalcyber/digital-art-women-blonde-futuristic-wallpaper-preview.jpg\n",
            "digitalcyber/images237.jpg\n",
            "digitalcyber/images36.jpg\n",
            "digitalcyber/images93.jpg\n",
            "digitalcyber/images100.jpg\n",
            "digitalcyber/images536.jpg\n",
            "digitalcyber/images239.jpg\n",
            "digitalcyber/images408.jpg\n",
            "digitalcyber/images16.jpg\n",
            "digitalcyber/images142.jpg\n",
            "digitalcyber/images334.jpg\n",
            "digitalcyber/images432.jpg\n",
            "digitalcyber/851e01476ca7ebd942b02f941d484b98.jpg\n",
            "digitalcyber/images575.jpg\n",
            "digitalcyber/digital-art-artwork-video-games-cyberpunk-cyberpunk-2077-hd-wallpaper-preview.jpg\n",
            "digitalcyber/image27.jpeg\n",
            "digitalcyber/image.jpeg\n",
            "digitalcyber/images208.jpg\n",
            "digitalcyber/images217.jpg\n",
            "digitalcyber/images264.jpg\n",
            "digitalcyber/images500.jpg\n",
            "digitalcyber/images542.jpg\n",
            "digitalcyber/cyber-science-fiction-digital-art-concept-art-cyberpunk-hd-wallpaper-preview.jpg\n",
            "digitalcyber/image29.jpeg\n",
            "digitalcyber/images276.jpg\n",
            "digitalcyber/images313.jpg\n",
            "digitalcyber/images540.jpg\n",
            "digitalcyber/images57.jpg\n",
            "digitalcyber/images225.jpg\n",
            "digitalcyber/images76.jpg\n",
            "digitalcyber/e-walking-futuristic-city-digital-art-style-illustration-painting_37402-1400.jpg\n",
            "digitalcyber/images187.jpg\n",
            "digitalcyber/create-cyberpunk-digital-art.jpg\n",
            "digitalcyber/number1sketch-asset.jpg\n",
            "digitalcyber/images167.jpg\n",
            "digitalcyber/images117.jpg\n",
            "digitalcyber/images60.jpg\n",
            "digitalcyber/images480.jpg\n",
            "digitalcyber/images623.jpg\n",
            "digitalcyber/images179.jpg\n",
            "digitalcyber/images189.jpg\n",
            "digitalcyber/images342.jpg\n",
            "digitalcyber/images403.jpg\n",
            "digitalcyber/images479.jpg\n",
            "digitalcyber/images420.jpg\n",
            "digitalcyber/360_F_527799984_QW4Ddw5kt0bhmutX3wuhQpucWDfeBEgY.jpg\n",
            "digitalcyber/images597.jpg\n",
            "digitalcyber/images288.jpg\n",
            "digitalcyber/images385.jpg\n",
            "digitalcyber/images345.jpg\n",
            "digitalcyber/images104.jpg\n",
            "digitalcyber/images530.jpg\n",
            "digitalcyber/images449.jpg\n",
            "digitalcyber/images601.jpg\n",
            "digitalcyber/images422.jpg\n",
            "digitalcyber/images522.jpg\n",
            "digitalcyber/cyberpunk-geisha-digital-art-hd-wallpaper-preview.jpg\n",
            "digitalcyber/images574.jpg\n",
            "digitalcyber/images136.jpg\n",
            "digitalcyber/images124.jpg\n",
            "digitalcyber/images466.jpg\n",
            "digitalcyber/images233.jpg\n",
            "digitalcyber/images317.jpg\n",
            "digitalcyber/images477.jpg\n",
            "digitalcyber/images141.jpg\n",
            "digitalcyber/cyberpunk-street-chinmay-naolekar.jpg\n",
            "digitalcyber/images528.jpg\n",
            "digitalcyber/images91.jpg\n",
            "digitalcyber/images456.jpg\n",
            "digitalcyber/images162.jpg\n",
            "digitalcyber/images180.jpg\n",
            "digitalcyber/images314.jpg\n",
            "digitalcyber/images572.jpg\n",
            "digitalcyber/images186.jpg\n",
            "digitalcyber/images551.jpg\n",
            "digitalcyber/images329.jpg\n",
            "digitalcyber/images612.jpg\n",
            "digitalcyber/maxresdefault2.jpg\n",
            "digitalcyber/images483.jpg\n",
            "digitalcyber/images319.jpg\n",
            "digitalcyber/images604.jpg\n",
            "digitalcyber/9---29493-portfolio-23094.motoh9.image.o0w.jpg\n",
            "digitalcyber/images451.jpg\n",
            "digitalcyber/images446.jpg\n",
            "digitalcyber/images123.jpg\n",
            "digitalcyber/images223.jpg\n",
            "digitalcyber/images253.jpg\n",
            "digitalcyber/images87.jpg\n",
            "digitalcyber/images25.jpg\n",
            "digitalcyber/image22.jpeg\n",
            "digitalcyber/images478.jpg\n",
            "digitalcyber/images482.jpg\n",
            "digitalcyber/images115.jpg\n",
            "digitalcyber/images297.jpg\n",
            "digitalcyber/images489.jpg\n",
            "digitalcyber/32---neuromancer-4k.xbxlaz.jpg\n",
            "digitalcyber/images269.jpg\n",
            "digitalcyber/images166.jpg\n",
            "digitalcyber/images442.jpg\n",
            "digitalcyber/images161.jpg\n",
            "digitalcyber/images458.jpg\n",
            "digitalcyber/images324.jpg\n",
            "digitalcyber/images352.jpg\n",
            "digitalcyber/images518.jpg\n",
            "digitalcyber/images215.jpg\n",
            "digitalcyber/image25.jpeg\n",
            "digitalcyber/images213.jpg\n",
            "digitalcyber/images224.jpg\n",
            "digitalcyber/images387.jpg\n",
            "digitalcyber/images583.jpg\n",
            "digitalcyber/images268.jpg\n",
            "digitalcyber/images254.jpg\n",
            "digitalcyber/images56.jpg\n",
            "digitalcyber/images476.jpg\n",
            "digitalcyber/images221.jpg\n",
            "digitalcyber/images140.jpg\n",
            "digitalcyber/images200.jpg\n",
            "digitalcyber/images469.jpg\n",
            "digitalcyber/images149.jpg\n",
            "digitalcyber/images86.jpg\n",
            "digitalcyber/images49.jpg\n",
            "digitalcyber/images227.jpg\n",
            "digitalcyber/images278.jpg\n",
            "digitalcyber/images250.jpg\n",
            "digitalcyber/images429.jpg\n",
            "digitalcyber/images453.jpg\n",
            "digitalcyber/images75.jpg\n",
            "digitalcyber/cyberpunk-sci-fi-sword-digital-art-uhdpaper.com-4K-131.jpg\n",
            "digitalcyber/images576.jpg\n",
            "digitalcyber/images58.jpg\n",
            "digitalcyber/images438.jpg\n",
            "digitalcyber/images472.jpg\n",
            "digitalcyber/images132.jpg\n",
            "digitalcyber/images390.jpg\n",
            "digitalcyber/images350.jpg\n",
            "digitalcyber/images372.jpg\n",
            "digitalcyber/cyberpunk-2077-digital-art-2020_bGllZmyUmZqaraWkpJRobWllrWdma2U.jpg\n",
            "digitalcyber/images351.jpg\n",
            "digitalcyber/woman-cyberpunk-city-futuristic-mask-standing-digital-art-style-illustration-painting-120692219.jpg\n",
            "digitalcyber/images210.jpg\n",
            "digitalcyber/images234.jpg\n",
            "digitalcyber/images464.jpg\n",
            "digitalcyber/images581.jpg\n",
            "digitalcyber/images357.jpg\n",
            "digitalcyber/images596.jpg\n",
            "digitalcyber/image3.jpeg\n",
            "digitalcyber/images550.jpg\n",
            "digitalcyber/-futuristic-colorful-light-digital-art-style-illustration-painting-110570562.jpg\n",
            "digitalcyber/futuristic-cyberpunk-artwork-digital-art-wallpaper.jpg\n",
            "digitalcyber/76665-cyberpunk-artist-artwork-digital-art-hd-city.jpg\n",
            "digitalcyber/AOh-ky00sHl7Y6Dj1hK51L4govVMpernUP84WPF4GnMUXgs64-c-mo.jpg\n",
            "digitalcyber/cyber-science-fiction-digital-art-concept-art-cyberpunk-hd-wallpaper-preview2.jpg\n",
            "digitalcyber/images465.jpg\n",
            "digitalcyber/images259.jpg\n",
            "digitalcyber/images622.jpg\n",
            "digitalcyber/images457.jpg\n",
            "digitalcyber/images625.jpg\n",
            "digitalcyber/images153.jpg\n",
            "digitalcyber/images320.jpg\n",
            "digitalcyber/cyberpunk-girl-torie.jpg\n",
            "digitalcyber/images151.jpg\n",
            "digitalcyber/image16.jpeg\n",
            "digitalcyber/images245.jpg\n",
            "digitalcyber/images428.jpg\n",
            "digitalcyber/cyborg-woman-in-cyberpunk-city-stock-illustrations_csp58031658.jpg\n",
            "digitalcyber/images299.jpg\n",
            "digitalcyber/images440.jpg\n",
            "digitalcyber/images435.jpg\n",
            "digitalcyber/image9.jpeg\n",
            "digitalcyber/images343.jpg\n",
            "digitalcyber/cyberpunk-nikolay-gorishniy.jpg\n",
            "digitalcyber/images209.jpg\n",
            "digitalcyber/images586.jpg\n",
            "digitalcyber/images564.jpg\n",
            "digitalcyber/cyberpunk-lisa-art.jpg\n",
            "digitalcyber/0f2fc918dedae29ad2b67963c01b6b17.jpg\n",
            "digitalcyber/images316.jpg\n",
            "digitalcyber/images508.jpg\n",
            "digitalcyber/images37.jpg\n",
            "digitalcyber/images328.jpg\n",
            "digitalcyber/images384.jpg\n",
            "digitalcyber/images21.jpg\n",
            "digitalcyber/images567.jpg\n",
            "digitalcyber/images197.jpg\n",
            "digitalcyber/images415.jpg\n",
            "digitalcyber/images42.jpg\n",
            "digitalcyber/images83.jpg\n",
            "digitalcyber/images414.jpg\n",
            "digitalcyber/images378.jpg\n",
            "digitalcyber/images383.jpg\n",
            "digitalcyber/images618.jpg\n",
            "digitalcyber/Cover_DigitalArtbook_Cyberpunk2077.png\n",
            "digitalcyber/images318.jpg\n",
            "digitalcyber/images588.jpg\n",
            "digitalcyber/images198.jpg\n",
            "digitalcyber/images393.jpg\n",
            "digitalcyber/images235.jpg\n",
            "digitalcyber/images238.jpg\n",
            "digitalcyber/images258.jpg\n",
            "digitalcyber/images47.jpg\n",
            "digitalcyber/images44.jpg\n",
            "digitalcyber/images475.jpg\n",
            "digitalcyber/images242.jpg\n",
            "digitalcyber/images131.jpg\n",
            "digitalcyber/images377.jpg\n",
            "digitalcyber/images244.jpg\n",
            "digitalcyber/images8.jpg\n",
            "digitalcyber/images159.jpg\n",
            "digitalcyber/images284.jpg\n",
            "digitalcyber/images402.jpg\n",
            "digitalcyber/images69.jpg\n",
            "digitalcyber/images267.jpg\n",
            "digitalcyber/images556.jpg\n",
            "digitalcyber/images64.jpg\n",
            "digitalcyber/42---cyber-a.egtku8.image.8j5.jpg\n",
            "digitalcyber/images79.jpg\n",
            "digitalcyber/images11.jpg\n",
            "digitalcyber/images112.jpg\n",
            "digitalcyber/image30.jpeg\n",
            "digitalcyber/images157.jpg\n",
            "digitalcyber/images309.jpg\n",
            "digitalcyber/images10.jpg\n",
            "digitalcyber/images146.jpg\n",
            "digitalcyber/images512.jpg\n",
            "digitalcyber/images122.jpg\n",
            "digitalcyber/images391.jpg\n",
            "digitalcyber/cyberpunk-hd-digital-art-2022_bWhqZWaUmZqaraWkpJRmaWllrWdqa2U.jpg\n",
            "digitalcyber/images143.jpg\n",
            "digitalcyber/images525.jpg\n",
            "digitalcyber/images92.jpg\n",
            "digitalcyber/images485.jpg\n",
            "digitalcyber/091515145779407.62a72f491d95a.jpg\n",
            "digitalcyber/images295.jpg\n",
            "digitalcyber/images275.jpg\n",
            "digitalcyber/images427.jpg\n",
            "digitalcyber/cyberpunk-neon-girl-digital-art-82-1125x2436.jpg\n",
            "digitalcyber/images291.jpg\n",
            "digitalcyber/images462.jpg\n",
            "digitalcyber/77481-cyberpunk-biker-smoking-artist-artwork-digital-art-hd-4k.jpg\n",
            "digitalcyber/cyberpunk-cyberpunk-2077-video-games-fan-art-women-hd-wallpaper-preview.jpg\n",
            "digitalcyber/images559.jpg\n",
            "digitalcyber/images218.jpg\n",
            "digitalcyber/Cyberpunk_final-uai-2880x1757-1-scaled-300x183.jpg\n",
            "digitalcyber/images260.jpg\n",
            "digitalcyber/images359.jpg\n",
            "digitalcyber/images388.jpg\n",
            "digitalcyber/94b94bb39fe24278803cc5e4a49c5135.jpg\n",
            "digitalcyber/images156.jpg\n",
            "digitalcyber/images172.jpg\n",
            "digitalcyber/HD-wallpaper-cyber-eyes-cyberpunk-neon-artist-artwork-digital-art.jpg\n",
            "digitalcyber/images409.jpg\n",
            "digitalcyber/images507.jpg\n",
            "digitalcyber/images570.jpg\n",
            "digitalcyber/images332.jpg\n",
            "digitalcyber/images128.jpg\n",
            "digitalcyber/images474.jpg\n",
            "digitalcyber/images82.jpg\n",
            "digitalcyber/images177.jpg\n",
            "digitalcyber/images553.jpg\n",
            "digitalcyber/images397.jpg\n",
            "digitalcyber/images430.jpg\n",
            "digitalcyber/images591.jpg\n",
            "digitalcyber/images613.jpg\n",
            "digitalcyber/cyberpunk-2077-girl-digital-art_bGptam2UmZqaraWkpJRoa2VlrWdlZ2s.jpg\n",
            "digitalcyber/images201.jpg\n",
            "digitalcyber/images273.jpg\n",
            "digitalcyber/images207.jpg\n",
            "digitalcyber/images255.jpg\n",
            "digitalcyber/images286.jpg\n",
            "digitalcyber/images366.jpg\n",
            "digitalcyber/images18.jpg\n",
            "digitalcyber/images46.jpg\n",
            "digitalcyber/images322.jpg\n",
            "digitalcyber/images389.jpg\n",
            "digitalcyber/image2.jpeg\n",
            "digitalcyber/images310.jpg\n",
            "digitalcyber/images176.jpg\n",
            "digitalcyber/l-art-digital-painting-fan-art-artwork-Yee-ling-Chung-Cyberpunk-2077-1977765.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6TQxEKQJuI4R"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRWx5D09dX3p"
      },
      "source": [
        "images_path = \"/content/drive/MyDrive/ColabNotebooks/Datasets/digitalcyber/\"\n",
        "#resized_images = \"/content/resized_images/\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaoY5WTbi4dJ"
      },
      "source": [
        "## **Resizing Data to match Neural Network Input**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUJtmq0gzkSx"
      },
      "source": [
        "#!mkdir resized_images\n",
        "import os\n",
        "from PIL import Image\n",
        "import cv2\n",
        "reshape_size = (128,128)\n",
        "\n",
        "i = 0\n",
        "for image in os.listdir(images_path):\n",
        "   #print(image)\n",
        "  #img = cv2.imread(\"/content/cyberart/cyberpunk/\" + image)\n",
        "  img = cv2.imread(images_path + image)\n",
        "  img = cv2.resize(img, reshape_size)\n",
        "  cv2.imwrite(\"resized_images/%d.png\" % i,img)\n",
        "  #cv2.imwrite(\"resized_images/%d.jpeg\" % i,img)\n",
        "  # # print(img.shape)\n",
        "  i = i+1\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr-eZOzg0X79"
      },
      "source": [
        "## **2) Parameters for Neural Networks & Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RThZMDruz9cB"
      },
      "source": [
        "img_width = 128\n",
        "img_height = 128\n",
        "channels = 3\n",
        "img_shape = (img_width, img_height, channels)\n",
        "latent_dim = 100\n",
        "adam = Adam(learning_rate=0.0002)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3bcJZZg0cqy"
      },
      "source": [
        "## **3) Building Generator**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdiqZpri0iQh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48632543-9afe-49e3-8caf-a5d0f3b7467b"
      },
      "source": [
        "def build_generator():\n",
        "    model = Sequential()\n",
        "    #to determine the input layer divide img_width /2 /2 /2 = 16 \n",
        "    model.add(Dense(256 * 16* 16, input_dim=latent_dim))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Reshape((16,16,256)))\n",
        "\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Conv2D(3, (3,3), activation='tanh', padding='same'))\n",
        "  \n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "generator = build_generator()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 65536)             6619136   \n",
            "                                                                 \n",
            " leaky_re_lu_8 (LeakyReLU)   (None, 65536)             0         \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 32, 32, 128)      524416    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_9 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_4 (Conv2DT  (None, 64, 64, 128)      262272    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_10 (LeakyReLU)  (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_5 (Conv2DT  (None, 128, 128, 128)    262272    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_11 (LeakyReLU)  (None, 128, 128, 128)     0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 128, 128, 3)       3459      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,671,555\n",
            "Trainable params: 7,671,555\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bt6QsJCW0mcI"
      },
      "source": [
        "## **4) Building Discriminator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2JzEAPv0lKt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfb7fe96-5bb0-43c2-cf7f-03548116cb97"
      },
      "source": [
        "def build_discriminator():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (3,3), padding='same', input_shape=img_shape))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Conv2D(128, (3,3), padding='same', ))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    \n",
        "    model.add(Conv2D(128, (3,3), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Conv2D(256, (3,3), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 128, 128, 64)      1792      \n",
            "                                                                 \n",
            " leaky_re_lu_12 (LeakyReLU)  (None, 128, 128, 64)      0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 128, 128, 128)     73856     \n",
            "                                                                 \n",
            " leaky_re_lu_13 (LeakyReLU)  (None, 128, 128, 128)     0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 128, 128, 128)     147584    \n",
            "                                                                 \n",
            " leaky_re_lu_14 (LeakyReLU)  (None, 128, 128, 128)     0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 128, 128, 256)     295168    \n",
            "                                                                 \n",
            " leaky_re_lu_15 (LeakyReLU)  (None, 128, 128, 256)     0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 4194304)           0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4194304)           0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 4194305   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,712,705\n",
            "Trainable params: 4,712,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbcKcKmA0q2S"
      },
      "source": [
        "## **5) Connecting Neural Networks to build GAN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0Ue3TEd0xLy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2a3289c-cec6-4e7f-c177-10393e40986d"
      },
      "source": [
        "GAN = Sequential()\n",
        "discriminator.trainable = False\n",
        "GAN.add(generator)\n",
        "GAN.add(discriminator)\n",
        "GAN.summary()\n",
        "\n",
        "GAN.compile(loss='binary_crossentropy', optimizer=adam)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential_3 (Sequential)   (None, 128, 128, 3)       7671555   \n",
            "                                                                 \n",
            " sequential_4 (Sequential)   (None, 1)                 4712705   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,384,260\n",
            "Trainable params: 7,671,555\n",
            "Non-trainable params: 4,712,705\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPqU8dZDaQmE"
      },
      "source": [
        "# generator.summary()\n",
        "# discriminator.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WaNhBDwRwTG"
      },
      "source": [
        "## **6) Outputting Images**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQEJ0WbjRppy"
      },
      "source": [
        "#@title\n",
        "## **7) Outputting Images**\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import imageio\n",
        "import PIL\n",
        "\n",
        "save_name = 0.00000000\n",
        "\n",
        "def save_imgs(epoch):\n",
        "    r, c = 4, 4\n",
        "    noise = np.random.normal(0, 1, (r * c, latent_dim))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "    global save_name\n",
        "    save_name += 0.00000001\n",
        "\n",
        "    # Rescale images 0 - 1\n",
        "    gen_imgs = (gen_imgs + 1) / 2.0\n",
        "\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axs[i,j].imshow(gen_imgs[cnt])\n",
        "            axs[i,j].axis('off')\n",
        "            cnt += 1\n",
        "    fig.savefig(\"currentgeneration.png\")\n",
        "    fig.savefig(\"generated_images/%.8f.png\" % save_name)\n",
        "    plt.close()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tE57Lk5V0xs2"
      },
      "source": [
        "## **7) Training GAN**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "array = []\n",
        "path = '/content/resized_images/'\n",
        "\n",
        "for image in os.listdir(path):\n",
        "  image = Image.open(path + image)\n",
        "  data = np.asarray(image)\n",
        "  array.append(data)\n",
        "\n",
        "\n",
        "  X_train = np.array(array)\n",
        "  X_train = X_train / 127.5 -1.\n",
        "  print(X_train.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaoMAnNSjqT7",
        "outputId": "5ada4c3e-09e7-491a-b6d9-bb3824bac8c8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 128, 128, 3)\n",
            "(2, 128, 128, 3)\n",
            "(3, 128, 128, 3)\n",
            "(4, 128, 128, 3)\n",
            "(5, 128, 128, 3)\n",
            "(6, 128, 128, 3)\n",
            "(7, 128, 128, 3)\n",
            "(8, 128, 128, 3)\n",
            "(9, 128, 128, 3)\n",
            "(10, 128, 128, 3)\n",
            "(11, 128, 128, 3)\n",
            "(12, 128, 128, 3)\n",
            "(13, 128, 128, 3)\n",
            "(14, 128, 128, 3)\n",
            "(15, 128, 128, 3)\n",
            "(16, 128, 128, 3)\n",
            "(17, 128, 128, 3)\n",
            "(18, 128, 128, 3)\n",
            "(19, 128, 128, 3)\n",
            "(20, 128, 128, 3)\n",
            "(21, 128, 128, 3)\n",
            "(22, 128, 128, 3)\n",
            "(23, 128, 128, 3)\n",
            "(24, 128, 128, 3)\n",
            "(25, 128, 128, 3)\n",
            "(26, 128, 128, 3)\n",
            "(27, 128, 128, 3)\n",
            "(28, 128, 128, 3)\n",
            "(29, 128, 128, 3)\n",
            "(30, 128, 128, 3)\n",
            "(31, 128, 128, 3)\n",
            "(32, 128, 128, 3)\n",
            "(33, 128, 128, 3)\n",
            "(34, 128, 128, 3)\n",
            "(35, 128, 128, 3)\n",
            "(36, 128, 128, 3)\n",
            "(37, 128, 128, 3)\n",
            "(38, 128, 128, 3)\n",
            "(39, 128, 128, 3)\n",
            "(40, 128, 128, 3)\n",
            "(41, 128, 128, 3)\n",
            "(42, 128, 128, 3)\n",
            "(43, 128, 128, 3)\n",
            "(44, 128, 128, 3)\n",
            "(45, 128, 128, 3)\n",
            "(46, 128, 128, 3)\n",
            "(47, 128, 128, 3)\n",
            "(48, 128, 128, 3)\n",
            "(49, 128, 128, 3)\n",
            "(50, 128, 128, 3)\n",
            "(51, 128, 128, 3)\n",
            "(52, 128, 128, 3)\n",
            "(53, 128, 128, 3)\n",
            "(54, 128, 128, 3)\n",
            "(55, 128, 128, 3)\n",
            "(56, 128, 128, 3)\n",
            "(57, 128, 128, 3)\n",
            "(58, 128, 128, 3)\n",
            "(59, 128, 128, 3)\n",
            "(60, 128, 128, 3)\n",
            "(61, 128, 128, 3)\n",
            "(62, 128, 128, 3)\n",
            "(63, 128, 128, 3)\n",
            "(64, 128, 128, 3)\n",
            "(65, 128, 128, 3)\n",
            "(66, 128, 128, 3)\n",
            "(67, 128, 128, 3)\n",
            "(68, 128, 128, 3)\n",
            "(69, 128, 128, 3)\n",
            "(70, 128, 128, 3)\n",
            "(71, 128, 128, 3)\n",
            "(72, 128, 128, 3)\n",
            "(73, 128, 128, 3)\n",
            "(74, 128, 128, 3)\n",
            "(75, 128, 128, 3)\n",
            "(76, 128, 128, 3)\n",
            "(77, 128, 128, 3)\n",
            "(78, 128, 128, 3)\n",
            "(79, 128, 128, 3)\n",
            "(80, 128, 128, 3)\n",
            "(81, 128, 128, 3)\n",
            "(82, 128, 128, 3)\n",
            "(83, 128, 128, 3)\n",
            "(84, 128, 128, 3)\n",
            "(85, 128, 128, 3)\n",
            "(86, 128, 128, 3)\n",
            "(87, 128, 128, 3)\n",
            "(88, 128, 128, 3)\n",
            "(89, 128, 128, 3)\n",
            "(90, 128, 128, 3)\n",
            "(91, 128, 128, 3)\n",
            "(92, 128, 128, 3)\n",
            "(93, 128, 128, 3)\n",
            "(94, 128, 128, 3)\n",
            "(95, 128, 128, 3)\n",
            "(96, 128, 128, 3)\n",
            "(97, 128, 128, 3)\n",
            "(98, 128, 128, 3)\n",
            "(99, 128, 128, 3)\n",
            "(100, 128, 128, 3)\n",
            "(101, 128, 128, 3)\n",
            "(102, 128, 128, 3)\n",
            "(103, 128, 128, 3)\n",
            "(104, 128, 128, 3)\n",
            "(105, 128, 128, 3)\n",
            "(106, 128, 128, 3)\n",
            "(107, 128, 128, 3)\n",
            "(108, 128, 128, 3)\n",
            "(109, 128, 128, 3)\n",
            "(110, 128, 128, 3)\n",
            "(111, 128, 128, 3)\n",
            "(112, 128, 128, 3)\n",
            "(113, 128, 128, 3)\n",
            "(114, 128, 128, 3)\n",
            "(115, 128, 128, 3)\n",
            "(116, 128, 128, 3)\n",
            "(117, 128, 128, 3)\n",
            "(118, 128, 128, 3)\n",
            "(119, 128, 128, 3)\n",
            "(120, 128, 128, 3)\n",
            "(121, 128, 128, 3)\n",
            "(122, 128, 128, 3)\n",
            "(123, 128, 128, 3)\n",
            "(124, 128, 128, 3)\n",
            "(125, 128, 128, 3)\n",
            "(126, 128, 128, 3)\n",
            "(127, 128, 128, 3)\n",
            "(128, 128, 128, 3)\n",
            "(129, 128, 128, 3)\n",
            "(130, 128, 128, 3)\n",
            "(131, 128, 128, 3)\n",
            "(132, 128, 128, 3)\n",
            "(133, 128, 128, 3)\n",
            "(134, 128, 128, 3)\n",
            "(135, 128, 128, 3)\n",
            "(136, 128, 128, 3)\n",
            "(137, 128, 128, 3)\n",
            "(138, 128, 128, 3)\n",
            "(139, 128, 128, 3)\n",
            "(140, 128, 128, 3)\n",
            "(141, 128, 128, 3)\n",
            "(142, 128, 128, 3)\n",
            "(143, 128, 128, 3)\n",
            "(144, 128, 128, 3)\n",
            "(145, 128, 128, 3)\n",
            "(146, 128, 128, 3)\n",
            "(147, 128, 128, 3)\n",
            "(148, 128, 128, 3)\n",
            "(149, 128, 128, 3)\n",
            "(150, 128, 128, 3)\n",
            "(151, 128, 128, 3)\n",
            "(152, 128, 128, 3)\n",
            "(153, 128, 128, 3)\n",
            "(154, 128, 128, 3)\n",
            "(155, 128, 128, 3)\n",
            "(156, 128, 128, 3)\n",
            "(157, 128, 128, 3)\n",
            "(158, 128, 128, 3)\n",
            "(159, 128, 128, 3)\n",
            "(160, 128, 128, 3)\n",
            "(161, 128, 128, 3)\n",
            "(162, 128, 128, 3)\n",
            "(163, 128, 128, 3)\n",
            "(164, 128, 128, 3)\n",
            "(165, 128, 128, 3)\n",
            "(166, 128, 128, 3)\n",
            "(167, 128, 128, 3)\n",
            "(168, 128, 128, 3)\n",
            "(169, 128, 128, 3)\n",
            "(170, 128, 128, 3)\n",
            "(171, 128, 128, 3)\n",
            "(172, 128, 128, 3)\n",
            "(173, 128, 128, 3)\n",
            "(174, 128, 128, 3)\n",
            "(175, 128, 128, 3)\n",
            "(176, 128, 128, 3)\n",
            "(177, 128, 128, 3)\n",
            "(178, 128, 128, 3)\n",
            "(179, 128, 128, 3)\n",
            "(180, 128, 128, 3)\n",
            "(181, 128, 128, 3)\n",
            "(182, 128, 128, 3)\n",
            "(183, 128, 128, 3)\n",
            "(184, 128, 128, 3)\n",
            "(185, 128, 128, 3)\n",
            "(186, 128, 128, 3)\n",
            "(187, 128, 128, 3)\n",
            "(188, 128, 128, 3)\n",
            "(189, 128, 128, 3)\n",
            "(190, 128, 128, 3)\n",
            "(191, 128, 128, 3)\n",
            "(192, 128, 128, 3)\n",
            "(193, 128, 128, 3)\n",
            "(194, 128, 128, 3)\n",
            "(195, 128, 128, 3)\n",
            "(196, 128, 128, 3)\n",
            "(197, 128, 128, 3)\n",
            "(198, 128, 128, 3)\n",
            "(199, 128, 128, 3)\n",
            "(200, 128, 128, 3)\n",
            "(201, 128, 128, 3)\n",
            "(202, 128, 128, 3)\n",
            "(203, 128, 128, 3)\n",
            "(204, 128, 128, 3)\n",
            "(205, 128, 128, 3)\n",
            "(206, 128, 128, 3)\n",
            "(207, 128, 128, 3)\n",
            "(208, 128, 128, 3)\n",
            "(209, 128, 128, 3)\n",
            "(210, 128, 128, 3)\n",
            "(211, 128, 128, 3)\n",
            "(212, 128, 128, 3)\n",
            "(213, 128, 128, 3)\n",
            "(214, 128, 128, 3)\n",
            "(215, 128, 128, 3)\n",
            "(216, 128, 128, 3)\n",
            "(217, 128, 128, 3)\n",
            "(218, 128, 128, 3)\n",
            "(219, 128, 128, 3)\n",
            "(220, 128, 128, 3)\n",
            "(221, 128, 128, 3)\n",
            "(222, 128, 128, 3)\n",
            "(223, 128, 128, 3)\n",
            "(224, 128, 128, 3)\n",
            "(225, 128, 128, 3)\n",
            "(226, 128, 128, 3)\n",
            "(227, 128, 128, 3)\n",
            "(228, 128, 128, 3)\n",
            "(229, 128, 128, 3)\n",
            "(230, 128, 128, 3)\n",
            "(231, 128, 128, 3)\n",
            "(232, 128, 128, 3)\n",
            "(233, 128, 128, 3)\n",
            "(234, 128, 128, 3)\n",
            "(235, 128, 128, 3)\n",
            "(236, 128, 128, 3)\n",
            "(237, 128, 128, 3)\n",
            "(238, 128, 128, 3)\n",
            "(239, 128, 128, 3)\n",
            "(240, 128, 128, 3)\n",
            "(241, 128, 128, 3)\n",
            "(242, 128, 128, 3)\n",
            "(243, 128, 128, 3)\n",
            "(244, 128, 128, 3)\n",
            "(245, 128, 128, 3)\n",
            "(246, 128, 128, 3)\n",
            "(247, 128, 128, 3)\n",
            "(248, 128, 128, 3)\n",
            "(249, 128, 128, 3)\n",
            "(250, 128, 128, 3)\n",
            "(251, 128, 128, 3)\n",
            "(252, 128, 128, 3)\n",
            "(253, 128, 128, 3)\n",
            "(254, 128, 128, 3)\n",
            "(255, 128, 128, 3)\n",
            "(256, 128, 128, 3)\n",
            "(257, 128, 128, 3)\n",
            "(258, 128, 128, 3)\n",
            "(259, 128, 128, 3)\n",
            "(260, 128, 128, 3)\n",
            "(261, 128, 128, 3)\n",
            "(262, 128, 128, 3)\n",
            "(263, 128, 128, 3)\n",
            "(264, 128, 128, 3)\n",
            "(265, 128, 128, 3)\n",
            "(266, 128, 128, 3)\n",
            "(267, 128, 128, 3)\n",
            "(268, 128, 128, 3)\n",
            "(269, 128, 128, 3)\n",
            "(270, 128, 128, 3)\n",
            "(271, 128, 128, 3)\n",
            "(272, 128, 128, 3)\n",
            "(273, 128, 128, 3)\n",
            "(274, 128, 128, 3)\n",
            "(275, 128, 128, 3)\n",
            "(276, 128, 128, 3)\n",
            "(277, 128, 128, 3)\n",
            "(278, 128, 128, 3)\n",
            "(279, 128, 128, 3)\n",
            "(280, 128, 128, 3)\n",
            "(281, 128, 128, 3)\n",
            "(282, 128, 128, 3)\n",
            "(283, 128, 128, 3)\n",
            "(284, 128, 128, 3)\n",
            "(285, 128, 128, 3)\n",
            "(286, 128, 128, 3)\n",
            "(287, 128, 128, 3)\n",
            "(288, 128, 128, 3)\n",
            "(289, 128, 128, 3)\n",
            "(290, 128, 128, 3)\n",
            "(291, 128, 128, 3)\n",
            "(292, 128, 128, 3)\n",
            "(293, 128, 128, 3)\n",
            "(294, 128, 128, 3)\n",
            "(295, 128, 128, 3)\n",
            "(296, 128, 128, 3)\n",
            "(297, 128, 128, 3)\n",
            "(298, 128, 128, 3)\n",
            "(299, 128, 128, 3)\n",
            "(300, 128, 128, 3)\n",
            "(301, 128, 128, 3)\n",
            "(302, 128, 128, 3)\n",
            "(303, 128, 128, 3)\n",
            "(304, 128, 128, 3)\n",
            "(305, 128, 128, 3)\n",
            "(306, 128, 128, 3)\n",
            "(307, 128, 128, 3)\n",
            "(308, 128, 128, 3)\n",
            "(309, 128, 128, 3)\n",
            "(310, 128, 128, 3)\n",
            "(311, 128, 128, 3)\n",
            "(312, 128, 128, 3)\n",
            "(313, 128, 128, 3)\n",
            "(314, 128, 128, 3)\n",
            "(315, 128, 128, 3)\n",
            "(316, 128, 128, 3)\n",
            "(317, 128, 128, 3)\n",
            "(318, 128, 128, 3)\n",
            "(319, 128, 128, 3)\n",
            "(320, 128, 128, 3)\n",
            "(321, 128, 128, 3)\n",
            "(322, 128, 128, 3)\n",
            "(323, 128, 128, 3)\n",
            "(324, 128, 128, 3)\n",
            "(325, 128, 128, 3)\n",
            "(326, 128, 128, 3)\n",
            "(327, 128, 128, 3)\n",
            "(328, 128, 128, 3)\n",
            "(329, 128, 128, 3)\n",
            "(330, 128, 128, 3)\n",
            "(331, 128, 128, 3)\n",
            "(332, 128, 128, 3)\n",
            "(333, 128, 128, 3)\n",
            "(334, 128, 128, 3)\n",
            "(335, 128, 128, 3)\n",
            "(336, 128, 128, 3)\n",
            "(337, 128, 128, 3)\n",
            "(338, 128, 128, 3)\n",
            "(339, 128, 128, 3)\n",
            "(340, 128, 128, 3)\n",
            "(341, 128, 128, 3)\n",
            "(342, 128, 128, 3)\n",
            "(343, 128, 128, 3)\n",
            "(344, 128, 128, 3)\n",
            "(345, 128, 128, 3)\n",
            "(346, 128, 128, 3)\n",
            "(347, 128, 128, 3)\n",
            "(348, 128, 128, 3)\n",
            "(349, 128, 128, 3)\n",
            "(350, 128, 128, 3)\n",
            "(351, 128, 128, 3)\n",
            "(352, 128, 128, 3)\n",
            "(353, 128, 128, 3)\n",
            "(354, 128, 128, 3)\n",
            "(355, 128, 128, 3)\n",
            "(356, 128, 128, 3)\n",
            "(357, 128, 128, 3)\n",
            "(358, 128, 128, 3)\n",
            "(359, 128, 128, 3)\n",
            "(360, 128, 128, 3)\n",
            "(361, 128, 128, 3)\n",
            "(362, 128, 128, 3)\n",
            "(363, 128, 128, 3)\n",
            "(364, 128, 128, 3)\n",
            "(365, 128, 128, 3)\n",
            "(366, 128, 128, 3)\n",
            "(367, 128, 128, 3)\n",
            "(368, 128, 128, 3)\n",
            "(369, 128, 128, 3)\n",
            "(370, 128, 128, 3)\n",
            "(371, 128, 128, 3)\n",
            "(372, 128, 128, 3)\n",
            "(373, 128, 128, 3)\n",
            "(374, 128, 128, 3)\n",
            "(375, 128, 128, 3)\n",
            "(376, 128, 128, 3)\n",
            "(377, 128, 128, 3)\n",
            "(378, 128, 128, 3)\n",
            "(379, 128, 128, 3)\n",
            "(380, 128, 128, 3)\n",
            "(381, 128, 128, 3)\n",
            "(382, 128, 128, 3)\n",
            "(383, 128, 128, 3)\n",
            "(384, 128, 128, 3)\n",
            "(385, 128, 128, 3)\n",
            "(386, 128, 128, 3)\n",
            "(387, 128, 128, 3)\n",
            "(388, 128, 128, 3)\n",
            "(389, 128, 128, 3)\n",
            "(390, 128, 128, 3)\n",
            "(391, 128, 128, 3)\n",
            "(392, 128, 128, 3)\n",
            "(393, 128, 128, 3)\n",
            "(394, 128, 128, 3)\n",
            "(395, 128, 128, 3)\n",
            "(396, 128, 128, 3)\n",
            "(397, 128, 128, 3)\n",
            "(398, 128, 128, 3)\n",
            "(399, 128, 128, 3)\n",
            "(400, 128, 128, 3)\n",
            "(401, 128, 128, 3)\n",
            "(402, 128, 128, 3)\n",
            "(403, 128, 128, 3)\n",
            "(404, 128, 128, 3)\n",
            "(405, 128, 128, 3)\n",
            "(406, 128, 128, 3)\n",
            "(407, 128, 128, 3)\n",
            "(408, 128, 128, 3)\n",
            "(409, 128, 128, 3)\n",
            "(410, 128, 128, 3)\n",
            "(411, 128, 128, 3)\n",
            "(412, 128, 128, 3)\n",
            "(413, 128, 128, 3)\n",
            "(414, 128, 128, 3)\n",
            "(415, 128, 128, 3)\n",
            "(416, 128, 128, 3)\n",
            "(417, 128, 128, 3)\n",
            "(418, 128, 128, 3)\n",
            "(419, 128, 128, 3)\n",
            "(420, 128, 128, 3)\n",
            "(421, 128, 128, 3)\n",
            "(422, 128, 128, 3)\n",
            "(423, 128, 128, 3)\n",
            "(424, 128, 128, 3)\n",
            "(425, 128, 128, 3)\n",
            "(426, 128, 128, 3)\n",
            "(427, 128, 128, 3)\n",
            "(428, 128, 128, 3)\n",
            "(429, 128, 128, 3)\n",
            "(430, 128, 128, 3)\n",
            "(431, 128, 128, 3)\n",
            "(432, 128, 128, 3)\n",
            "(433, 128, 128, 3)\n",
            "(434, 128, 128, 3)\n",
            "(435, 128, 128, 3)\n",
            "(436, 128, 128, 3)\n",
            "(437, 128, 128, 3)\n",
            "(438, 128, 128, 3)\n",
            "(439, 128, 128, 3)\n",
            "(440, 128, 128, 3)\n",
            "(441, 128, 128, 3)\n",
            "(442, 128, 128, 3)\n",
            "(443, 128, 128, 3)\n",
            "(444, 128, 128, 3)\n",
            "(445, 128, 128, 3)\n",
            "(446, 128, 128, 3)\n",
            "(447, 128, 128, 3)\n",
            "(448, 128, 128, 3)\n",
            "(449, 128, 128, 3)\n",
            "(450, 128, 128, 3)\n",
            "(451, 128, 128, 3)\n",
            "(452, 128, 128, 3)\n",
            "(453, 128, 128, 3)\n",
            "(454, 128, 128, 3)\n",
            "(455, 128, 128, 3)\n",
            "(456, 128, 128, 3)\n",
            "(457, 128, 128, 3)\n",
            "(458, 128, 128, 3)\n",
            "(459, 128, 128, 3)\n",
            "(460, 128, 128, 3)\n",
            "(461, 128, 128, 3)\n",
            "(462, 128, 128, 3)\n",
            "(463, 128, 128, 3)\n",
            "(464, 128, 128, 3)\n",
            "(465, 128, 128, 3)\n",
            "(466, 128, 128, 3)\n",
            "(467, 128, 128, 3)\n",
            "(468, 128, 128, 3)\n",
            "(469, 128, 128, 3)\n",
            "(470, 128, 128, 3)\n",
            "(471, 128, 128, 3)\n",
            "(472, 128, 128, 3)\n",
            "(473, 128, 128, 3)\n",
            "(474, 128, 128, 3)\n",
            "(475, 128, 128, 3)\n",
            "(476, 128, 128, 3)\n",
            "(477, 128, 128, 3)\n",
            "(478, 128, 128, 3)\n",
            "(479, 128, 128, 3)\n",
            "(480, 128, 128, 3)\n",
            "(481, 128, 128, 3)\n",
            "(482, 128, 128, 3)\n",
            "(483, 128, 128, 3)\n",
            "(484, 128, 128, 3)\n",
            "(485, 128, 128, 3)\n",
            "(486, 128, 128, 3)\n",
            "(487, 128, 128, 3)\n",
            "(488, 128, 128, 3)\n",
            "(489, 128, 128, 3)\n",
            "(490, 128, 128, 3)\n",
            "(491, 128, 128, 3)\n",
            "(492, 128, 128, 3)\n",
            "(493, 128, 128, 3)\n",
            "(494, 128, 128, 3)\n",
            "(495, 128, 128, 3)\n",
            "(496, 128, 128, 3)\n",
            "(497, 128, 128, 3)\n",
            "(498, 128, 128, 3)\n",
            "(499, 128, 128, 3)\n",
            "(500, 128, 128, 3)\n",
            "(501, 128, 128, 3)\n",
            "(502, 128, 128, 3)\n",
            "(503, 128, 128, 3)\n",
            "(504, 128, 128, 3)\n",
            "(505, 128, 128, 3)\n",
            "(506, 128, 128, 3)\n",
            "(507, 128, 128, 3)\n",
            "(508, 128, 128, 3)\n",
            "(509, 128, 128, 3)\n",
            "(510, 128, 128, 3)\n",
            "(511, 128, 128, 3)\n",
            "(512, 128, 128, 3)\n",
            "(513, 128, 128, 3)\n",
            "(514, 128, 128, 3)\n",
            "(515, 128, 128, 3)\n",
            "(516, 128, 128, 3)\n",
            "(517, 128, 128, 3)\n",
            "(518, 128, 128, 3)\n",
            "(519, 128, 128, 3)\n",
            "(520, 128, 128, 3)\n",
            "(521, 128, 128, 3)\n",
            "(522, 128, 128, 3)\n",
            "(523, 128, 128, 3)\n",
            "(524, 128, 128, 3)\n",
            "(525, 128, 128, 3)\n",
            "(526, 128, 128, 3)\n",
            "(527, 128, 128, 3)\n",
            "(528, 128, 128, 3)\n",
            "(529, 128, 128, 3)\n",
            "(530, 128, 128, 3)\n",
            "(531, 128, 128, 3)\n",
            "(532, 128, 128, 3)\n",
            "(533, 128, 128, 3)\n",
            "(534, 128, 128, 3)\n",
            "(535, 128, 128, 3)\n",
            "(536, 128, 128, 3)\n",
            "(537, 128, 128, 3)\n",
            "(538, 128, 128, 3)\n",
            "(539, 128, 128, 3)\n",
            "(540, 128, 128, 3)\n",
            "(541, 128, 128, 3)\n",
            "(542, 128, 128, 3)\n",
            "(543, 128, 128, 3)\n",
            "(544, 128, 128, 3)\n",
            "(545, 128, 128, 3)\n",
            "(546, 128, 128, 3)\n",
            "(547, 128, 128, 3)\n",
            "(548, 128, 128, 3)\n",
            "(549, 128, 128, 3)\n",
            "(550, 128, 128, 3)\n",
            "(551, 128, 128, 3)\n",
            "(552, 128, 128, 3)\n",
            "(553, 128, 128, 3)\n",
            "(554, 128, 128, 3)\n",
            "(555, 128, 128, 3)\n",
            "(556, 128, 128, 3)\n",
            "(557, 128, 128, 3)\n",
            "(558, 128, 128, 3)\n",
            "(559, 128, 128, 3)\n",
            "(560, 128, 128, 3)\n",
            "(561, 128, 128, 3)\n",
            "(562, 128, 128, 3)\n",
            "(563, 128, 128, 3)\n",
            "(564, 128, 128, 3)\n",
            "(565, 128, 128, 3)\n",
            "(566, 128, 128, 3)\n",
            "(567, 128, 128, 3)\n",
            "(568, 128, 128, 3)\n",
            "(569, 128, 128, 3)\n",
            "(570, 128, 128, 3)\n",
            "(571, 128, 128, 3)\n",
            "(572, 128, 128, 3)\n",
            "(573, 128, 128, 3)\n",
            "(574, 128, 128, 3)\n",
            "(575, 128, 128, 3)\n",
            "(576, 128, 128, 3)\n",
            "(577, 128, 128, 3)\n",
            "(578, 128, 128, 3)\n",
            "(579, 128, 128, 3)\n",
            "(580, 128, 128, 3)\n",
            "(581, 128, 128, 3)\n",
            "(582, 128, 128, 3)\n",
            "(583, 128, 128, 3)\n",
            "(584, 128, 128, 3)\n",
            "(585, 128, 128, 3)\n",
            "(586, 128, 128, 3)\n",
            "(587, 128, 128, 3)\n",
            "(588, 128, 128, 3)\n",
            "(589, 128, 128, 3)\n",
            "(590, 128, 128, 3)\n",
            "(591, 128, 128, 3)\n",
            "(592, 128, 128, 3)\n",
            "(593, 128, 128, 3)\n",
            "(594, 128, 128, 3)\n",
            "(595, 128, 128, 3)\n",
            "(596, 128, 128, 3)\n",
            "(597, 128, 128, 3)\n",
            "(598, 128, 128, 3)\n",
            "(599, 128, 128, 3)\n",
            "(600, 128, 128, 3)\n",
            "(601, 128, 128, 3)\n",
            "(602, 128, 128, 3)\n",
            "(603, 128, 128, 3)\n",
            "(604, 128, 128, 3)\n",
            "(605, 128, 128, 3)\n",
            "(606, 128, 128, 3)\n",
            "(607, 128, 128, 3)\n",
            "(608, 128, 128, 3)\n",
            "(609, 128, 128, 3)\n",
            "(610, 128, 128, 3)\n",
            "(611, 128, 128, 3)\n",
            "(612, 128, 128, 3)\n",
            "(613, 128, 128, 3)\n",
            "(614, 128, 128, 3)\n",
            "(615, 128, 128, 3)\n",
            "(616, 128, 128, 3)\n",
            "(617, 128, 128, 3)\n",
            "(618, 128, 128, 3)\n",
            "(619, 128, 128, 3)\n",
            "(620, 128, 128, 3)\n",
            "(621, 128, 128, 3)\n",
            "(622, 128, 128, 3)\n",
            "(623, 128, 128, 3)\n",
            "(624, 128, 128, 3)\n",
            "(625, 128, 128, 3)\n",
            "(626, 128, 128, 3)\n",
            "(627, 128, 128, 3)\n",
            "(628, 128, 128, 3)\n",
            "(629, 128, 128, 3)\n",
            "(630, 128, 128, 3)\n",
            "(631, 128, 128, 3)\n",
            "(632, 128, 128, 3)\n",
            "(633, 128, 128, 3)\n",
            "(634, 128, 128, 3)\n",
            "(635, 128, 128, 3)\n",
            "(636, 128, 128, 3)\n",
            "(637, 128, 128, 3)\n",
            "(638, 128, 128, 3)\n",
            "(639, 128, 128, 3)\n",
            "(640, 128, 128, 3)\n",
            "(641, 128, 128, 3)\n",
            "(642, 128, 128, 3)\n",
            "(643, 128, 128, 3)\n",
            "(644, 128, 128, 3)\n",
            "(645, 128, 128, 3)\n",
            "(646, 128, 128, 3)\n",
            "(647, 128, 128, 3)\n",
            "(648, 128, 128, 3)\n",
            "(649, 128, 128, 3)\n",
            "(650, 128, 128, 3)\n",
            "(651, 128, 128, 3)\n",
            "(652, 128, 128, 3)\n",
            "(653, 128, 128, 3)\n",
            "(654, 128, 128, 3)\n",
            "(655, 128, 128, 3)\n",
            "(656, 128, 128, 3)\n",
            "(657, 128, 128, 3)\n",
            "(658, 128, 128, 3)\n",
            "(659, 128, 128, 3)\n",
            "(660, 128, 128, 3)\n",
            "(661, 128, 128, 3)\n",
            "(662, 128, 128, 3)\n",
            "(663, 128, 128, 3)\n",
            "(664, 128, 128, 3)\n",
            "(665, 128, 128, 3)\n",
            "(666, 128, 128, 3)\n",
            "(667, 128, 128, 3)\n",
            "(668, 128, 128, 3)\n",
            "(669, 128, 128, 3)\n",
            "(670, 128, 128, 3)\n",
            "(671, 128, 128, 3)\n",
            "(672, 128, 128, 3)\n",
            "(673, 128, 128, 3)\n",
            "(674, 128, 128, 3)\n",
            "(675, 128, 128, 3)\n",
            "(676, 128, 128, 3)\n",
            "(677, 128, 128, 3)\n",
            "(678, 128, 128, 3)\n",
            "(679, 128, 128, 3)\n",
            "(680, 128, 128, 3)\n",
            "(681, 128, 128, 3)\n",
            "(682, 128, 128, 3)\n",
            "(683, 128, 128, 3)\n",
            "(684, 128, 128, 3)\n",
            "(685, 128, 128, 3)\n",
            "(686, 128, 128, 3)\n",
            "(687, 128, 128, 3)\n",
            "(688, 128, 128, 3)\n",
            "(689, 128, 128, 3)\n",
            "(690, 128, 128, 3)\n",
            "(691, 128, 128, 3)\n",
            "(692, 128, 128, 3)\n",
            "(693, 128, 128, 3)\n",
            "(694, 128, 128, 3)\n",
            "(695, 128, 128, 3)\n",
            "(696, 128, 128, 3)\n",
            "(697, 128, 128, 3)\n",
            "(698, 128, 128, 3)\n",
            "(699, 128, 128, 3)\n",
            "(700, 128, 128, 3)\n",
            "(701, 128, 128, 3)\n",
            "(702, 128, 128, 3)\n",
            "(703, 128, 128, 3)\n",
            "(704, 128, 128, 3)\n",
            "(705, 128, 128, 3)\n",
            "(706, 128, 128, 3)\n",
            "(707, 128, 128, 3)\n",
            "(708, 128, 128, 3)\n",
            "(709, 128, 128, 3)\n",
            "(710, 128, 128, 3)\n",
            "(711, 128, 128, 3)\n",
            "(712, 128, 128, 3)\n",
            "(713, 128, 128, 3)\n",
            "(714, 128, 128, 3)\n",
            "(715, 128, 128, 3)\n",
            "(716, 128, 128, 3)\n",
            "(717, 128, 128, 3)\n",
            "(718, 128, 128, 3)\n",
            "(719, 128, 128, 3)\n",
            "(720, 128, 128, 3)\n",
            "(721, 128, 128, 3)\n",
            "(722, 128, 128, 3)\n",
            "(723, 128, 128, 3)\n",
            "(724, 128, 128, 3)\n",
            "(725, 128, 128, 3)\n",
            "(726, 128, 128, 3)\n",
            "(727, 128, 128, 3)\n",
            "(728, 128, 128, 3)\n",
            "(729, 128, 128, 3)\n",
            "(730, 128, 128, 3)\n",
            "(731, 128, 128, 3)\n",
            "(732, 128, 128, 3)\n",
            "(733, 128, 128, 3)\n",
            "(734, 128, 128, 3)\n",
            "(735, 128, 128, 3)\n",
            "(736, 128, 128, 3)\n",
            "(737, 128, 128, 3)\n",
            "(738, 128, 128, 3)\n",
            "(739, 128, 128, 3)\n",
            "(740, 128, 128, 3)\n",
            "(741, 128, 128, 3)\n",
            "(742, 128, 128, 3)\n",
            "(743, 128, 128, 3)\n",
            "(744, 128, 128, 3)\n",
            "(745, 128, 128, 3)\n",
            "(746, 128, 128, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egSJJvik00Iq",
        "outputId": "a9172786-ba0e-4469-b853-752cfb8a45da"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "def train(epochs, batch_size=32, save_interval=200):\n",
        "  #(X_train, _), (_, _) = cifar10.load_data()\n",
        "\n",
        "  bat_per_epo = int(X_train.shape[0] / batch_size)\n",
        "  # X_train = np.expand_dims(X_train, axis=3)\n",
        "  # print(X_train.shape)\n",
        "\n",
        "  #Create our Y for our Neural Networks\n",
        "  valid = np.ones((batch_size, 1))\n",
        "  fakes = np.zeros((batch_size, 1))\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    for j in range(bat_per_epo):\n",
        "      #Get Random Batch\n",
        "      idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "      imgs = X_train[idx]\n",
        "\n",
        "      #Generate Fake Images\n",
        "      noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "      gen_imgs = generator.predict(noise)\n",
        "\n",
        "      #Train discriminator\n",
        "      d_loss_real = discriminator.train_on_batch(imgs, valid)\n",
        "      d_loss_fake = discriminator.train_on_batch(gen_imgs, fakes)\n",
        "      d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "      noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "      \n",
        "      #inverse y label\n",
        "      g_loss = GAN.train_on_batch(noise, valid)\n",
        "\n",
        "      print(\"******* %d %d [D loss: %f, acc: %.2f%%] [G loss: %f]\" % (epoch,j, d_loss[0], 100* d_loss[1], g_loss))\n",
        "\n",
        "      # if(epoch % save_interval) == 0:\n",
        "    save_imgs(epoch)\n",
        "\n",
        "\n",
        "train(30000, batch_size=32, save_interval=200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "******* 105 17 [D loss: 0.006236, acc: 100.00%] [G loss: 8.466302]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 105 18 [D loss: 0.008060, acc: 100.00%] [G loss: 8.670914]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 105 19 [D loss: 0.141717, acc: 93.75%] [G loss: 5.649356]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 105 20 [D loss: 0.179441, acc: 95.31%] [G loss: 5.539461]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 105 21 [D loss: 0.004587, acc: 100.00%] [G loss: 10.133544]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 105 22 [D loss: 0.020594, acc: 100.00%] [G loss: 11.962001]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "******* 106 0 [D loss: 0.077161, acc: 98.44%] [G loss: 13.004175]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 106 1 [D loss: 0.264103, acc: 90.62%] [G loss: 4.868741]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 106 2 [D loss: 0.491431, acc: 75.00%] [G loss: 11.726475]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 106 3 [D loss: 0.098929, acc: 98.44%] [G loss: 23.592640]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 106 4 [D loss: 0.864221, acc: 78.12%] [G loss: 18.786037]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 106 5 [D loss: 0.597963, acc: 85.94%] [G loss: 8.212276]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 106 6 [D loss: 0.069906, acc: 95.31%] [G loss: 3.545443]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 106 7 [D loss: 0.490205, acc: 81.25%] [G loss: 6.661175]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 106 8 [D loss: 0.000289, acc: 100.00%] [G loss: 17.647589]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 106 9 [D loss: 0.002594, acc: 100.00%] [G loss: 21.558968]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 106 10 [D loss: 0.089261, acc: 96.88%] [G loss: 26.298687]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 106 11 [D loss: 0.056366, acc: 98.44%] [G loss: 27.324667]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 106 12 [D loss: 0.004165, acc: 100.00%] [G loss: 25.964205]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 106 13 [D loss: 0.016309, acc: 100.00%] [G loss: 24.263433]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 106 14 [D loss: 0.007422, acc: 100.00%] [G loss: 19.465828]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 106 15 [D loss: 0.004468, acc: 100.00%] [G loss: 15.582237]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 106 16 [D loss: 0.002426, acc: 100.00%] [G loss: 11.200815]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 106 17 [D loss: 0.037730, acc: 98.44%] [G loss: 9.270470]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 106 18 [D loss: 0.031566, acc: 98.44%] [G loss: 7.516410]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 106 19 [D loss: 0.029921, acc: 96.88%] [G loss: 5.846908]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 106 20 [D loss: 0.138474, acc: 96.88%] [G loss: 7.157228]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 106 21 [D loss: 0.071345, acc: 96.88%] [G loss: 9.058704]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 106 22 [D loss: 0.262627, acc: 98.44%] [G loss: 10.007347]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 107 0 [D loss: 0.296702, acc: 93.75%] [G loss: 7.601890]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 107 1 [D loss: 0.218865, acc: 89.06%] [G loss: 8.013956]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 107 2 [D loss: 0.014598, acc: 100.00%] [G loss: 11.100499]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 107 3 [D loss: 0.051474, acc: 96.88%] [G loss: 13.465425]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 107 4 [D loss: 0.113562, acc: 96.88%] [G loss: 11.447236]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 107 5 [D loss: 0.221803, acc: 90.62%] [G loss: 9.506427]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 107 6 [D loss: 0.077747, acc: 96.88%] [G loss: 5.588502]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 107 7 [D loss: 0.109503, acc: 95.31%] [G loss: 4.708556]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 107 8 [D loss: 0.071754, acc: 95.31%] [G loss: 4.566061]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 107 9 [D loss: 0.027220, acc: 98.44%] [G loss: 5.694786]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 107 10 [D loss: 0.007563, acc: 100.00%] [G loss: 6.711143]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 107 11 [D loss: 0.007370, acc: 100.00%] [G loss: 7.914362]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 107 12 [D loss: 0.043481, acc: 98.44%] [G loss: 8.413912]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 107 13 [D loss: 0.023153, acc: 98.44%] [G loss: 7.258981]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 107 14 [D loss: 0.007352, acc: 100.00%] [G loss: 6.452039]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 107 15 [D loss: 0.029832, acc: 98.44%] [G loss: 6.810961]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 107 16 [D loss: 0.004364, acc: 100.00%] [G loss: 6.180926]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 107 17 [D loss: 0.040837, acc: 98.44%] [G loss: 6.372286]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 107 18 [D loss: 0.008123, acc: 100.00%] [G loss: 6.556549]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 107 19 [D loss: 0.011765, acc: 100.00%] [G loss: 5.834208]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 107 20 [D loss: 0.077516, acc: 96.88%] [G loss: 5.430674]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 107 21 [D loss: 0.161093, acc: 96.88%] [G loss: 5.146305]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 107 22 [D loss: 0.065462, acc: 98.44%] [G loss: 5.942780]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 108 0 [D loss: 0.146872, acc: 95.31%] [G loss: 6.775935]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 108 1 [D loss: 0.021492, acc: 98.44%] [G loss: 7.417243]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 108 2 [D loss: 0.006815, acc: 100.00%] [G loss: 8.955648]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 108 3 [D loss: 0.062804, acc: 98.44%] [G loss: 8.086339]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 108 4 [D loss: 0.005262, acc: 100.00%] [G loss: 7.434672]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 108 5 [D loss: 0.010985, acc: 100.00%] [G loss: 6.755572]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 108 6 [D loss: 0.019160, acc: 100.00%] [G loss: 5.727854]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 108 7 [D loss: 0.047930, acc: 96.88%] [G loss: 6.141607]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 108 8 [D loss: 0.035379, acc: 98.44%] [G loss: 8.262604]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 108 9 [D loss: 0.020246, acc: 98.44%] [G loss: 7.280893]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 108 10 [D loss: 0.012769, acc: 100.00%] [G loss: 7.274108]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 108 11 [D loss: 0.015465, acc: 100.00%] [G loss: 7.840828]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 108 12 [D loss: 0.074946, acc: 95.31%] [G loss: 6.100136]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 108 13 [D loss: 0.172753, acc: 92.19%] [G loss: 6.132334]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 108 14 [D loss: 0.026921, acc: 98.44%] [G loss: 8.803835]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 108 15 [D loss: 0.000265, acc: 100.00%] [G loss: 10.384385]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 108 16 [D loss: 0.079165, acc: 98.44%] [G loss: 12.534613]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 108 17 [D loss: 0.065449, acc: 98.44%] [G loss: 10.204832]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 108 18 [D loss: 0.099515, acc: 96.88%] [G loss: 10.459285]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 108 19 [D loss: 0.000317, acc: 100.00%] [G loss: 13.712791]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 108 20 [D loss: 0.004742, acc: 100.00%] [G loss: 14.914850]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 108 21 [D loss: 0.050779, acc: 96.88%] [G loss: 15.873912]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 108 22 [D loss: 0.012782, acc: 100.00%] [G loss: 14.032421]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 109 0 [D loss: 0.021152, acc: 98.44%] [G loss: 10.685232]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 109 1 [D loss: 0.029029, acc: 96.88%] [G loss: 7.775208]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 109 2 [D loss: 0.055686, acc: 98.44%] [G loss: 7.049490]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 109 3 [D loss: 0.009536, acc: 100.00%] [G loss: 8.373098]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 109 4 [D loss: 0.004424, acc: 100.00%] [G loss: 9.298355]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 109 5 [D loss: 0.000725, acc: 100.00%] [G loss: 10.002984]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 109 6 [D loss: 0.000311, acc: 100.00%] [G loss: 11.036995]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 109 7 [D loss: 0.001122, acc: 100.00%] [G loss: 11.692335]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 109 8 [D loss: 0.003556, acc: 100.00%] [G loss: 10.536213]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 109 9 [D loss: 0.000686, acc: 100.00%] [G loss: 10.309359]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 109 10 [D loss: 0.003484, acc: 100.00%] [G loss: 9.012630]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 109 11 [D loss: 0.001569, acc: 100.00%] [G loss: 7.740966]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 109 12 [D loss: 0.009409, acc: 100.00%] [G loss: 7.487451]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 109 13 [D loss: 0.016620, acc: 98.44%] [G loss: 8.074393]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 109 14 [D loss: 0.002475, acc: 100.00%] [G loss: 9.144968]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 109 15 [D loss: 0.001121, acc: 100.00%] [G loss: 10.082817]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 109 16 [D loss: 0.000470, acc: 100.00%] [G loss: 10.911813]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 109 17 [D loss: 0.107762, acc: 96.88%] [G loss: 9.514698]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 109 18 [D loss: 0.010872, acc: 100.00%] [G loss: 8.020514]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 109 19 [D loss: 0.004023, acc: 100.00%] [G loss: 6.720459]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 109 20 [D loss: 0.006622, acc: 100.00%] [G loss: 4.877910]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 109 21 [D loss: 0.014159, acc: 100.00%] [G loss: 6.109294]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 109 22 [D loss: 0.009283, acc: 100.00%] [G loss: 7.535429]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 110 0 [D loss: 0.001376, acc: 100.00%] [G loss: 9.997749]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 110 1 [D loss: 0.000276, acc: 100.00%] [G loss: 11.308033]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 110 2 [D loss: 0.003088, acc: 100.00%] [G loss: 12.207382]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 110 3 [D loss: 0.000140, acc: 100.00%] [G loss: 12.499168]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 110 4 [D loss: 0.028511, acc: 98.44%] [G loss: 11.763868]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 110 5 [D loss: 0.005516, acc: 100.00%] [G loss: 9.650544]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 110 6 [D loss: 0.015411, acc: 100.00%] [G loss: 8.887765]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 110 7 [D loss: 0.004241, acc: 100.00%] [G loss: 8.545805]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 110 8 [D loss: 0.001767, acc: 100.00%] [G loss: 8.652821]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 110 9 [D loss: 0.002335, acc: 100.00%] [G loss: 7.363077]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 110 10 [D loss: 0.009740, acc: 100.00%] [G loss: 8.014090]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 110 11 [D loss: 0.012082, acc: 100.00%] [G loss: 8.370764]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 110 12 [D loss: 0.010031, acc: 100.00%] [G loss: 9.131624]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 110 13 [D loss: 0.013274, acc: 100.00%] [G loss: 8.919909]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 110 14 [D loss: 0.047716, acc: 98.44%] [G loss: 7.850195]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 110 15 [D loss: 0.008221, acc: 100.00%] [G loss: 7.140149]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 110 16 [D loss: 0.003108, acc: 100.00%] [G loss: 6.082754]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 110 17 [D loss: 0.006466, acc: 100.00%] [G loss: 5.873008]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 110 18 [D loss: 0.013905, acc: 100.00%] [G loss: 6.181041]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 110 19 [D loss: 0.022730, acc: 98.44%] [G loss: 6.595650]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 110 20 [D loss: 0.009041, acc: 100.00%] [G loss: 6.833841]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 110 21 [D loss: 0.001453, acc: 100.00%] [G loss: 7.479275]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 110 22 [D loss: 0.018503, acc: 100.00%] [G loss: 6.840456]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 111 0 [D loss: 0.015583, acc: 100.00%] [G loss: 5.682967]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 111 1 [D loss: 0.009374, acc: 100.00%] [G loss: 5.668096]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 111 2 [D loss: 0.007447, acc: 100.00%] [G loss: 6.010778]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 111 3 [D loss: 0.004489, acc: 100.00%] [G loss: 6.626367]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 111 4 [D loss: 0.057379, acc: 96.88%] [G loss: 5.834867]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 111 5 [D loss: 0.009565, acc: 100.00%] [G loss: 5.576707]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 111 6 [D loss: 0.004036, acc: 100.00%] [G loss: 5.723910]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 111 7 [D loss: 0.006772, acc: 100.00%] [G loss: 6.046871]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 111 8 [D loss: 0.004818, acc: 100.00%] [G loss: 6.991993]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 111 9 [D loss: 0.000909, acc: 100.00%] [G loss: 7.740318]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 111 10 [D loss: 0.017027, acc: 98.44%] [G loss: 6.329371]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 111 11 [D loss: 0.040425, acc: 98.44%] [G loss: 4.439307]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 111 12 [D loss: 0.007384, acc: 100.00%] [G loss: 5.921671]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 111 13 [D loss: 0.010743, acc: 100.00%] [G loss: 6.575648]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 111 14 [D loss: 0.015625, acc: 100.00%] [G loss: 6.674836]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 111 15 [D loss: 0.004673, acc: 100.00%] [G loss: 7.939327]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 111 16 [D loss: 0.001646, acc: 100.00%] [G loss: 8.993578]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 111 17 [D loss: 0.000193, acc: 100.00%] [G loss: 10.643292]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 111 18 [D loss: 0.005634, acc: 100.00%] [G loss: 9.412775]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 111 19 [D loss: 0.080527, acc: 96.88%] [G loss: 5.621344]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 111 20 [D loss: 0.161520, acc: 92.19%] [G loss: 10.738772]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 111 21 [D loss: 0.024082, acc: 98.44%] [G loss: 19.847334]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 111 22 [D loss: 0.364324, acc: 92.19%] [G loss: 17.435295]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 112 0 [D loss: 0.039782, acc: 98.44%] [G loss: 13.146954]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 112 1 [D loss: 0.001240, acc: 100.00%] [G loss: 10.752903]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 112 2 [D loss: 0.002344, acc: 100.00%] [G loss: 8.191863]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 112 3 [D loss: 0.103217, acc: 96.88%] [G loss: 8.479494]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 112 4 [D loss: 0.011518, acc: 100.00%] [G loss: 10.232262]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 112 5 [D loss: 0.000162, acc: 100.00%] [G loss: 13.420595]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 112 6 [D loss: 0.003462, acc: 100.00%] [G loss: 12.482309]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 112 7 [D loss: 0.062103, acc: 98.44%] [G loss: 11.289572]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 112 8 [D loss: 0.001681, acc: 100.00%] [G loss: 9.913879]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 112 9 [D loss: 0.017090, acc: 100.00%] [G loss: 8.135685]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 112 10 [D loss: 0.030601, acc: 98.44%] [G loss: 7.575522]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 112 11 [D loss: 0.006016, acc: 100.00%] [G loss: 7.243501]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 112 12 [D loss: 0.119542, acc: 95.31%] [G loss: 10.043285]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 112 13 [D loss: 0.036410, acc: 98.44%] [G loss: 12.041756]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 112 14 [D loss: 0.026342, acc: 98.44%] [G loss: 13.664185]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 112 15 [D loss: 0.098060, acc: 95.31%] [G loss: 11.451187]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 112 16 [D loss: 0.019847, acc: 98.44%] [G loss: 10.043435]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 112 17 [D loss: 0.013041, acc: 100.00%] [G loss: 7.509792]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 112 18 [D loss: 0.028401, acc: 98.44%] [G loss: 8.427727]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 112 19 [D loss: 0.142546, acc: 98.44%] [G loss: 6.174008]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 112 20 [D loss: 0.024575, acc: 100.00%] [G loss: 6.191108]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 112 21 [D loss: 0.026029, acc: 98.44%] [G loss: 8.281014]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 112 22 [D loss: 0.008759, acc: 100.00%] [G loss: 10.193096]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 113 0 [D loss: 0.022430, acc: 100.00%] [G loss: 12.455406]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 113 1 [D loss: 0.294197, acc: 92.19%] [G loss: 15.211861]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 113 2 [D loss: 0.153685, acc: 93.75%] [G loss: 17.647835]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 113 3 [D loss: 0.034712, acc: 98.44%] [G loss: 16.819016]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 113 4 [D loss: 0.069777, acc: 96.88%] [G loss: 14.156298]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 113 5 [D loss: 0.178025, acc: 96.88%] [G loss: 10.810799]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 113 6 [D loss: 0.090632, acc: 98.44%] [G loss: 7.133763]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 113 7 [D loss: 0.027426, acc: 100.00%] [G loss: 5.348969]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 113 8 [D loss: 0.068655, acc: 98.44%] [G loss: 7.468231]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 113 9 [D loss: 0.002095, acc: 100.00%] [G loss: 9.860189]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 113 10 [D loss: 0.024985, acc: 98.44%] [G loss: 11.453300]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 113 11 [D loss: 0.000143, acc: 100.00%] [G loss: 13.209201]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 113 12 [D loss: 0.000179, acc: 100.00%] [G loss: 13.912745]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 113 13 [D loss: 0.000125, acc: 100.00%] [G loss: 13.161844]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 113 14 [D loss: 0.000425, acc: 100.00%] [G loss: 13.048124]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 113 15 [D loss: 0.000710, acc: 100.00%] [G loss: 11.674566]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 113 16 [D loss: 0.001753, acc: 100.00%] [G loss: 11.401560]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 113 17 [D loss: 0.002567, acc: 100.00%] [G loss: 9.278097]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 113 18 [D loss: 0.015855, acc: 100.00%] [G loss: 8.324708]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 113 19 [D loss: 0.092914, acc: 96.88%] [G loss: 6.085316]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 113 20 [D loss: 0.150073, acc: 90.62%] [G loss: 9.412116]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 113 21 [D loss: 0.031881, acc: 96.88%] [G loss: 13.949446]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 113 22 [D loss: 0.199918, acc: 95.31%] [G loss: 15.887316]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 114 0 [D loss: 0.204374, acc: 95.31%] [G loss: 10.332117]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 114 1 [D loss: 0.222075, acc: 92.19%] [G loss: 8.325651]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 114 2 [D loss: 0.056044, acc: 96.88%] [G loss: 6.369853]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 114 3 [D loss: 0.082239, acc: 96.88%] [G loss: 8.415801]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 114 4 [D loss: 0.287851, acc: 95.31%] [G loss: 7.382638]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 114 5 [D loss: 0.011264, acc: 100.00%] [G loss: 6.281778]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 114 6 [D loss: 0.036788, acc: 100.00%] [G loss: 6.758974]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 114 7 [D loss: 0.096017, acc: 98.44%] [G loss: 5.467843]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 114 8 [D loss: 0.088042, acc: 96.88%] [G loss: 5.099605]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 114 9 [D loss: 0.024775, acc: 100.00%] [G loss: 6.989917]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 114 10 [D loss: 0.086405, acc: 95.31%] [G loss: 7.826613]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 114 11 [D loss: 0.062690, acc: 98.44%] [G loss: 7.935529]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 114 12 [D loss: 0.044660, acc: 96.88%] [G loss: 6.701544]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 114 13 [D loss: 0.015635, acc: 100.00%] [G loss: 5.551950]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 114 14 [D loss: 0.120504, acc: 96.88%] [G loss: 6.311798]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 114 15 [D loss: 0.012503, acc: 100.00%] [G loss: 8.627024]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 114 16 [D loss: 0.016556, acc: 100.00%] [G loss: 10.274693]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 114 17 [D loss: 0.072823, acc: 98.44%] [G loss: 10.440718]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 114 18 [D loss: 0.032233, acc: 98.44%] [G loss: 6.860912]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 114 19 [D loss: 0.142617, acc: 95.31%] [G loss: 5.892941]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 114 20 [D loss: 0.121320, acc: 98.44%] [G loss: 8.138006]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 114 21 [D loss: 0.005331, acc: 100.00%] [G loss: 11.372032]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 114 22 [D loss: 0.032491, acc: 100.00%] [G loss: 12.082863]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 115 0 [D loss: 0.146313, acc: 96.88%] [G loss: 9.010776]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 115 1 [D loss: 0.009373, acc: 100.00%] [G loss: 7.426381]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 115 2 [D loss: 0.062026, acc: 96.88%] [G loss: 6.881238]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 115 3 [D loss: 0.010129, acc: 100.00%] [G loss: 10.724251]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 115 4 [D loss: 0.024505, acc: 98.44%] [G loss: 11.797835]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 115 5 [D loss: 0.001714, acc: 100.00%] [G loss: 13.381348]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 115 6 [D loss: 0.001054, acc: 100.00%] [G loss: 15.304441]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 115 7 [D loss: 0.018830, acc: 98.44%] [G loss: 14.824903]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 115 8 [D loss: 0.003554, acc: 100.00%] [G loss: 14.979486]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 115 9 [D loss: 0.001194, acc: 100.00%] [G loss: 12.322540]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 115 10 [D loss: 0.000979, acc: 100.00%] [G loss: 12.905030]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 115 11 [D loss: 0.017581, acc: 98.44%] [G loss: 10.825973]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 115 12 [D loss: 0.002690, acc: 100.00%] [G loss: 8.027536]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 115 13 [D loss: 0.019543, acc: 98.44%] [G loss: 6.367874]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 115 14 [D loss: 0.013935, acc: 100.00%] [G loss: 6.702421]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 115 15 [D loss: 0.004519, acc: 100.00%] [G loss: 7.268617]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 115 16 [D loss: 0.007088, acc: 100.00%] [G loss: 7.253776]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 115 17 [D loss: 0.008452, acc: 100.00%] [G loss: 7.837044]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 115 18 [D loss: 0.007628, acc: 100.00%] [G loss: 9.145302]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 115 19 [D loss: 0.007157, acc: 100.00%] [G loss: 8.123234]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 115 20 [D loss: 0.107633, acc: 98.44%] [G loss: 5.682221]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 115 21 [D loss: 0.019085, acc: 100.00%] [G loss: 4.963587]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 115 22 [D loss: 0.023725, acc: 100.00%] [G loss: 5.795887]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 116 0 [D loss: 0.048721, acc: 98.44%] [G loss: 6.453234]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 116 1 [D loss: 0.037165, acc: 100.00%] [G loss: 6.481150]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 116 2 [D loss: 0.056703, acc: 98.44%] [G loss: 5.006129]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 116 3 [D loss: 0.072024, acc: 96.88%] [G loss: 6.911528]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 116 4 [D loss: 0.081037, acc: 98.44%] [G loss: 7.878918]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "******* 116 5 [D loss: 0.016627, acc: 100.00%] [G loss: 9.783939]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 116 6 [D loss: 0.052808, acc: 95.31%] [G loss: 9.584706]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 116 7 [D loss: 0.025581, acc: 98.44%] [G loss: 9.112006]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 116 8 [D loss: 0.007726, acc: 100.00%] [G loss: 9.782307]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 116 9 [D loss: 0.012063, acc: 100.00%] [G loss: 11.398315]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 116 10 [D loss: 0.005051, acc: 100.00%] [G loss: 10.053149]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "******* 116 11 [D loss: 0.001713, acc: 100.00%] [G loss: 11.604458]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 116 12 [D loss: 0.034539, acc: 98.44%] [G loss: 8.067955]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 116 13 [D loss: 0.049016, acc: 96.88%] [G loss: 9.084808]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "******* 116 14 [D loss: 0.020370, acc: 100.00%] [G loss: 9.487267]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 116 15 [D loss: 0.005712, acc: 100.00%] [G loss: 7.811119]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 116 16 [D loss: 0.007096, acc: 100.00%] [G loss: 9.492085]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 116 17 [D loss: 0.054315, acc: 96.88%] [G loss: 7.570981]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 116 18 [D loss: 0.061341, acc: 98.44%] [G loss: 7.127908]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 116 19 [D loss: 0.078053, acc: 95.31%] [G loss: 6.863610]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 116 20 [D loss: 0.028551, acc: 100.00%] [G loss: 6.519765]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 116 21 [D loss: 0.025180, acc: 100.00%] [G loss: 7.257505]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 116 22 [D loss: 0.041975, acc: 98.44%] [G loss: 7.726665]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 117 0 [D loss: 0.017329, acc: 100.00%] [G loss: 8.649027]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 117 1 [D loss: 0.081704, acc: 96.88%] [G loss: 6.592336]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 117 2 [D loss: 0.013259, acc: 100.00%] [G loss: 5.354901]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 117 3 [D loss: 0.033064, acc: 100.00%] [G loss: 5.359457]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 117 4 [D loss: 0.010265, acc: 100.00%] [G loss: 6.937122]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 117 5 [D loss: 0.006507, acc: 100.00%] [G loss: 7.141289]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 117 6 [D loss: 0.052342, acc: 98.44%] [G loss: 6.843877]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 117 7 [D loss: 0.008499, acc: 100.00%] [G loss: 6.966285]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 117 8 [D loss: 0.008685, acc: 100.00%] [G loss: 5.877948]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 117 9 [D loss: 0.008117, acc: 100.00%] [G loss: 5.688322]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 117 10 [D loss: 0.012717, acc: 100.00%] [G loss: 5.956481]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 117 11 [D loss: 0.006063, acc: 100.00%] [G loss: 6.767588]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 117 12 [D loss: 0.002702, acc: 100.00%] [G loss: 6.714874]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 117 13 [D loss: 0.001319, acc: 100.00%] [G loss: 6.799143]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 117 14 [D loss: 0.015839, acc: 98.44%] [G loss: 7.395369]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 117 15 [D loss: 0.015108, acc: 100.00%] [G loss: 6.726027]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 117 16 [D loss: 0.019569, acc: 100.00%] [G loss: 5.450679]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 117 17 [D loss: 0.035973, acc: 98.44%] [G loss: 6.098632]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 117 18 [D loss: 0.066192, acc: 98.44%] [G loss: 3.858344]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 117 19 [D loss: 0.089858, acc: 95.31%] [G loss: 6.003161]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 117 20 [D loss: 0.011481, acc: 100.00%] [G loss: 9.385000]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 117 21 [D loss: 0.016783, acc: 100.00%] [G loss: 11.234953]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 117 22 [D loss: 0.208301, acc: 92.19%] [G loss: 6.607025]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 118 0 [D loss: 0.133613, acc: 92.19%] [G loss: 5.993360]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 118 1 [D loss: 0.004967, acc: 100.00%] [G loss: 8.606133]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 118 2 [D loss: 0.003074, acc: 100.00%] [G loss: 10.126720]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 118 3 [D loss: 0.011509, acc: 100.00%] [G loss: 10.907452]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 118 4 [D loss: 0.006946, acc: 100.00%] [G loss: 10.534712]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 118 5 [D loss: 0.000446, acc: 100.00%] [G loss: 10.588809]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 118 6 [D loss: 0.002308, acc: 100.00%] [G loss: 9.330782]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 118 7 [D loss: 0.001507, acc: 100.00%] [G loss: 8.522190]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 118 8 [D loss: 0.002065, acc: 100.00%] [G loss: 7.772191]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 118 9 [D loss: 0.002150, acc: 100.00%] [G loss: 7.193465]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 118 10 [D loss: 0.004082, acc: 100.00%] [G loss: 6.779273]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 118 11 [D loss: 0.004424, acc: 100.00%] [G loss: 5.813642]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 118 12 [D loss: 0.003235, acc: 100.00%] [G loss: 6.056142]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 118 13 [D loss: 0.004196, acc: 100.00%] [G loss: 6.469722]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 118 14 [D loss: 0.014506, acc: 100.00%] [G loss: 7.766234]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 118 15 [D loss: 0.025708, acc: 100.00%] [G loss: 8.484198]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 118 16 [D loss: 0.002937, acc: 100.00%] [G loss: 9.321974]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 118 17 [D loss: 0.011292, acc: 100.00%] [G loss: 9.454537]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 118 18 [D loss: 0.091851, acc: 96.88%] [G loss: 5.526705]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 118 19 [D loss: 0.074635, acc: 98.44%] [G loss: 5.655826]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 118 20 [D loss: 0.007304, acc: 100.00%] [G loss: 9.316740]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 118 21 [D loss: 0.021011, acc: 100.00%] [G loss: 10.778925]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 118 22 [D loss: 0.089589, acc: 96.88%] [G loss: 7.608434]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 119 0 [D loss: 0.044091, acc: 100.00%] [G loss: 4.771269]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 119 1 [D loss: 0.068512, acc: 96.88%] [G loss: 6.366071]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "******* 119 2 [D loss: 0.032812, acc: 96.88%] [G loss: 7.950217]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 119 3 [D loss: 0.030270, acc: 98.44%] [G loss: 9.343924]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 119 4 [D loss: 0.008917, acc: 100.00%] [G loss: 9.851844]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 119 5 [D loss: 0.032604, acc: 98.44%] [G loss: 8.756847]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 119 6 [D loss: 0.028395, acc: 98.44%] [G loss: 6.957752]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 119 7 [D loss: 0.034719, acc: 98.44%] [G loss: 6.660934]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 119 8 [D loss: 0.035971, acc: 98.44%] [G loss: 8.116758]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 119 9 [D loss: 0.014163, acc: 100.00%] [G loss: 10.488661]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 119 10 [D loss: 0.034342, acc: 98.44%] [G loss: 9.453692]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 119 11 [D loss: 0.016973, acc: 98.44%] [G loss: 9.868601]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 119 12 [D loss: 0.075117, acc: 96.88%] [G loss: 11.324492]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 119 13 [D loss: 0.009985, acc: 100.00%] [G loss: 15.331707]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 119 14 [D loss: 0.119015, acc: 95.31%] [G loss: 15.055494]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 119 15 [D loss: 0.002188, acc: 100.00%] [G loss: 13.793818]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 119 16 [D loss: 0.078740, acc: 98.44%] [G loss: 11.061205]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 119 17 [D loss: 0.033513, acc: 98.44%] [G loss: 9.882024]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 119 18 [D loss: 0.044255, acc: 98.44%] [G loss: 9.845974]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 119 19 [D loss: 0.003271, acc: 100.00%] [G loss: 14.579868]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 119 20 [D loss: 0.060584, acc: 98.44%] [G loss: 16.773901]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 119 21 [D loss: 0.048244, acc: 96.88%] [G loss: 14.992788]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 119 22 [D loss: 0.051795, acc: 95.31%] [G loss: 10.775780]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 120 0 [D loss: 0.107577, acc: 96.88%] [G loss: 12.286489]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 120 1 [D loss: 0.065650, acc: 98.44%] [G loss: 8.982469]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 120 2 [D loss: 0.021088, acc: 100.00%] [G loss: 6.337412]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 120 3 [D loss: 0.161542, acc: 92.19%] [G loss: 10.728758]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 120 4 [D loss: 0.117426, acc: 95.31%] [G loss: 13.577644]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 120 5 [D loss: 0.153002, acc: 92.19%] [G loss: 12.508497]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 120 6 [D loss: 0.056368, acc: 98.44%] [G loss: 8.095248]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 120 7 [D loss: 0.114709, acc: 96.88%] [G loss: 9.237061]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 120 8 [D loss: 0.017971, acc: 98.44%] [G loss: 11.362154]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 120 9 [D loss: 0.016963, acc: 98.44%] [G loss: 10.883082]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 120 10 [D loss: 0.002235, acc: 100.00%] [G loss: 11.131729]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 120 11 [D loss: 0.001712, acc: 100.00%] [G loss: 9.204599]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 120 12 [D loss: 0.002696, acc: 100.00%] [G loss: 8.176725]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 120 13 [D loss: 0.010676, acc: 100.00%] [G loss: 7.203092]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 120 14 [D loss: 0.014922, acc: 100.00%] [G loss: 7.397576]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 120 15 [D loss: 0.034920, acc: 98.44%] [G loss: 9.286693]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 120 16 [D loss: 0.082198, acc: 96.88%] [G loss: 9.172297]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 120 17 [D loss: 0.016211, acc: 100.00%] [G loss: 10.811165]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 120 18 [D loss: 0.012105, acc: 100.00%] [G loss: 10.189125]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 120 19 [D loss: 0.065943, acc: 95.31%] [G loss: 7.737876]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 120 20 [D loss: 0.119102, acc: 95.31%] [G loss: 10.696068]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 120 21 [D loss: 0.000448, acc: 100.00%] [G loss: 16.831211]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 120 22 [D loss: 0.013943, acc: 100.00%] [G loss: 21.667660]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 121 0 [D loss: 0.216388, acc: 90.62%] [G loss: 18.001118]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 121 1 [D loss: 0.025679, acc: 98.44%] [G loss: 12.792523]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 121 2 [D loss: 0.002286, acc: 100.00%] [G loss: 10.264618]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 121 3 [D loss: 0.037040, acc: 98.44%] [G loss: 9.199352]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 121 4 [D loss: 0.015641, acc: 100.00%] [G loss: 10.339012]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 121 5 [D loss: 0.045199, acc: 98.44%] [G loss: 12.118509]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 121 6 [D loss: 0.005542, acc: 100.00%] [G loss: 13.307369]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 121 7 [D loss: 0.003237, acc: 100.00%] [G loss: 13.840802]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 121 8 [D loss: 0.007692, acc: 100.00%] [G loss: 12.019348]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 121 9 [D loss: 0.042893, acc: 98.44%] [G loss: 14.838748]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 121 10 [D loss: 0.081574, acc: 95.31%] [G loss: 13.158838]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 121 11 [D loss: 0.118469, acc: 96.88%] [G loss: 8.486153]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 121 12 [D loss: 0.106203, acc: 93.75%] [G loss: 11.628374]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 121 13 [D loss: 0.004574, acc: 100.00%] [G loss: 13.711512]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 121 14 [D loss: 0.060260, acc: 93.75%] [G loss: 12.898806]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 121 15 [D loss: 0.068490, acc: 96.88%] [G loss: 9.949839]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 121 16 [D loss: 0.061423, acc: 98.44%] [G loss: 7.230547]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 121 17 [D loss: 0.101114, acc: 96.88%] [G loss: 9.852873]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 121 18 [D loss: 0.034585, acc: 98.44%] [G loss: 13.060994]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "******* 121 19 [D loss: 0.062956, acc: 96.88%] [G loss: 13.294309]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 121 20 [D loss: 0.169321, acc: 93.75%] [G loss: 11.442968]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 121 21 [D loss: 0.223480, acc: 96.88%] [G loss: 5.963743]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 121 22 [D loss: 0.059673, acc: 98.44%] [G loss: 8.010876]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 122 0 [D loss: 0.031274, acc: 98.44%] [G loss: 11.978325]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 122 1 [D loss: 0.012932, acc: 100.00%] [G loss: 15.360706]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 122 2 [D loss: 0.008631, acc: 100.00%] [G loss: 19.594698]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 122 3 [D loss: 0.087700, acc: 96.88%] [G loss: 20.314650]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 122 4 [D loss: 0.015102, acc: 100.00%] [G loss: 20.514637]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 122 5 [D loss: 0.004061, acc: 100.00%] [G loss: 19.102457]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 122 6 [D loss: 0.003955, acc: 100.00%] [G loss: 16.303232]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 122 7 [D loss: 0.003553, acc: 100.00%] [G loss: 15.390679]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 122 8 [D loss: 0.011546, acc: 100.00%] [G loss: 15.738148]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 122 9 [D loss: 0.001047, acc: 100.00%] [G loss: 10.622972]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 122 10 [D loss: 0.008539, acc: 100.00%] [G loss: 9.130520]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 122 11 [D loss: 0.022221, acc: 98.44%] [G loss: 7.166686]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 122 12 [D loss: 0.027991, acc: 98.44%] [G loss: 8.842335]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 122 13 [D loss: 0.009536, acc: 100.00%] [G loss: 8.890202]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 122 14 [D loss: 0.007769, acc: 100.00%] [G loss: 10.107198]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 122 15 [D loss: 0.051751, acc: 96.88%] [G loss: 8.321026]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 122 16 [D loss: 0.148781, acc: 93.75%] [G loss: 4.627598]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 122 17 [D loss: 0.314419, acc: 90.62%] [G loss: 7.304111]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 122 18 [D loss: 0.007991, acc: 100.00%] [G loss: 13.052520]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 122 19 [D loss: 0.039770, acc: 98.44%] [G loss: 16.863882]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "******* 122 20 [D loss: 0.138329, acc: 95.31%] [G loss: 15.496386]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 122 21 [D loss: 0.168334, acc: 92.19%] [G loss: 9.275328]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 122 22 [D loss: 0.044565, acc: 96.88%] [G loss: 5.400684]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 123 0 [D loss: 0.075172, acc: 96.88%] [G loss: 4.759563]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 123 1 [D loss: 0.120028, acc: 95.31%] [G loss: 9.698157]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 123 2 [D loss: 0.000086, acc: 100.00%] [G loss: 14.417137]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 123 3 [D loss: 0.002749, acc: 100.00%] [G loss: 19.255981]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 123 4 [D loss: 0.110001, acc: 95.31%] [G loss: 18.887018]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 123 5 [D loss: 0.000038, acc: 100.00%] [G loss: 17.138186]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 123 6 [D loss: 0.001102, acc: 100.00%] [G loss: 16.133205]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 123 7 [D loss: 0.013757, acc: 100.00%] [G loss: 14.927253]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 123 8 [D loss: 0.015669, acc: 100.00%] [G loss: 14.656004]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 123 9 [D loss: 0.017046, acc: 98.44%] [G loss: 11.498578]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 123 10 [D loss: 0.102937, acc: 93.75%] [G loss: 15.640810]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 123 11 [D loss: 0.072444, acc: 98.44%] [G loss: 15.947157]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 123 12 [D loss: 0.005368, acc: 100.00%] [G loss: 16.740625]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 123 13 [D loss: 0.210513, acc: 92.19%] [G loss: 10.752198]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 123 14 [D loss: 0.010867, acc: 100.00%] [G loss: 9.440660]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 123 15 [D loss: 0.044423, acc: 98.44%] [G loss: 7.725674]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 123 16 [D loss: 0.100956, acc: 95.31%] [G loss: 10.685053]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 123 17 [D loss: 0.107090, acc: 98.44%] [G loss: 12.055901]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 123 18 [D loss: 0.013586, acc: 100.00%] [G loss: 13.108040]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 123 19 [D loss: 0.082705, acc: 96.88%] [G loss: 10.994234]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "******* 123 20 [D loss: 0.044412, acc: 96.88%] [G loss: 6.730711]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 123 21 [D loss: 0.468743, acc: 79.69%] [G loss: 13.254198]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 123 22 [D loss: 0.284212, acc: 90.62%] [G loss: 17.608788]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 124 0 [D loss: 0.412754, acc: 85.94%] [G loss: 14.919463]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 124 1 [D loss: 0.042990, acc: 96.88%] [G loss: 9.371139]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 124 2 [D loss: 0.011696, acc: 100.00%] [G loss: 4.419010]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 124 3 [D loss: 0.236813, acc: 89.06%] [G loss: 6.184911]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 124 4 [D loss: 0.000876, acc: 100.00%] [G loss: 14.192566]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 124 5 [D loss: 0.000080, acc: 100.00%] [G loss: 18.618664]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 124 6 [D loss: 0.005911, acc: 100.00%] [G loss: 22.292614]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 124 7 [D loss: 0.030258, acc: 98.44%] [G loss: 22.266426]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 124 8 [D loss: 0.000177, acc: 100.00%] [G loss: 23.934504]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 124 9 [D loss: 0.090880, acc: 98.44%] [G loss: 21.184198]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 124 10 [D loss: 0.000226, acc: 100.00%] [G loss: 21.093699]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 124 11 [D loss: 0.023251, acc: 98.44%] [G loss: 18.319180]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 124 12 [D loss: 0.015396, acc: 98.44%] [G loss: 15.556572]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 124 13 [D loss: 0.009663, acc: 100.00%] [G loss: 12.641731]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 124 14 [D loss: 0.022725, acc: 98.44%] [G loss: 12.132745]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 124 15 [D loss: 0.195786, acc: 95.31%] [G loss: 9.558279]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 124 16 [D loss: 0.072555, acc: 98.44%] [G loss: 15.961916]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 124 17 [D loss: 0.001357, acc: 100.00%] [G loss: 14.445056]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 124 18 [D loss: 0.002337, acc: 100.00%] [G loss: 14.997978]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 124 19 [D loss: 0.060228, acc: 98.44%] [G loss: 12.533957]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 124 20 [D loss: 0.149402, acc: 96.88%] [G loss: 9.261845]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 124 21 [D loss: 0.016125, acc: 100.00%] [G loss: 7.195943]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 124 22 [D loss: 0.017400, acc: 100.00%] [G loss: 5.747204]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 125 0 [D loss: 0.030514, acc: 100.00%] [G loss: 6.217345]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 125 1 [D loss: 0.006719, acc: 100.00%] [G loss: 8.273493]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 125 2 [D loss: 0.106765, acc: 96.88%] [G loss: 8.163842]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 125 3 [D loss: 0.052107, acc: 98.44%] [G loss: 7.470935]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 125 4 [D loss: 0.037258, acc: 96.88%] [G loss: 7.218737]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 125 5 [D loss: 0.042419, acc: 98.44%] [G loss: 8.791025]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 125 6 [D loss: 0.010724, acc: 100.00%] [G loss: 10.143243]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 125 7 [D loss: 0.003487, acc: 100.00%] [G loss: 11.421583]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 125 8 [D loss: 0.047880, acc: 95.31%] [G loss: 8.735970]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 125 9 [D loss: 0.040400, acc: 98.44%] [G loss: 7.724413]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 125 10 [D loss: 0.139844, acc: 95.31%] [G loss: 6.565121]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 125 11 [D loss: 0.068491, acc: 96.88%] [G loss: 9.772797]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 125 12 [D loss: 0.033712, acc: 98.44%] [G loss: 10.859781]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 125 13 [D loss: 0.000558, acc: 100.00%] [G loss: 11.749835]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 125 14 [D loss: 0.001925, acc: 100.00%] [G loss: 12.161505]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 125 15 [D loss: 0.044403, acc: 98.44%] [G loss: 10.597930]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 125 16 [D loss: 0.003094, acc: 100.00%] [G loss: 9.662433]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 125 17 [D loss: 0.033906, acc: 98.44%] [G loss: 9.731121]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 125 18 [D loss: 0.018658, acc: 98.44%] [G loss: 9.220602]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 125 19 [D loss: 0.004786, acc: 100.00%] [G loss: 10.772823]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 125 20 [D loss: 0.007142, acc: 100.00%] [G loss: 8.713797]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 125 21 [D loss: 0.041810, acc: 96.88%] [G loss: 9.664250]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 125 22 [D loss: 0.021525, acc: 98.44%] [G loss: 9.305828]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 126 0 [D loss: 0.005875, acc: 100.00%] [G loss: 9.168530]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 126 1 [D loss: 0.013385, acc: 100.00%] [G loss: 10.281897]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 126 2 [D loss: 0.005062, acc: 100.00%] [G loss: 9.581871]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 126 3 [D loss: 0.153119, acc: 92.19%] [G loss: 9.542800]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 126 4 [D loss: 0.055943, acc: 96.88%] [G loss: 12.664930]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 126 5 [D loss: 0.180964, acc: 93.75%] [G loss: 12.056566]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 126 6 [D loss: 0.191375, acc: 96.88%] [G loss: 7.757274]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 126 7 [D loss: 0.074615, acc: 96.88%] [G loss: 6.087080]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 126 8 [D loss: 0.067447, acc: 96.88%] [G loss: 11.678951]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 126 9 [D loss: 0.045273, acc: 98.44%] [G loss: 16.305777]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 126 10 [D loss: 0.056452, acc: 98.44%] [G loss: 16.548561]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 126 11 [D loss: 0.020861, acc: 100.00%] [G loss: 14.988625]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 126 12 [D loss: 0.051221, acc: 98.44%] [G loss: 13.505079]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 126 13 [D loss: 0.000357, acc: 100.00%] [G loss: 8.003418]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 126 14 [D loss: 0.088559, acc: 96.88%] [G loss: 10.104503]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 126 15 [D loss: 0.001098, acc: 100.00%] [G loss: 12.071276]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 126 16 [D loss: 0.006201, acc: 100.00%] [G loss: 15.290785]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 126 17 [D loss: 0.002704, acc: 100.00%] [G loss: 14.647247]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 126 18 [D loss: 0.002544, acc: 100.00%] [G loss: 12.722952]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 126 19 [D loss: 0.027182, acc: 98.44%] [G loss: 10.345325]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 126 20 [D loss: 0.016190, acc: 100.00%] [G loss: 7.901577]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 126 21 [D loss: 0.125772, acc: 93.75%] [G loss: 11.629890]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 126 22 [D loss: 0.004629, acc: 100.00%] [G loss: 16.734863]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 127 0 [D loss: 0.130498, acc: 96.88%] [G loss: 15.156384]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 127 1 [D loss: 0.059815, acc: 98.44%] [G loss: 10.727162]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 127 2 [D loss: 0.036952, acc: 98.44%] [G loss: 7.200956]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 127 3 [D loss: 0.130760, acc: 93.75%] [G loss: 10.318231]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 127 4 [D loss: 0.039703, acc: 98.44%] [G loss: 16.171610]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 127 5 [D loss: 0.013823, acc: 98.44%] [G loss: 17.352476]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 127 6 [D loss: 0.141306, acc: 92.19%] [G loss: 14.694060]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 127 7 [D loss: 0.043350, acc: 98.44%] [G loss: 10.569309]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 127 8 [D loss: 0.153067, acc: 92.19%] [G loss: 8.883883]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 127 9 [D loss: 0.032347, acc: 98.44%] [G loss: 10.301508]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 127 10 [D loss: 0.000807, acc: 100.00%] [G loss: 10.781556]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 127 11 [D loss: 0.000634, acc: 100.00%] [G loss: 10.262405]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 127 12 [D loss: 0.002940, acc: 100.00%] [G loss: 10.635469]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "******* 127 13 [D loss: 0.010725, acc: 100.00%] [G loss: 9.319685]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 127 14 [D loss: 0.005540, acc: 100.00%] [G loss: 7.424337]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 127 15 [D loss: 0.003445, acc: 100.00%] [G loss: 7.118801]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 127 16 [D loss: 0.008139, acc: 100.00%] [G loss: 6.867041]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 127 17 [D loss: 0.010824, acc: 100.00%] [G loss: 6.794205]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 127 18 [D loss: 0.091599, acc: 95.31%] [G loss: 7.542045]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 127 19 [D loss: 0.007955, acc: 100.00%] [G loss: 10.035353]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 127 20 [D loss: 0.026344, acc: 98.44%] [G loss: 10.385925]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 127 21 [D loss: 0.027759, acc: 98.44%] [G loss: 8.345408]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 127 22 [D loss: 0.016720, acc: 100.00%] [G loss: 7.015679]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 128 0 [D loss: 0.028635, acc: 100.00%] [G loss: 5.583864]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 128 1 [D loss: 0.058129, acc: 96.88%] [G loss: 7.048848]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 128 2 [D loss: 0.019641, acc: 100.00%] [G loss: 9.090679]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 128 3 [D loss: 0.003507, acc: 100.00%] [G loss: 10.878078]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 128 4 [D loss: 0.058777, acc: 96.88%] [G loss: 8.870119]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 128 5 [D loss: 0.010699, acc: 100.00%] [G loss: 7.808796]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "******* 128 6 [D loss: 0.097799, acc: 95.31%] [G loss: 8.160263]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 128 7 [D loss: 0.028673, acc: 100.00%] [G loss: 9.319794]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 128 8 [D loss: 0.052669, acc: 96.88%] [G loss: 8.979485]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 128 9 [D loss: 0.056230, acc: 96.88%] [G loss: 8.266299]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 128 10 [D loss: 0.045392, acc: 98.44%] [G loss: 6.631397]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 128 11 [D loss: 0.005042, acc: 100.00%] [G loss: 8.776537]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 128 12 [D loss: 0.007132, acc: 100.00%] [G loss: 9.374975]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 128 13 [D loss: 0.002989, acc: 100.00%] [G loss: 9.666553]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 128 14 [D loss: 0.003937, acc: 100.00%] [G loss: 9.384791]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 128 15 [D loss: 0.029166, acc: 98.44%] [G loss: 8.031366]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 128 16 [D loss: 0.024271, acc: 98.44%] [G loss: 8.136599]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 128 17 [D loss: 0.063951, acc: 96.88%] [G loss: 9.434050]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 128 18 [D loss: 0.020090, acc: 98.44%] [G loss: 10.556135]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 128 19 [D loss: 0.006129, acc: 100.00%] [G loss: 11.330616]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 128 20 [D loss: 0.000902, acc: 100.00%] [G loss: 12.085920]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 128 21 [D loss: 0.004969, acc: 100.00%] [G loss: 10.717970]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 128 22 [D loss: 0.004145, acc: 100.00%] [G loss: 12.649826]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 129 0 [D loss: 0.000143, acc: 100.00%] [G loss: 10.901783]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 129 1 [D loss: 0.001115, acc: 100.00%] [G loss: 12.535240]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 129 2 [D loss: 0.013009, acc: 100.00%] [G loss: 9.771210]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 129 3 [D loss: 0.004806, acc: 100.00%] [G loss: 11.549906]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 129 4 [D loss: 0.076051, acc: 98.44%] [G loss: 10.659292]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 129 5 [D loss: 0.039212, acc: 98.44%] [G loss: 8.415186]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 129 6 [D loss: 0.013592, acc: 100.00%] [G loss: 9.067184]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 129 7 [D loss: 0.005944, acc: 100.00%] [G loss: 10.297230]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 129 8 [D loss: 0.048029, acc: 98.44%] [G loss: 10.514875]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 129 9 [D loss: 0.091884, acc: 95.31%] [G loss: 8.653885]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 129 10 [D loss: 0.010495, acc: 100.00%] [G loss: 9.672976]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 129 11 [D loss: 0.033692, acc: 98.44%] [G loss: 7.850826]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 129 12 [D loss: 0.307443, acc: 90.62%] [G loss: 10.924492]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 129 13 [D loss: 0.049815, acc: 96.88%] [G loss: 15.054034]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 129 14 [D loss: 0.186208, acc: 92.19%] [G loss: 9.627453]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 129 15 [D loss: 0.436860, acc: 85.94%] [G loss: 11.880537]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 129 16 [D loss: 0.019332, acc: 98.44%] [G loss: 18.988144]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 129 17 [D loss: 0.248627, acc: 96.88%] [G loss: 20.831924]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 129 18 [D loss: 0.063738, acc: 95.31%] [G loss: 19.374043]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 129 19 [D loss: 0.087268, acc: 96.88%] [G loss: 15.429749]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 129 20 [D loss: 0.000798, acc: 100.00%] [G loss: 10.019614]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 129 21 [D loss: 0.007243, acc: 100.00%] [G loss: 6.186077]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 129 22 [D loss: 0.158758, acc: 93.75%] [G loss: 7.496147]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 130 0 [D loss: 0.004243, acc: 100.00%] [G loss: 10.530201]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 130 1 [D loss: 0.000025, acc: 100.00%] [G loss: 14.309732]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 130 2 [D loss: 0.087178, acc: 98.44%] [G loss: 14.426838]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 130 3 [D loss: 0.059131, acc: 98.44%] [G loss: 13.156861]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 130 4 [D loss: 0.207423, acc: 95.31%] [G loss: 8.962711]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 130 5 [D loss: 0.018668, acc: 100.00%] [G loss: 5.537497]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 130 6 [D loss: 0.267321, acc: 93.75%] [G loss: 6.403485]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 130 7 [D loss: 0.056291, acc: 98.44%] [G loss: 10.468410]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 130 8 [D loss: 0.002259, acc: 100.00%] [G loss: 12.957436]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 130 9 [D loss: 0.039240, acc: 98.44%] [G loss: 15.326286]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 130 10 [D loss: 0.011134, acc: 100.00%] [G loss: 16.611473]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 130 11 [D loss: 0.101052, acc: 96.88%] [G loss: 13.917505]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 130 12 [D loss: 0.060524, acc: 96.88%] [G loss: 10.223376]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 130 13 [D loss: 0.054301, acc: 98.44%] [G loss: 6.608589]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 130 14 [D loss: 0.219917, acc: 90.62%] [G loss: 7.732392]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 130 15 [D loss: 0.071323, acc: 96.88%] [G loss: 12.708101]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 130 16 [D loss: 0.006363, acc: 100.00%] [G loss: 17.467289]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 130 17 [D loss: 0.166255, acc: 93.75%] [G loss: 17.629581]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 130 18 [D loss: 0.000098, acc: 100.00%] [G loss: 15.652942]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 130 19 [D loss: 0.002317, acc: 100.00%] [G loss: 13.047640]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 130 20 [D loss: 0.000133, acc: 100.00%] [G loss: 9.632090]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 130 21 [D loss: 0.005344, acc: 100.00%] [G loss: 8.808779]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 130 22 [D loss: 0.013901, acc: 100.00%] [G loss: 7.503299]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 131 0 [D loss: 0.005811, acc: 100.00%] [G loss: 9.182750]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 131 1 [D loss: 0.004141, acc: 100.00%] [G loss: 8.969784]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 131 2 [D loss: 0.003677, acc: 100.00%] [G loss: 9.592436]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 131 3 [D loss: 0.055740, acc: 98.44%] [G loss: 10.507992]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 131 4 [D loss: 0.001865, acc: 100.00%] [G loss: 11.930841]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 131 5 [D loss: 0.051056, acc: 98.44%] [G loss: 13.484918]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 131 6 [D loss: 0.013974, acc: 100.00%] [G loss: 11.265339]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 131 7 [D loss: 0.104413, acc: 98.44%] [G loss: 7.845017]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 131 8 [D loss: 0.085724, acc: 95.31%] [G loss: 7.437400]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 131 9 [D loss: 0.003268, acc: 100.00%] [G loss: 9.421803]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 131 10 [D loss: 0.001179, acc: 100.00%] [G loss: 11.129079]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 131 11 [D loss: 0.018889, acc: 98.44%] [G loss: 10.912525]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 131 12 [D loss: 0.051802, acc: 98.44%] [G loss: 7.308814]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 131 13 [D loss: 0.091737, acc: 93.75%] [G loss: 10.370234]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 131 14 [D loss: 0.043859, acc: 96.88%] [G loss: 15.576641]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 131 15 [D loss: 0.001523, acc: 100.00%] [G loss: 20.042391]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 131 16 [D loss: 0.020961, acc: 98.44%] [G loss: 14.463836]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 131 17 [D loss: 0.000694, acc: 100.00%] [G loss: 16.145971]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 131 18 [D loss: 0.008657, acc: 100.00%] [G loss: 12.390906]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 131 19 [D loss: 0.080429, acc: 95.31%] [G loss: 12.821129]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "******* 131 20 [D loss: 0.000359, acc: 100.00%] [G loss: 16.120796]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 131 21 [D loss: 0.063474, acc: 95.31%] [G loss: 14.022427]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "******* 131 22 [D loss: 0.027737, acc: 98.44%] [G loss: 12.064539]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 132 0 [D loss: 0.118063, acc: 93.75%] [G loss: 8.319428]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 132 1 [D loss: 0.102515, acc: 95.31%] [G loss: 8.905899]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 132 2 [D loss: 0.051307, acc: 98.44%] [G loss: 9.712658]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 132 3 [D loss: 0.009587, acc: 100.00%] [G loss: 10.984165]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 132 4 [D loss: 0.030570, acc: 100.00%] [G loss: 9.452085]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 132 5 [D loss: 0.183725, acc: 95.31%] [G loss: 8.033745]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 132 6 [D loss: 0.404191, acc: 90.62%] [G loss: 7.895685]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 132 7 [D loss: 0.005995, acc: 100.00%] [G loss: 10.528673]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 132 8 [D loss: 0.237961, acc: 95.31%] [G loss: 9.775385]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 132 9 [D loss: 0.182387, acc: 92.19%] [G loss: 7.438537]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 132 10 [D loss: 0.374003, acc: 89.06%] [G loss: 5.173002]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 132 11 [D loss: 0.077065, acc: 96.88%] [G loss: 8.848142]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 132 12 [D loss: 0.001823, acc: 100.00%] [G loss: 12.308071]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 132 13 [D loss: 0.104276, acc: 96.88%] [G loss: 12.692759]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 132 14 [D loss: 0.002360, acc: 100.00%] [G loss: 10.973143]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 132 15 [D loss: 0.018475, acc: 100.00%] [G loss: 10.789627]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 132 16 [D loss: 0.001436, acc: 100.00%] [G loss: 8.438747]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 132 17 [D loss: 0.002088, acc: 100.00%] [G loss: 8.660963]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 132 18 [D loss: 0.007318, acc: 100.00%] [G loss: 6.845163]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 132 19 [D loss: 0.087557, acc: 98.44%] [G loss: 7.334563]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 132 20 [D loss: 0.016712, acc: 100.00%] [G loss: 10.126041]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 132 21 [D loss: 0.009845, acc: 100.00%] [G loss: 11.054883]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 132 22 [D loss: 0.011722, acc: 100.00%] [G loss: 10.426798]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 133 0 [D loss: 0.009803, acc: 100.00%] [G loss: 10.734841]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 133 1 [D loss: 0.123319, acc: 96.88%] [G loss: 6.565783]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 133 2 [D loss: 0.028476, acc: 100.00%] [G loss: 4.941436]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 133 3 [D loss: 0.083353, acc: 95.31%] [G loss: 6.615579]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 133 4 [D loss: 0.027371, acc: 100.00%] [G loss: 10.590840]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 133 5 [D loss: 0.248575, acc: 92.19%] [G loss: 8.317747]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 133 6 [D loss: 0.055388, acc: 96.88%] [G loss: 6.956856]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 133 7 [D loss: 0.017382, acc: 100.00%] [G loss: 7.463961]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 133 8 [D loss: 0.014871, acc: 98.44%] [G loss: 9.147501]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 133 9 [D loss: 0.074070, acc: 98.44%] [G loss: 10.418034]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 133 10 [D loss: 0.024101, acc: 98.44%] [G loss: 8.412533]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 133 11 [D loss: 0.016740, acc: 98.44%] [G loss: 7.063134]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 133 12 [D loss: 0.004189, acc: 100.00%] [G loss: 5.799117]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 133 13 [D loss: 0.027660, acc: 98.44%] [G loss: 5.757463]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 133 14 [D loss: 0.026129, acc: 98.44%] [G loss: 8.383957]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 133 15 [D loss: 0.004228, acc: 100.00%] [G loss: 10.104212]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 133 16 [D loss: 0.001512, acc: 100.00%] [G loss: 11.905552]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 133 17 [D loss: 0.094836, acc: 96.88%] [G loss: 11.456264]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 133 18 [D loss: 0.083803, acc: 98.44%] [G loss: 10.262842]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 133 19 [D loss: 0.003218, acc: 100.00%] [G loss: 10.037139]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 133 20 [D loss: 0.004140, acc: 100.00%] [G loss: 8.641206]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 133 21 [D loss: 0.008285, acc: 100.00%] [G loss: 9.082619]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 133 22 [D loss: 0.023987, acc: 100.00%] [G loss: 8.000973]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 134 0 [D loss: 0.003820, acc: 100.00%] [G loss: 9.041659]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "******* 134 1 [D loss: 0.014661, acc: 100.00%] [G loss: 7.660255]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 134 2 [D loss: 0.022234, acc: 100.00%] [G loss: 8.230745]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 134 3 [D loss: 0.015269, acc: 100.00%] [G loss: 8.089456]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 134 4 [D loss: 0.117099, acc: 95.31%] [G loss: 8.481126]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 134 5 [D loss: 0.103939, acc: 95.31%] [G loss: 10.635221]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 134 6 [D loss: 0.026184, acc: 98.44%] [G loss: 12.235849]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 134 7 [D loss: 0.072101, acc: 96.88%] [G loss: 8.555471]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 134 8 [D loss: 0.121030, acc: 95.31%] [G loss: 10.813917]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 134 9 [D loss: 0.044267, acc: 100.00%] [G loss: 10.138355]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 134 10 [D loss: 0.109715, acc: 93.75%] [G loss: 6.847517]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 134 11 [D loss: 0.031374, acc: 98.44%] [G loss: 7.288707]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 134 12 [D loss: 0.025565, acc: 100.00%] [G loss: 9.100754]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 134 13 [D loss: 0.012806, acc: 100.00%] [G loss: 9.749762]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 134 14 [D loss: 0.078701, acc: 96.88%] [G loss: 8.290461]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 134 15 [D loss: 0.007248, acc: 100.00%] [G loss: 8.125103]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 134 16 [D loss: 0.005258, acc: 100.00%] [G loss: 7.584290]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 134 17 [D loss: 0.003056, acc: 100.00%] [G loss: 8.029303]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 134 18 [D loss: 0.014233, acc: 100.00%] [G loss: 6.788637]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 134 19 [D loss: 0.023198, acc: 100.00%] [G loss: 8.091423]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 134 20 [D loss: 0.056134, acc: 98.44%] [G loss: 8.257692]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 134 21 [D loss: 0.021516, acc: 98.44%] [G loss: 9.000083]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 134 22 [D loss: 0.017743, acc: 98.44%] [G loss: 8.833937]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 135 0 [D loss: 0.010644, acc: 100.00%] [G loss: 8.188079]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 135 1 [D loss: 0.051985, acc: 96.88%] [G loss: 6.648570]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 135 2 [D loss: 0.012693, acc: 100.00%] [G loss: 7.642440]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 135 3 [D loss: 0.042093, acc: 98.44%] [G loss: 7.154449]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 135 4 [D loss: 0.072759, acc: 95.31%] [G loss: 5.958915]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 135 5 [D loss: 0.020829, acc: 100.00%] [G loss: 8.833348]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 135 6 [D loss: 0.006914, acc: 100.00%] [G loss: 11.465225]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 135 7 [D loss: 0.052575, acc: 98.44%] [G loss: 11.069210]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 135 8 [D loss: 0.084423, acc: 93.75%] [G loss: 4.010735]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 135 9 [D loss: 0.347245, acc: 87.50%] [G loss: 12.372186]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 135 10 [D loss: 0.038131, acc: 98.44%] [G loss: 24.706551]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 135 11 [D loss: 0.543354, acc: 87.50%] [G loss: 25.200100]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 135 12 [D loss: 0.098995, acc: 96.88%] [G loss: 18.217285]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 135 13 [D loss: 0.015670, acc: 100.00%] [G loss: 16.362000]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "******* 135 14 [D loss: 0.038811, acc: 98.44%] [G loss: 14.424980]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 135 15 [D loss: 0.048915, acc: 96.88%] [G loss: 14.114504]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 135 16 [D loss: 0.088425, acc: 96.88%] [G loss: 10.603130]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 135 17 [D loss: 0.058465, acc: 96.88%] [G loss: 13.425253]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 135 18 [D loss: 0.000598, acc: 100.00%] [G loss: 13.869522]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 135 19 [D loss: 0.147275, acc: 96.88%] [G loss: 12.933596]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 135 20 [D loss: 0.034267, acc: 98.44%] [G loss: 12.435946]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 135 21 [D loss: 0.000244, acc: 100.00%] [G loss: 10.776352]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 135 22 [D loss: 0.039165, acc: 98.44%] [G loss: 7.073065]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 136 0 [D loss: 0.186108, acc: 92.19%] [G loss: 9.679659]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 136 1 [D loss: 0.063345, acc: 96.88%] [G loss: 10.408312]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 136 2 [D loss: 0.020707, acc: 100.00%] [G loss: 11.146051]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 136 3 [D loss: 0.233418, acc: 92.19%] [G loss: 8.770161]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 136 4 [D loss: 0.040381, acc: 98.44%] [G loss: 6.655229]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 136 5 [D loss: 0.081440, acc: 98.44%] [G loss: 5.094892]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 136 6 [D loss: 0.032435, acc: 98.44%] [G loss: 6.578194]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 136 7 [D loss: 0.021935, acc: 100.00%] [G loss: 6.188052]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 136 8 [D loss: 0.014851, acc: 100.00%] [G loss: 7.362368]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 136 9 [D loss: 0.005146, acc: 100.00%] [G loss: 7.722593]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 136 10 [D loss: 0.015904, acc: 100.00%] [G loss: 7.902349]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 136 11 [D loss: 0.126305, acc: 96.88%] [G loss: 6.997878]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 136 12 [D loss: 0.010267, acc: 100.00%] [G loss: 6.056351]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 136 13 [D loss: 0.067997, acc: 96.88%] [G loss: 5.453012]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 136 14 [D loss: 0.012886, acc: 100.00%] [G loss: 8.739326]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 136 15 [D loss: 0.002979, acc: 100.00%] [G loss: 10.037549]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 136 16 [D loss: 0.031548, acc: 98.44%] [G loss: 9.720162]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 136 17 [D loss: 0.025349, acc: 98.44%] [G loss: 9.993412]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 136 18 [D loss: 0.046354, acc: 96.88%] [G loss: 8.295282]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 136 19 [D loss: 0.029104, acc: 98.44%] [G loss: 8.817961]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 136 20 [D loss: 0.009149, acc: 100.00%] [G loss: 8.533104]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 136 21 [D loss: 0.028234, acc: 100.00%] [G loss: 8.640689]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 136 22 [D loss: 0.042440, acc: 98.44%] [G loss: 6.419503]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 137 0 [D loss: 0.235607, acc: 89.06%] [G loss: 6.905209]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 137 1 [D loss: 0.001913, acc: 100.00%] [G loss: 7.889513]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 137 2 [D loss: 0.039113, acc: 98.44%] [G loss: 9.679884]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 137 3 [D loss: 0.086672, acc: 96.88%] [G loss: 9.141756]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 137 4 [D loss: 0.005910, acc: 100.00%] [G loss: 9.063313]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 137 5 [D loss: 0.043572, acc: 96.88%] [G loss: 7.190943]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 137 6 [D loss: 0.029680, acc: 100.00%] [G loss: 5.858629]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 137 7 [D loss: 0.047492, acc: 96.88%] [G loss: 7.695573]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 137 8 [D loss: 0.004367, acc: 100.00%] [G loss: 10.574369]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 137 9 [D loss: 0.001469, acc: 100.00%] [G loss: 12.339202]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 137 10 [D loss: 0.055773, acc: 98.44%] [G loss: 11.116137]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 137 11 [D loss: 0.002606, acc: 100.00%] [G loss: 12.122258]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 137 12 [D loss: 0.005829, acc: 100.00%] [G loss: 11.293953]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 137 13 [D loss: 0.009465, acc: 100.00%] [G loss: 10.610991]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 137 14 [D loss: 0.024022, acc: 100.00%] [G loss: 10.416642]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 137 15 [D loss: 0.046984, acc: 98.44%] [G loss: 7.949579]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 137 16 [D loss: 0.053662, acc: 96.88%] [G loss: 8.664289]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 137 17 [D loss: 0.001840, acc: 100.00%] [G loss: 11.417336]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 137 18 [D loss: 0.011031, acc: 98.44%] [G loss: 11.754839]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 137 19 [D loss: 0.013841, acc: 100.00%] [G loss: 11.362272]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 137 20 [D loss: 0.008478, acc: 100.00%] [G loss: 10.655755]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 137 21 [D loss: 0.005983, acc: 100.00%] [G loss: 8.354944]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 137 22 [D loss: 0.010555, acc: 100.00%] [G loss: 7.530954]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 138 0 [D loss: 0.029751, acc: 100.00%] [G loss: 6.419025]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 138 1 [D loss: 0.006673, acc: 100.00%] [G loss: 7.861582]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 138 2 [D loss: 0.022263, acc: 100.00%] [G loss: 8.234589]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 138 3 [D loss: 0.009689, acc: 100.00%] [G loss: 9.387979]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 138 4 [D loss: 0.033657, acc: 98.44%] [G loss: 6.742379]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 138 5 [D loss: 0.105599, acc: 95.31%] [G loss: 5.721348]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 138 6 [D loss: 0.113017, acc: 96.88%] [G loss: 6.718267]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 138 7 [D loss: 0.017537, acc: 100.00%] [G loss: 9.953223]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 138 8 [D loss: 0.208588, acc: 92.19%] [G loss: 5.821710]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 138 9 [D loss: 0.073477, acc: 96.88%] [G loss: 5.710835]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 138 10 [D loss: 0.053749, acc: 98.44%] [G loss: 7.790596]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 138 11 [D loss: 0.024501, acc: 100.00%] [G loss: 9.474520]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 138 12 [D loss: 0.031893, acc: 98.44%] [G loss: 8.586987]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 138 13 [D loss: 0.005888, acc: 100.00%] [G loss: 8.752367]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 138 14 [D loss: 0.063032, acc: 96.88%] [G loss: 5.478100]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 138 15 [D loss: 0.084032, acc: 96.88%] [G loss: 5.251817]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 138 16 [D loss: 0.223830, acc: 90.62%] [G loss: 8.485587]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 138 17 [D loss: 0.041743, acc: 98.44%] [G loss: 11.885670]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 138 18 [D loss: 0.104625, acc: 95.31%] [G loss: 11.124523]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 138 19 [D loss: 0.186340, acc: 95.31%] [G loss: 8.138035]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 138 20 [D loss: 0.018211, acc: 100.00%] [G loss: 5.410014]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 138 21 [D loss: 0.205183, acc: 90.62%] [G loss: 6.664962]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 138 22 [D loss: 0.003957, acc: 100.00%] [G loss: 9.266094]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 139 0 [D loss: 0.005799, acc: 100.00%] [G loss: 11.955610]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 139 1 [D loss: 0.049684, acc: 96.88%] [G loss: 12.753566]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "******* 139 2 [D loss: 0.027731, acc: 96.88%] [G loss: 11.470991]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "******* 139 3 [D loss: 0.082138, acc: 98.44%] [G loss: 9.363377]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 139 4 [D loss: 0.028327, acc: 98.44%] [G loss: 6.533944]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 139 5 [D loss: 0.032978, acc: 100.00%] [G loss: 5.082158]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 139 6 [D loss: 0.137594, acc: 92.19%] [G loss: 6.328488]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 139 7 [D loss: 0.005762, acc: 100.00%] [G loss: 10.025025]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 139 8 [D loss: 0.002253, acc: 100.00%] [G loss: 13.703320]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 139 9 [D loss: 0.089826, acc: 96.88%] [G loss: 11.710272]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 139 10 [D loss: 0.057015, acc: 96.88%] [G loss: 11.748572]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 139 11 [D loss: 0.025765, acc: 98.44%] [G loss: 8.662129]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 139 12 [D loss: 0.008405, acc: 100.00%] [G loss: 5.316794]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 139 13 [D loss: 0.046513, acc: 98.44%] [G loss: 5.306853]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 139 14 [D loss: 0.012408, acc: 100.00%] [G loss: 8.854729]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 139 15 [D loss: 0.010467, acc: 100.00%] [G loss: 9.105419]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 139 16 [D loss: 0.002919, acc: 100.00%] [G loss: 9.927864]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 139 17 [D loss: 0.006788, acc: 100.00%] [G loss: 11.246918]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 139 18 [D loss: 0.011249, acc: 100.00%] [G loss: 10.669806]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 139 19 [D loss: 0.059466, acc: 96.88%] [G loss: 8.916113]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 139 20 [D loss: 0.061282, acc: 96.88%] [G loss: 7.393522]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 139 21 [D loss: 0.009312, acc: 100.00%] [G loss: 6.785175]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 139 22 [D loss: 0.035559, acc: 98.44%] [G loss: 6.405802]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 140 0 [D loss: 0.006085, acc: 100.00%] [G loss: 8.559978]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 140 1 [D loss: 0.002162, acc: 100.00%] [G loss: 8.524975]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 140 2 [D loss: 0.003811, acc: 100.00%] [G loss: 10.028661]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 140 3 [D loss: 0.019753, acc: 98.44%] [G loss: 9.179103]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 140 4 [D loss: 0.024135, acc: 100.00%] [G loss: 7.692551]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 140 5 [D loss: 0.014888, acc: 100.00%] [G loss: 7.026833]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 140 6 [D loss: 0.014968, acc: 100.00%] [G loss: 8.754194]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 140 7 [D loss: 0.013668, acc: 100.00%] [G loss: 8.206157]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 140 8 [D loss: 0.004061, acc: 100.00%] [G loss: 8.217657]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 140 9 [D loss: 0.097466, acc: 98.44%] [G loss: 7.803376]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 140 10 [D loss: 0.043391, acc: 98.44%] [G loss: 8.824720]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 140 11 [D loss: 0.008780, acc: 100.00%] [G loss: 13.632936]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 140 12 [D loss: 0.011372, acc: 100.00%] [G loss: 15.151643]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "******* 140 13 [D loss: 0.015164, acc: 100.00%] [G loss: 18.111807]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 140 14 [D loss: 0.014847, acc: 98.44%] [G loss: 18.160164]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 140 15 [D loss: 0.004207, acc: 100.00%] [G loss: 15.547805]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 140 16 [D loss: 0.002545, acc: 100.00%] [G loss: 12.728389]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 140 17 [D loss: 0.002967, acc: 100.00%] [G loss: 12.093502]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 140 18 [D loss: 0.032784, acc: 98.44%] [G loss: 10.175903]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 140 19 [D loss: 0.009494, acc: 100.00%] [G loss: 8.889275]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 140 20 [D loss: 0.017518, acc: 98.44%] [G loss: 9.949128]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 140 21 [D loss: 0.021461, acc: 100.00%] [G loss: 8.197561]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 140 22 [D loss: 0.213742, acc: 92.19%] [G loss: 8.402339]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 141 0 [D loss: 0.191511, acc: 96.88%] [G loss: 7.895811]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 141 1 [D loss: 0.008764, acc: 100.00%] [G loss: 8.663691]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 141 2 [D loss: 0.029627, acc: 100.00%] [G loss: 7.930754]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 141 3 [D loss: 0.094092, acc: 95.31%] [G loss: 4.120831]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 141 4 [D loss: 0.145925, acc: 96.88%] [G loss: 4.687610]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 141 5 [D loss: 0.008560, acc: 100.00%] [G loss: 7.252769]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 141 6 [D loss: 0.093940, acc: 96.88%] [G loss: 6.502622]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 141 7 [D loss: 0.024438, acc: 98.44%] [G loss: 6.991362]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 141 8 [D loss: 0.027127, acc: 98.44%] [G loss: 6.470496]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 141 9 [D loss: 0.082494, acc: 96.88%] [G loss: 6.556916]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 141 10 [D loss: 0.021095, acc: 100.00%] [G loss: 7.098340]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 141 11 [D loss: 0.036523, acc: 98.44%] [G loss: 8.172348]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 141 12 [D loss: 0.008414, acc: 100.00%] [G loss: 7.964776]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "******* 141 13 [D loss: 0.018276, acc: 100.00%] [G loss: 8.094916]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 141 14 [D loss: 0.005133, acc: 100.00%] [G loss: 7.322264]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 141 15 [D loss: 0.049682, acc: 98.44%] [G loss: 7.249346]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 141 16 [D loss: 0.004234, acc: 100.00%] [G loss: 8.761194]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 141 17 [D loss: 0.007407, acc: 100.00%] [G loss: 9.012457]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 141 18 [D loss: 0.002573, acc: 100.00%] [G loss: 9.629198]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 141 19 [D loss: 0.074971, acc: 95.31%] [G loss: 8.556631]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 141 20 [D loss: 0.131790, acc: 95.31%] [G loss: 5.015201]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 141 21 [D loss: 0.069112, acc: 100.00%] [G loss: 6.821267]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 141 22 [D loss: 0.006394, acc: 100.00%] [G loss: 9.498783]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 142 0 [D loss: 0.041393, acc: 98.44%] [G loss: 10.698195]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 142 1 [D loss: 0.013079, acc: 98.44%] [G loss: 12.276282]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 142 2 [D loss: 0.005861, acc: 100.00%] [G loss: 11.465887]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 142 3 [D loss: 0.000409, acc: 100.00%] [G loss: 10.837505]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 142 4 [D loss: 0.215668, acc: 92.19%] [G loss: 6.877198]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 142 5 [D loss: 0.170026, acc: 90.62%] [G loss: 7.643239]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 142 6 [D loss: 0.009722, acc: 100.00%] [G loss: 9.247589]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 142 7 [D loss: 0.056945, acc: 98.44%] [G loss: 11.749737]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 142 8 [D loss: 0.016501, acc: 100.00%] [G loss: 12.688762]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 142 9 [D loss: 0.012316, acc: 100.00%] [G loss: 12.262791]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 142 10 [D loss: 0.102053, acc: 96.88%] [G loss: 9.186852]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 142 11 [D loss: 0.001902, acc: 100.00%] [G loss: 6.465786]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 142 12 [D loss: 0.030637, acc: 100.00%] [G loss: 5.442809]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 142 13 [D loss: 0.022736, acc: 100.00%] [G loss: 7.571184]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 142 14 [D loss: 0.017985, acc: 98.44%] [G loss: 9.960703]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 142 15 [D loss: 0.001798, acc: 100.00%] [G loss: 13.081438]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 142 16 [D loss: 0.041847, acc: 98.44%] [G loss: 13.321671]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 142 17 [D loss: 0.036410, acc: 98.44%] [G loss: 11.255983]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 142 18 [D loss: 0.008712, acc: 100.00%] [G loss: 7.755357]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 142 19 [D loss: 0.200256, acc: 92.19%] [G loss: 11.381033]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 142 20 [D loss: 0.004955, acc: 100.00%] [G loss: 16.176037]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 142 21 [D loss: 0.261212, acc: 93.75%] [G loss: 14.831964]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 142 22 [D loss: 0.007168, acc: 100.00%] [G loss: 11.866156]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 143 0 [D loss: 0.184416, acc: 96.88%] [G loss: 10.638771]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 143 1 [D loss: 0.000554, acc: 100.00%] [G loss: 11.185277]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 143 2 [D loss: 0.075944, acc: 98.44%] [G loss: 9.638059]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 143 3 [D loss: 0.039597, acc: 98.44%] [G loss: 9.090094]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 143 4 [D loss: 0.021707, acc: 98.44%] [G loss: 8.114979]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 143 5 [D loss: 0.003500, acc: 100.00%] [G loss: 10.163820]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 143 6 [D loss: 0.012725, acc: 100.00%] [G loss: 11.181190]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 143 7 [D loss: 0.023559, acc: 98.44%] [G loss: 8.552401]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 143 8 [D loss: 0.044170, acc: 98.44%] [G loss: 9.469632]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 143 9 [D loss: 0.006725, acc: 100.00%] [G loss: 11.226497]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 143 10 [D loss: 0.008693, acc: 100.00%] [G loss: 10.054480]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 143 11 [D loss: 0.026153, acc: 96.88%] [G loss: 10.188066]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 143 12 [D loss: 0.018295, acc: 100.00%] [G loss: 9.933587]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 143 13 [D loss: 0.009718, acc: 100.00%] [G loss: 10.002508]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 143 14 [D loss: 0.017421, acc: 100.00%] [G loss: 9.391706]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 143 15 [D loss: 0.110071, acc: 96.88%] [G loss: 9.368090]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 143 16 [D loss: 0.013150, acc: 100.00%] [G loss: 10.588614]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 143 17 [D loss: 0.202843, acc: 95.31%] [G loss: 8.708239]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 143 18 [D loss: 0.026522, acc: 100.00%] [G loss: 8.777781]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 143 19 [D loss: 0.078733, acc: 98.44%] [G loss: 8.107069]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 143 20 [D loss: 0.033811, acc: 98.44%] [G loss: 8.369804]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 143 21 [D loss: 0.101387, acc: 96.88%] [G loss: 8.391373]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 143 22 [D loss: 0.009952, acc: 100.00%] [G loss: 9.161423]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 144 0 [D loss: 0.497122, acc: 81.25%] [G loss: 10.347490]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 144 1 [D loss: 0.110737, acc: 95.31%] [G loss: 14.069515]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 144 2 [D loss: 0.156889, acc: 95.31%] [G loss: 13.474648]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 144 3 [D loss: 0.011872, acc: 100.00%] [G loss: 11.865910]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 144 4 [D loss: 0.032568, acc: 100.00%] [G loss: 8.583698]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 144 5 [D loss: 0.050665, acc: 98.44%] [G loss: 7.639400]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 144 6 [D loss: 0.015777, acc: 98.44%] [G loss: 8.684045]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 144 7 [D loss: 0.002553, acc: 100.00%] [G loss: 7.769334]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 144 8 [D loss: 0.000595, acc: 100.00%] [G loss: 8.905656]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 144 9 [D loss: 0.065509, acc: 98.44%] [G loss: 9.423292]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 144 10 [D loss: 0.008106, acc: 100.00%] [G loss: 10.228559]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 144 11 [D loss: 0.001865, acc: 100.00%] [G loss: 10.728752]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 144 12 [D loss: 0.077954, acc: 98.44%] [G loss: 8.520699]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 144 13 [D loss: 0.200651, acc: 93.75%] [G loss: 6.700467]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 144 14 [D loss: 0.042648, acc: 98.44%] [G loss: 6.472044]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 144 15 [D loss: 0.077038, acc: 96.88%] [G loss: 8.246864]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 144 16 [D loss: 0.141348, acc: 93.75%] [G loss: 9.826685]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 144 17 [D loss: 0.003299, acc: 100.00%] [G loss: 11.541317]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 144 18 [D loss: 0.063073, acc: 95.31%] [G loss: 10.791538]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 144 19 [D loss: 0.046102, acc: 98.44%] [G loss: 8.234589]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 144 20 [D loss: 0.026037, acc: 100.00%] [G loss: 6.220375]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 144 21 [D loss: 0.045601, acc: 98.44%] [G loss: 4.611357]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 144 22 [D loss: 0.040367, acc: 98.44%] [G loss: 6.337504]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 145 0 [D loss: 0.006800, acc: 100.00%] [G loss: 8.113411]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 145 1 [D loss: 0.006377, acc: 100.00%] [G loss: 9.225449]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 145 2 [D loss: 0.021417, acc: 100.00%] [G loss: 8.703740]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 145 3 [D loss: 0.045063, acc: 96.88%] [G loss: 8.805159]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 145 4 [D loss: 0.072680, acc: 96.88%] [G loss: 6.764101]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 145 5 [D loss: 0.025955, acc: 98.44%] [G loss: 6.092720]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 145 6 [D loss: 0.088961, acc: 93.75%] [G loss: 5.924138]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 145 7 [D loss: 0.018698, acc: 100.00%] [G loss: 6.846200]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 145 8 [D loss: 0.059212, acc: 98.44%] [G loss: 8.109798]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 145 9 [D loss: 0.069048, acc: 96.88%] [G loss: 7.414650]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 145 10 [D loss: 0.006107, acc: 100.00%] [G loss: 6.805397]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 145 11 [D loss: 0.006886, acc: 100.00%] [G loss: 7.454226]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 145 12 [D loss: 0.104404, acc: 92.19%] [G loss: 7.321255]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 145 13 [D loss: 0.001946, acc: 100.00%] [G loss: 8.217183]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 145 14 [D loss: 0.011104, acc: 100.00%] [G loss: 9.097475]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 145 15 [D loss: 0.065152, acc: 98.44%] [G loss: 7.389907]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 145 16 [D loss: 0.059735, acc: 96.88%] [G loss: 5.002496]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 145 17 [D loss: 0.052382, acc: 98.44%] [G loss: 4.125698]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 145 18 [D loss: 0.115590, acc: 93.75%] [G loss: 7.623979]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 145 19 [D loss: 0.007332, acc: 100.00%] [G loss: 11.050310]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 145 20 [D loss: 0.159269, acc: 95.31%] [G loss: 11.559387]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "******* 145 21 [D loss: 0.101725, acc: 93.75%] [G loss: 7.322514]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 145 22 [D loss: 0.033137, acc: 98.44%] [G loss: 4.967854]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 146 0 [D loss: 0.100758, acc: 95.31%] [G loss: 5.439076]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 146 1 [D loss: 0.001975, acc: 100.00%] [G loss: 8.610099]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 146 2 [D loss: 0.000869, acc: 100.00%] [G loss: 10.444277]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 146 3 [D loss: 0.002311, acc: 100.00%] [G loss: 12.973499]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 146 4 [D loss: 0.005085, acc: 100.00%] [G loss: 12.821609]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 146 5 [D loss: 0.003267, acc: 100.00%] [G loss: 12.566594]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 146 6 [D loss: 0.009507, acc: 100.00%] [G loss: 11.731480]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 146 7 [D loss: 0.001811, acc: 100.00%] [G loss: 10.949344]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 146 8 [D loss: 0.005595, acc: 100.00%] [G loss: 8.350534]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 146 9 [D loss: 0.030681, acc: 98.44%] [G loss: 6.472277]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 146 10 [D loss: 0.076323, acc: 98.44%] [G loss: 6.041604]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 146 11 [D loss: 0.010024, acc: 100.00%] [G loss: 7.663093]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 146 12 [D loss: 0.026888, acc: 98.44%] [G loss: 8.437062]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 146 13 [D loss: 0.247888, acc: 92.19%] [G loss: 6.354236]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 146 14 [D loss: 0.131646, acc: 93.75%] [G loss: 5.702924]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 146 15 [D loss: 0.306526, acc: 85.94%] [G loss: 7.377245]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 146 16 [D loss: 0.003578, acc: 100.00%] [G loss: 10.703115]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 146 17 [D loss: 0.184467, acc: 93.75%] [G loss: 9.872929]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 146 18 [D loss: 0.037701, acc: 98.44%] [G loss: 7.403022]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 146 19 [D loss: 0.020727, acc: 100.00%] [G loss: 6.452808]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 146 20 [D loss: 0.079576, acc: 95.31%] [G loss: 6.299682]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 146 21 [D loss: 0.010919, acc: 100.00%] [G loss: 8.624403]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 146 22 [D loss: 0.017864, acc: 98.44%] [G loss: 9.612562]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 147 0 [D loss: 0.081417, acc: 98.44%] [G loss: 10.094850]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 147 1 [D loss: 0.073903, acc: 96.88%] [G loss: 8.398978]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 147 2 [D loss: 0.049735, acc: 96.88%] [G loss: 6.653338]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 147 3 [D loss: 0.054572, acc: 98.44%] [G loss: 6.638167]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 147 4 [D loss: 0.034281, acc: 100.00%] [G loss: 7.972845]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 147 5 [D loss: 0.005643, acc: 100.00%] [G loss: 9.962835]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 147 6 [D loss: 0.014530, acc: 100.00%] [G loss: 10.728907]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 147 7 [D loss: 0.007575, acc: 100.00%] [G loss: 10.310360]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 147 8 [D loss: 0.110874, acc: 98.44%] [G loss: 8.759602]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 147 9 [D loss: 0.007338, acc: 100.00%] [G loss: 8.123869]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 147 10 [D loss: 0.101939, acc: 93.75%] [G loss: 9.325130]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 147 11 [D loss: 0.000509, acc: 100.00%] [G loss: 14.504878]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 147 12 [D loss: 0.000623, acc: 100.00%] [G loss: 17.317085]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 147 13 [D loss: 0.010191, acc: 100.00%] [G loss: 19.720089]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 147 14 [D loss: 0.000891, acc: 100.00%] [G loss: 18.096035]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 147 15 [D loss: 0.000225, acc: 100.00%] [G loss: 17.689220]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 147 16 [D loss: 0.000084, acc: 100.00%] [G loss: 15.723173]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 147 17 [D loss: 0.000600, acc: 100.00%] [G loss: 12.482586]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 147 18 [D loss: 0.053345, acc: 98.44%] [G loss: 9.598217]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 147 19 [D loss: 0.180015, acc: 95.31%] [G loss: 14.308033]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 147 20 [D loss: 0.011752, acc: 98.44%] [G loss: 20.817314]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 147 21 [D loss: 0.222501, acc: 93.75%] [G loss: 19.460861]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 147 22 [D loss: 0.028017, acc: 98.44%] [G loss: 14.631611]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 148 0 [D loss: 0.018427, acc: 98.44%] [G loss: 6.737606]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 148 1 [D loss: 0.378756, acc: 87.50%] [G loss: 13.532569]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 148 2 [D loss: 0.000027, acc: 100.00%] [G loss: 27.624569]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 148 3 [D loss: 0.372050, acc: 87.50%] [G loss: 21.089756]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 148 4 [D loss: 0.145531, acc: 95.31%] [G loss: 10.338270]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 148 5 [D loss: 0.103430, acc: 95.31%] [G loss: 6.911541]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 148 6 [D loss: 0.127062, acc: 93.75%] [G loss: 11.095960]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 148 7 [D loss: 0.000001, acc: 100.00%] [G loss: 19.660458]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 148 8 [D loss: 0.001914, acc: 100.00%] [G loss: 25.229610]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 148 9 [D loss: 0.055880, acc: 98.44%] [G loss: 25.045929]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 148 10 [D loss: 0.002099, acc: 100.00%] [G loss: 26.169104]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 148 11 [D loss: 0.099315, acc: 96.88%] [G loss: 23.307053]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 148 12 [D loss: 0.037733, acc: 98.44%] [G loss: 16.452927]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 148 13 [D loss: 0.018532, acc: 98.44%] [G loss: 13.229190]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 148 14 [D loss: 0.248404, acc: 95.31%] [G loss: 6.684576]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 148 15 [D loss: 0.291445, acc: 90.62%] [G loss: 11.014243]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 148 16 [D loss: 0.036803, acc: 96.88%] [G loss: 15.698593]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 148 17 [D loss: 0.038878, acc: 98.44%] [G loss: 16.316710]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 148 18 [D loss: 0.329465, acc: 87.50%] [G loss: 12.747441]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 148 19 [D loss: 0.005215, acc: 100.00%] [G loss: 7.882599]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 148 20 [D loss: 0.108919, acc: 95.31%] [G loss: 6.995469]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 148 21 [D loss: 0.039100, acc: 98.44%] [G loss: 8.315663]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 148 22 [D loss: 0.004170, acc: 100.00%] [G loss: 10.123661]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 149 0 [D loss: 0.044856, acc: 98.44%] [G loss: 11.027559]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 149 1 [D loss: 0.025408, acc: 100.00%] [G loss: 10.869500]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 149 2 [D loss: 0.106058, acc: 96.88%] [G loss: 7.082530]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 149 3 [D loss: 0.204777, acc: 96.88%] [G loss: 8.238707]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 149 4 [D loss: 0.180994, acc: 96.88%] [G loss: 7.856342]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 149 5 [D loss: 0.063354, acc: 96.88%] [G loss: 11.807676]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 149 6 [D loss: 0.083028, acc: 96.88%] [G loss: 11.703419]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 149 7 [D loss: 0.055975, acc: 98.44%] [G loss: 10.525414]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 149 8 [D loss: 0.036303, acc: 98.44%] [G loss: 8.675050]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 149 9 [D loss: 0.027806, acc: 98.44%] [G loss: 6.862006]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 149 10 [D loss: 0.020903, acc: 98.44%] [G loss: 7.288404]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 149 11 [D loss: 0.007276, acc: 100.00%] [G loss: 6.993712]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 149 12 [D loss: 0.034071, acc: 98.44%] [G loss: 9.362396]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 149 13 [D loss: 0.006089, acc: 100.00%] [G loss: 9.458652]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 149 14 [D loss: 0.019745, acc: 100.00%] [G loss: 9.897308]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 149 15 [D loss: 0.047202, acc: 98.44%] [G loss: 8.416899]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 149 16 [D loss: 0.184670, acc: 96.88%] [G loss: 7.429411]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 149 17 [D loss: 0.060744, acc: 96.88%] [G loss: 8.172993]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 149 18 [D loss: 0.183053, acc: 93.75%] [G loss: 8.177073]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 149 19 [D loss: 0.041846, acc: 98.44%] [G loss: 10.146706]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 149 20 [D loss: 0.002288, acc: 100.00%] [G loss: 11.053938]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 149 21 [D loss: 0.043708, acc: 96.88%] [G loss: 10.660650]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 149 22 [D loss: 0.020004, acc: 98.44%] [G loss: 8.603319]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "******* 150 0 [D loss: 0.074080, acc: 98.44%] [G loss: 8.184172]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 150 1 [D loss: 0.019271, acc: 98.44%] [G loss: 8.927927]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 150 2 [D loss: 0.003177, acc: 100.00%] [G loss: 9.428522]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 150 3 [D loss: 0.022586, acc: 98.44%] [G loss: 11.680420]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 150 4 [D loss: 0.024440, acc: 98.44%] [G loss: 10.513776]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 150 5 [D loss: 0.055920, acc: 96.88%] [G loss: 10.264730]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 150 6 [D loss: 0.012351, acc: 100.00%] [G loss: 8.150234]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 150 7 [D loss: 0.013912, acc: 100.00%] [G loss: 9.645184]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 150 8 [D loss: 0.031436, acc: 98.44%] [G loss: 10.864796]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 150 9 [D loss: 0.032378, acc: 100.00%] [G loss: 11.465564]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 150 10 [D loss: 0.002687, acc: 100.00%] [G loss: 13.855798]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 150 11 [D loss: 0.025684, acc: 98.44%] [G loss: 14.291036]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 150 12 [D loss: 0.037256, acc: 98.44%] [G loss: 11.057060]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 150 13 [D loss: 0.031973, acc: 98.44%] [G loss: 8.005770]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 150 14 [D loss: 0.050321, acc: 98.44%] [G loss: 7.282621]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 150 15 [D loss: 0.002639, acc: 100.00%] [G loss: 10.133498]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 150 16 [D loss: 0.011766, acc: 100.00%] [G loss: 10.270935]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 150 17 [D loss: 0.014645, acc: 98.44%] [G loss: 10.407240]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 150 18 [D loss: 0.039851, acc: 98.44%] [G loss: 10.176771]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 150 19 [D loss: 0.201227, acc: 98.44%] [G loss: 10.213623]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 150 20 [D loss: 0.014827, acc: 100.00%] [G loss: 9.636466]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 150 21 [D loss: 0.091882, acc: 95.31%] [G loss: 9.616204]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 150 22 [D loss: 0.005284, acc: 100.00%] [G loss: 13.106081]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 151 0 [D loss: 0.203360, acc: 92.19%] [G loss: 6.766692]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 151 1 [D loss: 0.107791, acc: 95.31%] [G loss: 13.313047]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 151 2 [D loss: 0.000200, acc: 100.00%] [G loss: 22.209919]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 151 3 [D loss: 0.197471, acc: 93.75%] [G loss: 21.954697]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 151 4 [D loss: 0.003467, acc: 100.00%] [G loss: 19.804157]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 151 5 [D loss: 0.023772, acc: 98.44%] [G loss: 11.869456]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 151 6 [D loss: 0.311660, acc: 90.62%] [G loss: 25.138878]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 151 7 [D loss: 0.146890, acc: 95.31%] [G loss: 28.981026]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 151 8 [D loss: 1.015588, acc: 79.69%] [G loss: 16.017317]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 151 9 [D loss: 0.307161, acc: 87.50%] [G loss: 10.550836]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 151 10 [D loss: 0.028705, acc: 98.44%] [G loss: 12.447204]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 151 11 [D loss: 0.028671, acc: 98.44%] [G loss: 11.036922]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 151 12 [D loss: 0.077013, acc: 98.44%] [G loss: 11.017675]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 151 13 [D loss: 0.001278, acc: 100.00%] [G loss: 8.727032]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 151 14 [D loss: 0.001805, acc: 100.00%] [G loss: 8.832092]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 151 15 [D loss: 0.007880, acc: 100.00%] [G loss: 7.379724]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 151 16 [D loss: 0.123973, acc: 95.31%] [G loss: 5.247766]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 151 17 [D loss: 0.082886, acc: 96.88%] [G loss: 5.724306]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 151 18 [D loss: 0.007972, acc: 100.00%] [G loss: 8.268991]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 151 19 [D loss: 0.220226, acc: 95.31%] [G loss: 7.081676]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 151 20 [D loss: 0.086641, acc: 98.44%] [G loss: 5.040234]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 151 21 [D loss: 0.123814, acc: 95.31%] [G loss: 5.301718]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 151 22 [D loss: 0.041349, acc: 98.44%] [G loss: 8.077272]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 152 0 [D loss: 0.090485, acc: 96.88%] [G loss: 8.062963]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 152 1 [D loss: 0.029899, acc: 100.00%] [G loss: 8.068213]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 152 2 [D loss: 0.065235, acc: 96.88%] [G loss: 7.044150]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 152 3 [D loss: 0.110086, acc: 98.44%] [G loss: 5.893767]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 152 4 [D loss: 0.058039, acc: 98.44%] [G loss: 5.895045]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 152 5 [D loss: 0.039005, acc: 98.44%] [G loss: 5.400302]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 152 6 [D loss: 0.067206, acc: 98.44%] [G loss: 4.168941]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 152 7 [D loss: 0.048843, acc: 98.44%] [G loss: 5.281333]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 152 8 [D loss: 0.035499, acc: 100.00%] [G loss: 6.745949]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 152 9 [D loss: 0.003715, acc: 100.00%] [G loss: 8.461658]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 152 10 [D loss: 0.003514, acc: 100.00%] [G loss: 9.185898]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 152 11 [D loss: 0.000793, acc: 100.00%] [G loss: 11.049291]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 152 12 [D loss: 0.000151, acc: 100.00%] [G loss: 11.941717]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 152 13 [D loss: 0.002084, acc: 100.00%] [G loss: 12.080524]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 152 14 [D loss: 0.004364, acc: 100.00%] [G loss: 11.902958]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 152 15 [D loss: 0.059918, acc: 95.31%] [G loss: 10.172190]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 152 16 [D loss: 0.021797, acc: 98.44%] [G loss: 7.610431]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 152 17 [D loss: 0.081410, acc: 96.88%] [G loss: 8.555182]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 152 18 [D loss: 0.000540, acc: 100.00%] [G loss: 10.876390]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 152 19 [D loss: 0.200916, acc: 92.19%] [G loss: 9.725355]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 152 20 [D loss: 0.041966, acc: 98.44%] [G loss: 8.854994]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 152 21 [D loss: 0.008727, acc: 100.00%] [G loss: 8.477961]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 152 22 [D loss: 0.093556, acc: 96.88%] [G loss: 8.628265]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 153 0 [D loss: 0.026262, acc: 98.44%] [G loss: 8.038132]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 153 1 [D loss: 0.009145, acc: 100.00%] [G loss: 9.962030]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 153 2 [D loss: 0.003690, acc: 100.00%] [G loss: 10.627493]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 153 3 [D loss: 0.050209, acc: 96.88%] [G loss: 10.384986]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 153 4 [D loss: 0.025128, acc: 98.44%] [G loss: 13.059236]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 153 5 [D loss: 0.003048, acc: 100.00%] [G loss: 12.148634]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 153 6 [D loss: 0.049916, acc: 96.88%] [G loss: 10.531447]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 153 7 [D loss: 0.065082, acc: 96.88%] [G loss: 10.850015]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 153 8 [D loss: 0.059884, acc: 98.44%] [G loss: 10.671510]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 153 9 [D loss: 0.425942, acc: 92.19%] [G loss: 9.197278]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 153 10 [D loss: 0.024391, acc: 98.44%] [G loss: 13.132761]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 153 11 [D loss: 0.138379, acc: 96.88%] [G loss: 13.898509]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "******* 153 12 [D loss: 0.074964, acc: 98.44%] [G loss: 12.608274]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 153 13 [D loss: 0.012187, acc: 100.00%] [G loss: 11.991951]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 153 14 [D loss: 0.003323, acc: 100.00%] [G loss: 10.374016]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 153 15 [D loss: 0.003559, acc: 100.00%] [G loss: 8.953320]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 153 16 [D loss: 0.012783, acc: 98.44%] [G loss: 9.950174]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 153 17 [D loss: 0.013276, acc: 100.00%] [G loss: 9.740112]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 153 18 [D loss: 0.000638, acc: 100.00%] [G loss: 10.312658]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 153 19 [D loss: 0.006054, acc: 100.00%] [G loss: 10.136604]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 153 20 [D loss: 0.025242, acc: 98.44%] [G loss: 10.693427]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 153 21 [D loss: 0.016170, acc: 100.00%] [G loss: 9.945908]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "******* 153 22 [D loss: 0.010749, acc: 100.00%] [G loss: 9.386840]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 154 0 [D loss: 0.044544, acc: 96.88%] [G loss: 11.579376]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 154 1 [D loss: 0.005186, acc: 100.00%] [G loss: 12.853964]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 154 2 [D loss: 0.042725, acc: 98.44%] [G loss: 11.191641]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 154 3 [D loss: 0.001714, acc: 100.00%] [G loss: 11.745911]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 154 4 [D loss: 0.018779, acc: 98.44%] [G loss: 9.151165]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 154 5 [D loss: 0.094252, acc: 96.88%] [G loss: 6.585604]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 154 6 [D loss: 0.231242, acc: 89.06%] [G loss: 9.356426]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 154 7 [D loss: 0.000554, acc: 100.00%] [G loss: 16.312859]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 154 8 [D loss: 0.056291, acc: 96.88%] [G loss: 18.921223]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 154 9 [D loss: 0.126985, acc: 95.31%] [G loss: 17.232681]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 154 10 [D loss: 0.052527, acc: 98.44%] [G loss: 13.857271]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 154 11 [D loss: 0.001012, acc: 100.00%] [G loss: 10.308220]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 154 12 [D loss: 0.000270, acc: 100.00%] [G loss: 7.476048]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 154 13 [D loss: 0.005738, acc: 100.00%] [G loss: 5.424892]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 154 14 [D loss: 0.041588, acc: 98.44%] [G loss: 6.102948]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 154 15 [D loss: 0.001735, acc: 100.00%] [G loss: 8.569715]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 154 16 [D loss: 0.006712, acc: 100.00%] [G loss: 11.293330]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 154 17 [D loss: 0.000072, acc: 100.00%] [G loss: 10.986275]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 154 18 [D loss: 0.000087, acc: 100.00%] [G loss: 12.455572]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 154 19 [D loss: 0.001940, acc: 100.00%] [G loss: 13.873167]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 154 20 [D loss: 0.000046, acc: 100.00%] [G loss: 14.039759]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 154 21 [D loss: 0.000154, acc: 100.00%] [G loss: 13.512083]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 154 22 [D loss: 0.001525, acc: 100.00%] [G loss: 14.828912]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 155 0 [D loss: 0.003715, acc: 100.00%] [G loss: 13.540945]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 155 1 [D loss: 0.004550, acc: 100.00%] [G loss: 13.599911]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 155 2 [D loss: 0.084585, acc: 96.88%] [G loss: 10.451357]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 155 3 [D loss: 0.000748, acc: 100.00%] [G loss: 9.863396]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 155 4 [D loss: 0.001965, acc: 100.00%] [G loss: 7.216000]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 155 5 [D loss: 0.004022, acc: 100.00%] [G loss: 6.350088]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 155 6 [D loss: 0.075397, acc: 95.31%] [G loss: 6.791660]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 155 7 [D loss: 0.007400, acc: 100.00%] [G loss: 8.587111]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 155 8 [D loss: 0.003863, acc: 100.00%] [G loss: 11.231626]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 155 9 [D loss: 0.001714, acc: 100.00%] [G loss: 13.333057]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 155 10 [D loss: 0.011907, acc: 100.00%] [G loss: 13.024494]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 155 11 [D loss: 0.016777, acc: 98.44%] [G loss: 12.257545]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 155 12 [D loss: 0.008684, acc: 100.00%] [G loss: 11.789004]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "******* 155 13 [D loss: 0.011678, acc: 100.00%] [G loss: 11.187954]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 155 14 [D loss: 0.027726, acc: 98.44%] [G loss: 9.988364]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 155 15 [D loss: 0.005157, acc: 100.00%] [G loss: 10.176611]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 155 16 [D loss: 0.154664, acc: 98.44%] [G loss: 10.458785]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 155 17 [D loss: 0.018645, acc: 98.44%] [G loss: 11.310829]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 155 18 [D loss: 0.016163, acc: 100.00%] [G loss: 11.723617]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 155 19 [D loss: 0.016720, acc: 100.00%] [G loss: 10.983300]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 155 20 [D loss: 0.012710, acc: 100.00%] [G loss: 9.851442]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 155 21 [D loss: 0.062136, acc: 98.44%] [G loss: 11.237783]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 155 22 [D loss: 0.035109, acc: 96.88%] [G loss: 11.579640]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 156 0 [D loss: 0.047820, acc: 98.44%] [G loss: 11.810574]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 156 1 [D loss: 0.040102, acc: 98.44%] [G loss: 12.733052]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 156 2 [D loss: 0.009574, acc: 100.00%] [G loss: 12.102351]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 156 3 [D loss: 0.093086, acc: 96.88%] [G loss: 10.005707]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 156 4 [D loss: 0.036391, acc: 98.44%] [G loss: 5.947209]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 156 5 [D loss: 0.230288, acc: 90.62%] [G loss: 10.151141]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 156 6 [D loss: 0.001700, acc: 100.00%] [G loss: 19.167631]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 156 7 [D loss: 0.032372, acc: 98.44%] [G loss: 25.552277]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 156 8 [D loss: 0.779541, acc: 87.50%] [G loss: 18.371223]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 156 9 [D loss: 0.016078, acc: 98.44%] [G loss: 9.963387]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 156 10 [D loss: 0.587184, acc: 79.69%] [G loss: 12.530207]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 156 11 [D loss: 0.000052, acc: 100.00%] [G loss: 22.328527]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 156 12 [D loss: 0.162791, acc: 93.75%] [G loss: 27.845448]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 156 13 [D loss: 0.124265, acc: 95.31%] [G loss: 26.464977]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 156 14 [D loss: 0.009214, acc: 100.00%] [G loss: 20.907946]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 156 15 [D loss: 0.128531, acc: 93.75%] [G loss: 17.056314]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 156 16 [D loss: 0.003849, acc: 100.00%] [G loss: 14.379855]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 156 17 [D loss: 0.040259, acc: 98.44%] [G loss: 13.671358]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 156 18 [D loss: 0.129085, acc: 98.44%] [G loss: 10.937415]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 156 19 [D loss: 0.058671, acc: 96.88%] [G loss: 10.053329]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 156 20 [D loss: 0.004136, acc: 100.00%] [G loss: 14.603212]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 156 21 [D loss: 0.005118, acc: 100.00%] [G loss: 14.746973]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 156 22 [D loss: 0.311132, acc: 92.19%] [G loss: 9.699346]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 157 0 [D loss: 0.231403, acc: 87.50%] [G loss: 7.478401]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 157 1 [D loss: 0.009235, acc: 100.00%] [G loss: 9.529075]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 157 2 [D loss: 0.241847, acc: 93.75%] [G loss: 8.878011]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 157 3 [D loss: 0.044563, acc: 96.88%] [G loss: 7.611020]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 157 4 [D loss: 0.116684, acc: 96.88%] [G loss: 7.532217]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 157 5 [D loss: 0.019304, acc: 100.00%] [G loss: 6.882709]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 157 6 [D loss: 0.066964, acc: 96.88%] [G loss: 7.424655]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 157 7 [D loss: 0.102438, acc: 95.31%] [G loss: 9.253474]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 157 8 [D loss: 0.041722, acc: 98.44%] [G loss: 10.399647]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 157 9 [D loss: 0.100856, acc: 95.31%] [G loss: 10.714869]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 157 10 [D loss: 0.199520, acc: 93.75%] [G loss: 8.641264]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 157 11 [D loss: 0.052155, acc: 98.44%] [G loss: 7.478017]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 157 12 [D loss: 0.225342, acc: 90.62%] [G loss: 9.286146]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 157 13 [D loss: 0.021776, acc: 98.44%] [G loss: 11.842799]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 157 14 [D loss: 0.153730, acc: 92.19%] [G loss: 10.906114]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 157 15 [D loss: 0.032883, acc: 98.44%] [G loss: 8.597204]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 157 16 [D loss: 0.045222, acc: 96.88%] [G loss: 7.370685]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 157 17 [D loss: 0.061976, acc: 96.88%] [G loss: 6.694747]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 157 18 [D loss: 0.083519, acc: 95.31%] [G loss: 10.556203]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 157 19 [D loss: 0.013643, acc: 100.00%] [G loss: 12.997096]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 157 20 [D loss: 0.046178, acc: 98.44%] [G loss: 12.611627]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 157 21 [D loss: 0.041737, acc: 98.44%] [G loss: 11.544553]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 157 22 [D loss: 0.024732, acc: 100.00%] [G loss: 8.372215]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 158 0 [D loss: 0.065223, acc: 95.31%] [G loss: 6.644702]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 158 1 [D loss: 0.066920, acc: 93.75%] [G loss: 7.779932]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 158 2 [D loss: 0.020877, acc: 100.00%] [G loss: 10.924769]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 158 3 [D loss: 0.040631, acc: 98.44%] [G loss: 10.488640]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 158 4 [D loss: 0.142005, acc: 95.31%] [G loss: 8.667338]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 158 5 [D loss: 0.012142, acc: 100.00%] [G loss: 8.213402]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 158 6 [D loss: 0.022901, acc: 100.00%] [G loss: 6.640721]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 158 7 [D loss: 0.039561, acc: 100.00%] [G loss: 7.885180]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 158 8 [D loss: 0.059305, acc: 98.44%] [G loss: 9.750707]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 158 9 [D loss: 0.036267, acc: 98.44%] [G loss: 13.348782]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 158 10 [D loss: 0.082710, acc: 93.75%] [G loss: 11.714738]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 158 11 [D loss: 0.112663, acc: 96.88%] [G loss: 9.641007]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 158 12 [D loss: 0.042470, acc: 98.44%] [G loss: 7.536293]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 158 13 [D loss: 0.006805, acc: 100.00%] [G loss: 7.859087]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 158 14 [D loss: 0.015938, acc: 100.00%] [G loss: 9.418016]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 158 15 [D loss: 0.004012, acc: 100.00%] [G loss: 9.421659]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 158 16 [D loss: 0.005684, acc: 100.00%] [G loss: 10.220785]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 158 17 [D loss: 0.009062, acc: 100.00%] [G loss: 10.150928]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 158 18 [D loss: 0.008871, acc: 100.00%] [G loss: 10.121331]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 158 19 [D loss: 0.009489, acc: 100.00%] [G loss: 9.917450]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 158 20 [D loss: 0.019978, acc: 100.00%] [G loss: 8.827185]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "******* 158 21 [D loss: 0.010112, acc: 100.00%] [G loss: 9.528754]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 158 22 [D loss: 0.035525, acc: 98.44%] [G loss: 10.092249]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 159 0 [D loss: 0.047912, acc: 98.44%] [G loss: 12.087372]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 159 1 [D loss: 0.035171, acc: 98.44%] [G loss: 12.619960]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 159 2 [D loss: 0.011811, acc: 100.00%] [G loss: 13.682526]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 159 3 [D loss: 0.071019, acc: 96.88%] [G loss: 13.435230]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 159 4 [D loss: 0.108072, acc: 98.44%] [G loss: 14.726469]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 159 5 [D loss: 0.000929, acc: 100.00%] [G loss: 16.540892]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 159 6 [D loss: 0.000465, acc: 100.00%] [G loss: 19.674366]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 159 7 [D loss: 0.056622, acc: 98.44%] [G loss: 18.054115]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 159 8 [D loss: 0.000144, acc: 100.00%] [G loss: 15.201853]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 159 9 [D loss: 0.003399, acc: 100.00%] [G loss: 11.224463]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 159 10 [D loss: 0.149952, acc: 93.75%] [G loss: 14.635398]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 159 11 [D loss: 0.000407, acc: 100.00%] [G loss: 18.787537]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 159 12 [D loss: 0.016347, acc: 100.00%] [G loss: 21.323475]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 159 13 [D loss: 0.074361, acc: 98.44%] [G loss: 21.529005]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 159 14 [D loss: 0.094445, acc: 93.75%] [G loss: 13.066652]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 159 15 [D loss: 0.134814, acc: 95.31%] [G loss: 9.705005]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 159 16 [D loss: 0.072417, acc: 95.31%] [G loss: 11.028675]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 159 17 [D loss: 0.089547, acc: 96.88%] [G loss: 10.931218]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 159 18 [D loss: 0.184873, acc: 95.31%] [G loss: 5.817363]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 159 19 [D loss: 0.297913, acc: 89.06%] [G loss: 7.883586]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 159 20 [D loss: 0.040247, acc: 98.44%] [G loss: 12.819633]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 159 21 [D loss: 0.134116, acc: 96.88%] [G loss: 12.597915]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 159 22 [D loss: 0.293650, acc: 90.62%] [G loss: 8.281522]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 160 0 [D loss: 0.127575, acc: 93.75%] [G loss: 6.317269]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 160 1 [D loss: 0.012480, acc: 100.00%] [G loss: 9.995825]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 160 2 [D loss: 0.012333, acc: 100.00%] [G loss: 12.331141]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 160 3 [D loss: 0.000211, acc: 100.00%] [G loss: 14.569243]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 160 4 [D loss: 0.092578, acc: 96.88%] [G loss: 13.288513]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 160 5 [D loss: 0.002107, acc: 100.00%] [G loss: 13.107204]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 160 6 [D loss: 0.022535, acc: 98.44%] [G loss: 11.284721]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 160 7 [D loss: 0.001265, acc: 100.00%] [G loss: 10.077621]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 160 8 [D loss: 0.030589, acc: 98.44%] [G loss: 8.891242]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 160 9 [D loss: 0.051175, acc: 96.88%] [G loss: 13.407433]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 160 10 [D loss: 0.000045, acc: 100.00%] [G loss: 15.298166]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 160 11 [D loss: 0.000149, acc: 100.00%] [G loss: 16.967567]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 160 12 [D loss: 0.041202, acc: 98.44%] [G loss: 15.654253]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 160 13 [D loss: 0.003127, acc: 100.00%] [G loss: 15.023618]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 160 14 [D loss: 0.000661, acc: 100.00%] [G loss: 12.061583]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 160 15 [D loss: 0.001422, acc: 100.00%] [G loss: 11.585995]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 160 16 [D loss: 0.199101, acc: 98.44%] [G loss: 7.542526]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 160 17 [D loss: 0.109899, acc: 96.88%] [G loss: 5.905096]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 160 18 [D loss: 0.073378, acc: 96.88%] [G loss: 7.099162]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 160 19 [D loss: 0.006608, acc: 100.00%] [G loss: 9.209035]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 160 20 [D loss: 0.001050, acc: 100.00%] [G loss: 11.067551]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 160 21 [D loss: 0.015467, acc: 98.44%] [G loss: 10.673216]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 160 22 [D loss: 0.077480, acc: 96.88%] [G loss: 10.178679]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 161 0 [D loss: 0.141890, acc: 93.75%] [G loss: 10.188814]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 161 1 [D loss: 0.012415, acc: 100.00%] [G loss: 11.722353]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 161 2 [D loss: 0.002049, acc: 100.00%] [G loss: 13.312807]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 161 3 [D loss: 0.003808, acc: 100.00%] [G loss: 12.396612]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 161 4 [D loss: 0.036176, acc: 98.44%] [G loss: 11.688295]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 161 5 [D loss: 0.001508, acc: 100.00%] [G loss: 11.056856]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 161 6 [D loss: 0.068286, acc: 96.88%] [G loss: 6.807213]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "******* 161 7 [D loss: 0.013381, acc: 100.00%] [G loss: 4.673448]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 161 8 [D loss: 0.166841, acc: 93.75%] [G loss: 7.099028]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 161 9 [D loss: 0.000140, acc: 100.00%] [G loss: 13.390464]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 161 10 [D loss: 0.147185, acc: 95.31%] [G loss: 14.655540]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 161 11 [D loss: 0.000903, acc: 100.00%] [G loss: 14.969958]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 161 12 [D loss: 0.034770, acc: 96.88%] [G loss: 13.107857]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "******* 161 13 [D loss: 0.004193, acc: 100.00%] [G loss: 11.507987]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 161 14 [D loss: 0.034510, acc: 98.44%] [G loss: 8.576500]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 161 15 [D loss: 0.119291, acc: 98.44%] [G loss: 6.290343]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 161 16 [D loss: 0.003215, acc: 100.00%] [G loss: 7.355196]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 161 17 [D loss: 0.022885, acc: 98.44%] [G loss: 8.053183]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 161 18 [D loss: 0.001938, acc: 100.00%] [G loss: 9.361765]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 161 19 [D loss: 0.024180, acc: 98.44%] [G loss: 8.432591]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 161 20 [D loss: 0.016992, acc: 100.00%] [G loss: 7.560551]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 161 21 [D loss: 0.037127, acc: 98.44%] [G loss: 6.589428]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 161 22 [D loss: 0.038372, acc: 98.44%] [G loss: 6.764145]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 162 0 [D loss: 0.022163, acc: 100.00%] [G loss: 7.654525]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 162 1 [D loss: 0.139146, acc: 95.31%] [G loss: 4.645700]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 162 2 [D loss: 0.117234, acc: 93.75%] [G loss: 6.137116]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 162 3 [D loss: 0.007356, acc: 100.00%] [G loss: 10.398666]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 162 4 [D loss: 0.013171, acc: 100.00%] [G loss: 13.032432]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 162 5 [D loss: 0.116918, acc: 93.75%] [G loss: 11.654116]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 162 6 [D loss: 0.031019, acc: 98.44%] [G loss: 9.568695]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 162 7 [D loss: 0.009210, acc: 100.00%] [G loss: 7.294611]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 162 8 [D loss: 0.107100, acc: 95.31%] [G loss: 7.455174]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 162 9 [D loss: 0.012866, acc: 100.00%] [G loss: 9.877087]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 162 10 [D loss: 0.001552, acc: 100.00%] [G loss: 13.071829]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 162 11 [D loss: 0.106308, acc: 96.88%] [G loss: 13.002686]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 162 12 [D loss: 0.048399, acc: 96.88%] [G loss: 11.275478]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 162 13 [D loss: 0.003373, acc: 100.00%] [G loss: 8.948274]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 162 14 [D loss: 0.007537, acc: 100.00%] [G loss: 7.720726]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 162 15 [D loss: 0.010681, acc: 100.00%] [G loss: 5.755783]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 162 16 [D loss: 0.043240, acc: 98.44%] [G loss: 7.212495]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 162 17 [D loss: 0.012585, acc: 100.00%] [G loss: 8.983171]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 162 18 [D loss: 0.000844, acc: 100.00%] [G loss: 11.042331]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 162 19 [D loss: 0.001278, acc: 100.00%] [G loss: 12.741543]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 162 20 [D loss: 0.003673, acc: 100.00%] [G loss: 12.700268]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 162 21 [D loss: 0.019531, acc: 100.00%] [G loss: 11.539583]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 162 22 [D loss: 0.076206, acc: 98.44%] [G loss: 9.173063]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 163 0 [D loss: 0.012052, acc: 100.00%] [G loss: 5.688972]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 163 1 [D loss: 0.257710, acc: 90.62%] [G loss: 11.378577]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 163 2 [D loss: 0.045099, acc: 96.88%] [G loss: 15.787476]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 163 3 [D loss: 0.296208, acc: 90.62%] [G loss: 15.120680]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 163 4 [D loss: 0.008321, acc: 100.00%] [G loss: 12.919619]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 163 5 [D loss: 0.000835, acc: 100.00%] [G loss: 10.248758]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 163 6 [D loss: 0.001250, acc: 100.00%] [G loss: 7.791457]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 163 7 [D loss: 0.026495, acc: 98.44%] [G loss: 7.458883]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 163 8 [D loss: 0.054143, acc: 96.88%] [G loss: 8.664452]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 163 9 [D loss: 0.037747, acc: 96.88%] [G loss: 10.906255]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 163 10 [D loss: 0.003806, acc: 100.00%] [G loss: 11.761166]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 163 11 [D loss: 0.000048, acc: 100.00%] [G loss: 12.234229]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 163 12 [D loss: 0.000188, acc: 100.00%] [G loss: 13.132660]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 163 13 [D loss: 0.000132, acc: 100.00%] [G loss: 13.950950]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 163 14 [D loss: 0.001107, acc: 100.00%] [G loss: 12.890774]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 163 15 [D loss: 0.004761, acc: 100.00%] [G loss: 12.652513]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 163 16 [D loss: 0.267963, acc: 93.75%] [G loss: 11.392524]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 163 17 [D loss: 0.001544, acc: 100.00%] [G loss: 12.343323]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 163 18 [D loss: 0.012393, acc: 100.00%] [G loss: 13.144836]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 163 19 [D loss: 0.228519, acc: 98.44%] [G loss: 9.151882]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 163 20 [D loss: 0.058763, acc: 98.44%] [G loss: 7.997571]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 163 21 [D loss: 0.011197, acc: 100.00%] [G loss: 9.780425]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 163 22 [D loss: 0.003732, acc: 100.00%] [G loss: 10.814754]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 164 0 [D loss: 0.005698, acc: 100.00%] [G loss: 11.182236]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 164 1 [D loss: 0.003817, acc: 100.00%] [G loss: 10.934774]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 164 2 [D loss: 0.001428, acc: 100.00%] [G loss: 11.252880]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 164 3 [D loss: 0.003841, acc: 100.00%] [G loss: 9.850614]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "******* 164 4 [D loss: 0.097230, acc: 96.88%] [G loss: 10.663546]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 164 5 [D loss: 0.008461, acc: 100.00%] [G loss: 14.530182]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 164 6 [D loss: 0.005941, acc: 100.00%] [G loss: 16.487709]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 164 7 [D loss: 0.102175, acc: 98.44%] [G loss: 12.576395]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 164 8 [D loss: 0.002002, acc: 100.00%] [G loss: 8.865342]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 164 9 [D loss: 0.026127, acc: 98.44%] [G loss: 8.028847]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 164 10 [D loss: 0.003284, acc: 100.00%] [G loss: 11.978978]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 164 11 [D loss: 0.007920, acc: 100.00%] [G loss: 12.022989]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 164 12 [D loss: 0.035661, acc: 98.44%] [G loss: 8.443175]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 164 13 [D loss: 0.002229, acc: 100.00%] [G loss: 7.243860]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 164 14 [D loss: 0.088450, acc: 95.31%] [G loss: 13.124704]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 164 15 [D loss: 0.011961, acc: 98.44%] [G loss: 24.113792]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 164 16 [D loss: 0.107688, acc: 98.44%] [G loss: 28.677891]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 164 17 [D loss: 0.156596, acc: 96.88%] [G loss: 22.833767]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 164 18 [D loss: 0.099938, acc: 95.31%] [G loss: 18.168247]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 164 19 [D loss: 0.000309, acc: 100.00%] [G loss: 10.937254]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 164 20 [D loss: 0.065343, acc: 96.88%] [G loss: 11.590057]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 164 21 [D loss: 0.008327, acc: 100.00%] [G loss: 14.613499]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 164 22 [D loss: 0.034720, acc: 98.44%] [G loss: 16.659279]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 165 0 [D loss: 0.000320, acc: 100.00%] [G loss: 14.303946]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 165 1 [D loss: 0.000858, acc: 100.00%] [G loss: 14.918330]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 165 2 [D loss: 0.028211, acc: 98.44%] [G loss: 13.586981]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 165 3 [D loss: 0.080581, acc: 96.88%] [G loss: 10.376225]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 165 4 [D loss: 0.004257, acc: 100.00%] [G loss: 8.974346]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 165 5 [D loss: 0.007224, acc: 100.00%] [G loss: 8.562903]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 165 6 [D loss: 0.063184, acc: 96.88%] [G loss: 6.441138]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 165 7 [D loss: 0.041939, acc: 98.44%] [G loss: 8.409176]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 165 8 [D loss: 0.016171, acc: 98.44%] [G loss: 10.723461]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 165 9 [D loss: 0.024758, acc: 98.44%] [G loss: 11.838920]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 165 10 [D loss: 0.004510, acc: 100.00%] [G loss: 11.397030]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 165 11 [D loss: 0.003791, acc: 100.00%] [G loss: 10.831985]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 165 12 [D loss: 0.085861, acc: 96.88%] [G loss: 9.130177]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 165 13 [D loss: 0.003859, acc: 100.00%] [G loss: 7.091795]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 165 14 [D loss: 0.028623, acc: 100.00%] [G loss: 6.900298]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 165 15 [D loss: 0.054517, acc: 96.88%] [G loss: 6.920835]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 165 16 [D loss: 0.004130, acc: 100.00%] [G loss: 9.293549]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 165 17 [D loss: 0.357841, acc: 98.44%] [G loss: 9.508265]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 165 18 [D loss: 0.207973, acc: 98.44%] [G loss: 8.357971]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 165 19 [D loss: 0.096958, acc: 96.88%] [G loss: 7.395257]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 165 20 [D loss: 0.011687, acc: 100.00%] [G loss: 9.482631]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 165 21 [D loss: 0.013950, acc: 100.00%] [G loss: 11.890152]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 165 22 [D loss: 0.121855, acc: 96.88%] [G loss: 11.942434]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 166 0 [D loss: 0.089278, acc: 96.88%] [G loss: 11.570141]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 166 1 [D loss: 0.040917, acc: 96.88%] [G loss: 10.702054]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 166 2 [D loss: 0.027900, acc: 98.44%] [G loss: 10.593229]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 166 3 [D loss: 0.006958, acc: 100.00%] [G loss: 8.883070]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 166 4 [D loss: 0.001798, acc: 100.00%] [G loss: 9.411116]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 166 5 [D loss: 0.002497, acc: 100.00%] [G loss: 9.194550]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 166 6 [D loss: 0.003273, acc: 100.00%] [G loss: 9.435411]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 166 7 [D loss: 0.020206, acc: 98.44%] [G loss: 8.381058]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 166 8 [D loss: 0.015164, acc: 100.00%] [G loss: 8.677929]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 166 9 [D loss: 0.013983, acc: 98.44%] [G loss: 8.116151]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 166 10 [D loss: 0.048066, acc: 96.88%] [G loss: 9.814464]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 166 11 [D loss: 0.058629, acc: 96.88%] [G loss: 9.341238]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 166 12 [D loss: 0.004772, acc: 100.00%] [G loss: 9.468431]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 166 13 [D loss: 0.002614, acc: 100.00%] [G loss: 8.922518]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 166 14 [D loss: 0.010983, acc: 100.00%] [G loss: 8.219533]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 166 15 [D loss: 0.007117, acc: 100.00%] [G loss: 8.986094]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 166 16 [D loss: 0.026459, acc: 98.44%] [G loss: 9.015070]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 166 17 [D loss: 0.093391, acc: 98.44%] [G loss: 7.974661]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 166 18 [D loss: 0.018478, acc: 98.44%] [G loss: 8.131575]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 166 19 [D loss: 0.043382, acc: 98.44%] [G loss: 8.958349]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 166 20 [D loss: 0.069982, acc: 96.88%] [G loss: 9.384521]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "******* 166 21 [D loss: 0.004165, acc: 100.00%] [G loss: 8.640287]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 166 22 [D loss: 0.005680, acc: 100.00%] [G loss: 7.633852]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 167 0 [D loss: 0.003158, acc: 100.00%] [G loss: 7.888619]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 167 1 [D loss: 0.018212, acc: 100.00%] [G loss: 8.845434]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 167 2 [D loss: 0.002050, acc: 100.00%] [G loss: 8.980152]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 167 3 [D loss: 0.029314, acc: 98.44%] [G loss: 9.017771]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 167 4 [D loss: 0.013348, acc: 100.00%] [G loss: 10.225909]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 167 5 [D loss: 0.058356, acc: 96.88%] [G loss: 9.376545]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 167 6 [D loss: 0.003872, acc: 100.00%] [G loss: 7.440022]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 167 7 [D loss: 0.057964, acc: 96.88%] [G loss: 7.053045]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 167 8 [D loss: 0.048008, acc: 98.44%] [G loss: 9.829009]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 167 9 [D loss: 0.036947, acc: 96.88%] [G loss: 10.938992]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 167 10 [D loss: 0.003068, acc: 100.00%] [G loss: 12.118886]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 167 11 [D loss: 0.040056, acc: 98.44%] [G loss: 10.740778]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 167 12 [D loss: 0.005391, acc: 100.00%] [G loss: 9.925878]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 167 13 [D loss: 0.040915, acc: 98.44%] [G loss: 8.174175]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 167 14 [D loss: 0.026999, acc: 100.00%] [G loss: 8.517241]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 167 15 [D loss: 0.037386, acc: 98.44%] [G loss: 7.510574]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 167 16 [D loss: 0.003015, acc: 100.00%] [G loss: 6.680972]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 167 17 [D loss: 0.002197, acc: 100.00%] [G loss: 6.937392]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 167 18 [D loss: 0.015259, acc: 100.00%] [G loss: 8.081894]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 167 19 [D loss: 0.008660, acc: 100.00%] [G loss: 8.347067]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 167 20 [D loss: 0.017399, acc: 98.44%] [G loss: 7.997798]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 167 21 [D loss: 0.001789, acc: 100.00%] [G loss: 8.840843]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 167 22 [D loss: 0.021345, acc: 98.44%] [G loss: 8.004818]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 168 0 [D loss: 0.019839, acc: 98.44%] [G loss: 7.382762]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 168 1 [D loss: 0.005194, acc: 100.00%] [G loss: 7.040127]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 168 2 [D loss: 0.003306, acc: 100.00%] [G loss: 7.177468]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 168 3 [D loss: 0.004583, acc: 100.00%] [G loss: 6.340758]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 168 4 [D loss: 0.001929, acc: 100.00%] [G loss: 7.651236]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 168 5 [D loss: 0.007844, acc: 100.00%] [G loss: 7.819134]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 168 6 [D loss: 0.005597, acc: 100.00%] [G loss: 9.159497]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 168 7 [D loss: 0.007259, acc: 100.00%] [G loss: 9.216398]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 168 8 [D loss: 0.034436, acc: 98.44%] [G loss: 9.509444]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 168 9 [D loss: 0.007043, acc: 100.00%] [G loss: 9.382652]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 168 10 [D loss: 0.006392, acc: 100.00%] [G loss: 8.604694]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 168 11 [D loss: 0.002315, acc: 100.00%] [G loss: 8.705074]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 168 12 [D loss: 0.008903, acc: 100.00%] [G loss: 8.141078]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 168 13 [D loss: 0.010006, acc: 100.00%] [G loss: 8.049403]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 168 14 [D loss: 0.062782, acc: 98.44%] [G loss: 7.364064]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 168 15 [D loss: 0.015003, acc: 100.00%] [G loss: 8.306737]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 168 16 [D loss: 0.139860, acc: 95.31%] [G loss: 8.693589]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 168 17 [D loss: 0.000657, acc: 100.00%] [G loss: 12.439713]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 168 18 [D loss: 0.039182, acc: 98.44%] [G loss: 13.660460]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 168 19 [D loss: 0.030588, acc: 98.44%] [G loss: 11.006929]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 168 20 [D loss: 0.063128, acc: 96.88%] [G loss: 6.475514]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 168 21 [D loss: 0.102416, acc: 95.31%] [G loss: 7.871723]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 168 22 [D loss: 0.004964, acc: 100.00%] [G loss: 13.443035]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 169 0 [D loss: 0.025954, acc: 98.44%] [G loss: 15.308470]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 169 1 [D loss: 0.018306, acc: 100.00%] [G loss: 16.245481]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 169 2 [D loss: 0.053324, acc: 98.44%] [G loss: 13.578592]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 169 3 [D loss: 0.004992, acc: 100.00%] [G loss: 9.188502]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 169 4 [D loss: 0.001568, acc: 100.00%] [G loss: 7.929688]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 169 5 [D loss: 0.091288, acc: 95.31%] [G loss: 9.679426]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 169 6 [D loss: 0.002121, acc: 100.00%] [G loss: 11.868708]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 169 7 [D loss: 0.010851, acc: 100.00%] [G loss: 14.558929]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 169 8 [D loss: 0.083185, acc: 93.75%] [G loss: 12.136769]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 169 9 [D loss: 0.001075, acc: 100.00%] [G loss: 10.217566]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 169 10 [D loss: 0.001478, acc: 100.00%] [G loss: 8.555492]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 169 11 [D loss: 0.024643, acc: 98.44%] [G loss: 7.285553]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 169 12 [D loss: 0.069167, acc: 96.88%] [G loss: 7.321348]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 169 13 [D loss: 0.025238, acc: 98.44%] [G loss: 7.809976]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 169 14 [D loss: 0.037134, acc: 98.44%] [G loss: 7.980233]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 169 15 [D loss: 0.012474, acc: 100.00%] [G loss: 8.950027]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 169 16 [D loss: 0.001566, acc: 100.00%] [G loss: 10.453117]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 169 17 [D loss: 0.000754, acc: 100.00%] [G loss: 10.465710]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 169 18 [D loss: 0.041141, acc: 98.44%] [G loss: 9.224216]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 169 19 [D loss: 0.028328, acc: 98.44%] [G loss: 8.856525]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 169 20 [D loss: 0.003003, acc: 100.00%] [G loss: 8.624800]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 169 21 [D loss: 0.024470, acc: 98.44%] [G loss: 7.322296]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 169 22 [D loss: 0.033218, acc: 98.44%] [G loss: 6.082846]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 170 0 [D loss: 0.019242, acc: 100.00%] [G loss: 6.334423]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 170 1 [D loss: 0.010582, acc: 100.00%] [G loss: 7.564630]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 170 2 [D loss: 0.007657, acc: 100.00%] [G loss: 9.127690]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 170 3 [D loss: 0.074699, acc: 98.44%] [G loss: 8.092651]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 170 4 [D loss: 0.009200, acc: 100.00%] [G loss: 7.826959]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 170 5 [D loss: 0.007564, acc: 100.00%] [G loss: 7.060230]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 170 6 [D loss: 0.053390, acc: 96.88%] [G loss: 5.670497]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 170 7 [D loss: 0.032326, acc: 98.44%] [G loss: 6.312573]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 170 8 [D loss: 0.037524, acc: 98.44%] [G loss: 9.277693]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 170 9 [D loss: 0.010408, acc: 100.00%] [G loss: 10.482163]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 170 10 [D loss: 0.021998, acc: 100.00%] [G loss: 10.466438]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 170 11 [D loss: 0.066943, acc: 98.44%] [G loss: 8.113031]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 170 12 [D loss: 0.003737, acc: 100.00%] [G loss: 5.452688]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 170 13 [D loss: 0.036077, acc: 100.00%] [G loss: 5.246334]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 170 14 [D loss: 0.097910, acc: 98.44%] [G loss: 6.418204]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 170 15 [D loss: 0.002376, acc: 100.00%] [G loss: 7.421784]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 170 16 [D loss: 0.013035, acc: 100.00%] [G loss: 8.737075]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 170 17 [D loss: 0.000504, acc: 100.00%] [G loss: 9.424552]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 170 18 [D loss: 0.001247, acc: 100.00%] [G loss: 10.420313]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 170 19 [D loss: 0.002117, acc: 100.00%] [G loss: 10.322929]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 170 20 [D loss: 0.009283, acc: 100.00%] [G loss: 10.018993]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 170 21 [D loss: 0.003212, acc: 100.00%] [G loss: 9.604992]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 170 22 [D loss: 0.001459, acc: 100.00%] [G loss: 10.026531]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 171 0 [D loss: 0.026396, acc: 98.44%] [G loss: 9.821534]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 171 1 [D loss: 0.022778, acc: 98.44%] [G loss: 9.161316]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 171 2 [D loss: 0.008456, acc: 100.00%] [G loss: 8.774595]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 171 3 [D loss: 0.002850, acc: 100.00%] [G loss: 8.542108]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 171 4 [D loss: 0.056475, acc: 96.88%] [G loss: 8.139705]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 171 5 [D loss: 0.010302, acc: 100.00%] [G loss: 8.346247]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 171 6 [D loss: 0.016023, acc: 100.00%] [G loss: 9.022858]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 171 7 [D loss: 0.003575, acc: 100.00%] [G loss: 9.593690]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 171 8 [D loss: 0.045398, acc: 98.44%] [G loss: 6.826824]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 171 9 [D loss: 0.013501, acc: 100.00%] [G loss: 5.000544]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 171 10 [D loss: 0.072450, acc: 96.88%] [G loss: 7.800531]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 171 11 [D loss: 0.000793, acc: 100.00%] [G loss: 12.466631]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 171 12 [D loss: 0.059796, acc: 96.88%] [G loss: 12.618421]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 171 13 [D loss: 0.193303, acc: 89.06%] [G loss: 4.919132]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 171 14 [D loss: 0.446349, acc: 82.81%] [G loss: 7.630656]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 171 15 [D loss: 0.000291, acc: 100.00%] [G loss: 17.568665]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 171 16 [D loss: 0.392080, acc: 92.19%] [G loss: 20.031895]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 171 17 [D loss: 0.083817, acc: 96.88%] [G loss: 17.360409]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 171 18 [D loss: 0.150718, acc: 93.75%] [G loss: 10.806032]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 171 19 [D loss: 0.119582, acc: 98.44%] [G loss: 6.997946]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 171 20 [D loss: 0.336739, acc: 87.50%] [G loss: 10.633959]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 171 21 [D loss: 0.000014, acc: 100.00%] [G loss: 17.371853]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 171 22 [D loss: 0.003292, acc: 100.00%] [G loss: 21.797279]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 172 0 [D loss: 0.277831, acc: 92.19%] [G loss: 20.903770]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 172 1 [D loss: 0.010538, acc: 100.00%] [G loss: 20.201336]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 172 2 [D loss: 0.000040, acc: 100.00%] [G loss: 18.710476]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 172 3 [D loss: 0.013757, acc: 98.44%] [G loss: 16.443222]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 172 4 [D loss: 0.000061, acc: 100.00%] [G loss: 14.589653]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 172 5 [D loss: 0.001597, acc: 100.00%] [G loss: 13.321887]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 172 6 [D loss: 0.000238, acc: 100.00%] [G loss: 10.775494]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 172 7 [D loss: 0.002283, acc: 100.00%] [G loss: 8.019507]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 172 8 [D loss: 0.046804, acc: 96.88%] [G loss: 7.089552]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 172 9 [D loss: 0.012527, acc: 100.00%] [G loss: 7.898869]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 172 10 [D loss: 0.002140, acc: 100.00%] [G loss: 7.830864]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 172 11 [D loss: 0.148116, acc: 98.44%] [G loss: 9.541804]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 172 12 [D loss: 0.023552, acc: 98.44%] [G loss: 9.993828]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 172 13 [D loss: 0.091007, acc: 98.44%] [G loss: 9.710923]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 172 14 [D loss: 0.033115, acc: 98.44%] [G loss: 10.214440]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 172 15 [D loss: 0.047504, acc: 98.44%] [G loss: 8.264783]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 172 16 [D loss: 0.015573, acc: 100.00%] [G loss: 6.497438]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 172 17 [D loss: 0.069984, acc: 95.31%] [G loss: 7.375562]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 172 18 [D loss: 0.006135, acc: 100.00%] [G loss: 10.023048]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 172 19 [D loss: 0.065725, acc: 96.88%] [G loss: 9.611570]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 172 20 [D loss: 0.049399, acc: 98.44%] [G loss: 8.182661]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 172 21 [D loss: 0.007424, acc: 100.00%] [G loss: 5.916122]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 172 22 [D loss: 0.034164, acc: 100.00%] [G loss: 7.799359]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 173 0 [D loss: 0.084781, acc: 95.31%] [G loss: 9.755621]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 173 1 [D loss: 0.048522, acc: 96.88%] [G loss: 13.099401]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 173 2 [D loss: 0.084191, acc: 96.88%] [G loss: 14.310593]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 173 3 [D loss: 0.074538, acc: 95.31%] [G loss: 12.233490]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 173 4 [D loss: 0.048413, acc: 98.44%] [G loss: 9.413401]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 173 5 [D loss: 0.051618, acc: 96.88%] [G loss: 8.232058]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 173 6 [D loss: 0.009369, acc: 100.00%] [G loss: 7.315246]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 173 7 [D loss: 0.010542, acc: 100.00%] [G loss: 8.415218]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 173 8 [D loss: 0.018027, acc: 100.00%] [G loss: 11.226986]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 173 9 [D loss: 0.115236, acc: 98.44%] [G loss: 10.736959]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 173 10 [D loss: 0.013493, acc: 98.44%] [G loss: 12.956812]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 173 11 [D loss: 0.001641, acc: 100.00%] [G loss: 14.436782]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 173 12 [D loss: 0.024375, acc: 98.44%] [G loss: 11.896648]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 173 13 [D loss: 0.018069, acc: 98.44%] [G loss: 10.295208]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 173 14 [D loss: 0.078587, acc: 95.31%] [G loss: 10.296876]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 173 15 [D loss: 0.021420, acc: 98.44%] [G loss: 11.421465]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 173 16 [D loss: 0.004795, acc: 100.00%] [G loss: 14.665804]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 173 17 [D loss: 0.056859, acc: 98.44%] [G loss: 13.605852]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 173 18 [D loss: 0.002648, acc: 100.00%] [G loss: 13.158472]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 173 19 [D loss: 0.003278, acc: 100.00%] [G loss: 11.733549]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 173 20 [D loss: 0.073050, acc: 96.88%] [G loss: 12.471972]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 173 21 [D loss: 0.011668, acc: 100.00%] [G loss: 17.078957]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 173 22 [D loss: 0.009659, acc: 100.00%] [G loss: 16.854343]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "******* 174 0 [D loss: 0.100044, acc: 98.44%] [G loss: 14.885834]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 174 1 [D loss: 0.132428, acc: 95.31%] [G loss: 15.361098]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 174 2 [D loss: 0.010985, acc: 100.00%] [G loss: 21.813892]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 174 3 [D loss: 0.106778, acc: 98.44%] [G loss: 19.623543]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "******* 174 4 [D loss: 0.132030, acc: 95.31%] [G loss: 9.594479]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 174 5 [D loss: 0.259882, acc: 92.19%] [G loss: 11.741199]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 174 6 [D loss: 0.004994, acc: 100.00%] [G loss: 11.503442]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 174 7 [D loss: 0.003135, acc: 100.00%] [G loss: 13.931999]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 174 8 [D loss: 0.017624, acc: 100.00%] [G loss: 12.513909]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 174 9 [D loss: 0.003273, acc: 100.00%] [G loss: 11.354004]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 174 10 [D loss: 0.031749, acc: 98.44%] [G loss: 10.846194]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "******* 174 11 [D loss: 0.051638, acc: 98.44%] [G loss: 11.921192]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 174 12 [D loss: 0.005982, acc: 100.00%] [G loss: 11.206883]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 174 13 [D loss: 0.067336, acc: 96.88%] [G loss: 9.440222]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 174 14 [D loss: 0.022621, acc: 98.44%] [G loss: 10.165365]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 174 15 [D loss: 0.019136, acc: 98.44%] [G loss: 10.104057]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 174 16 [D loss: 0.015711, acc: 100.00%] [G loss: 10.625687]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 174 17 [D loss: 0.006159, acc: 100.00%] [G loss: 11.139588]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 174 18 [D loss: 0.016431, acc: 100.00%] [G loss: 10.853802]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 174 19 [D loss: 0.048814, acc: 98.44%] [G loss: 12.178714]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 174 20 [D loss: 0.008674, acc: 100.00%] [G loss: 10.853276]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 174 21 [D loss: 0.075541, acc: 96.88%] [G loss: 8.973129]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 174 22 [D loss: 0.154032, acc: 92.19%] [G loss: 8.690157]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 175 0 [D loss: 0.015467, acc: 100.00%] [G loss: 12.321898]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 175 1 [D loss: 0.033915, acc: 98.44%] [G loss: 15.967896]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 175 2 [D loss: 0.345585, acc: 90.62%] [G loss: 4.885918]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 175 3 [D loss: 2.237764, acc: 75.00%] [G loss: 13.449938]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 175 4 [D loss: 0.013469, acc: 100.00%] [G loss: 30.744081]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 175 5 [D loss: 2.384905, acc: 64.06%] [G loss: 18.049873]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 175 6 [D loss: 2.622746, acc: 76.56%] [G loss: 13.256084]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 175 7 [D loss: 0.216881, acc: 95.31%] [G loss: 13.452209]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 175 8 [D loss: 0.184417, acc: 96.88%] [G loss: 10.434181]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 175 9 [D loss: 0.235935, acc: 95.31%] [G loss: 11.754072]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 175 10 [D loss: 0.079262, acc: 96.88%] [G loss: 14.031334]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 175 11 [D loss: 0.022230, acc: 98.44%] [G loss: 16.457832]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 175 12 [D loss: 0.036235, acc: 98.44%] [G loss: 14.421267]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 175 13 [D loss: 0.000621, acc: 100.00%] [G loss: 18.116703]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 175 14 [D loss: 0.026762, acc: 98.44%] [G loss: 16.495293]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 175 15 [D loss: 0.089057, acc: 96.88%] [G loss: 18.672741]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 175 16 [D loss: 0.002185, acc: 100.00%] [G loss: 17.330240]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 175 17 [D loss: 0.637114, acc: 93.75%] [G loss: 14.702878]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 175 18 [D loss: 0.001465, acc: 100.00%] [G loss: 12.015820]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 175 19 [D loss: 0.002525, acc: 100.00%] [G loss: 13.895294]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 175 20 [D loss: 0.047513, acc: 98.44%] [G loss: 10.706048]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 175 21 [D loss: 0.001584, acc: 100.00%] [G loss: 11.991161]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "******* 175 22 [D loss: 0.050113, acc: 98.44%] [G loss: 10.847828]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 176 0 [D loss: 0.018444, acc: 100.00%] [G loss: 10.793833]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 176 1 [D loss: 0.022642, acc: 98.44%] [G loss: 9.587000]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 176 2 [D loss: 0.001561, acc: 100.00%] [G loss: 13.279810]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 176 3 [D loss: 0.011349, acc: 100.00%] [G loss: 12.341898]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 176 4 [D loss: 0.009477, acc: 100.00%] [G loss: 10.801413]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 176 5 [D loss: 0.237451, acc: 95.31%] [G loss: 9.495416]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 176 6 [D loss: 0.037148, acc: 98.44%] [G loss: 10.697916]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 176 7 [D loss: 0.046715, acc: 96.88%] [G loss: 12.446816]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 176 8 [D loss: 0.055683, acc: 98.44%] [G loss: 12.476759]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 176 9 [D loss: 0.001323, acc: 100.00%] [G loss: 14.245503]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 176 10 [D loss: 0.049371, acc: 96.88%] [G loss: 12.453327]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 176 11 [D loss: 0.050621, acc: 98.44%] [G loss: 9.159887]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 176 12 [D loss: 0.013376, acc: 100.00%] [G loss: 7.787170]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 176 13 [D loss: 0.458392, acc: 87.50%] [G loss: 8.574541]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 176 14 [D loss: 0.000162, acc: 100.00%] [G loss: 12.915140]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 176 15 [D loss: 0.024052, acc: 98.44%] [G loss: 15.607548]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 176 16 [D loss: 0.013622, acc: 100.00%] [G loss: 18.082302]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 176 17 [D loss: 0.302959, acc: 93.75%] [G loss: 13.344593]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 176 18 [D loss: 0.021302, acc: 98.44%] [G loss: 9.756329]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 176 19 [D loss: 0.086976, acc: 96.88%] [G loss: 6.624273]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 176 20 [D loss: 0.114043, acc: 95.31%] [G loss: 5.776225]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 176 21 [D loss: 0.059073, acc: 98.44%] [G loss: 9.486775]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 176 22 [D loss: 0.005021, acc: 100.00%] [G loss: 11.233912]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 177 0 [D loss: 0.011020, acc: 100.00%] [G loss: 11.685149]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 177 1 [D loss: 0.054602, acc: 96.88%] [G loss: 13.504040]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 177 2 [D loss: 0.121559, acc: 96.88%] [G loss: 9.996704]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 177 3 [D loss: 0.049860, acc: 96.88%] [G loss: 9.124735]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 177 4 [D loss: 0.018017, acc: 100.00%] [G loss: 5.578869]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 177 5 [D loss: 0.178107, acc: 89.06%] [G loss: 5.518869]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 177 6 [D loss: 0.098276, acc: 96.88%] [G loss: 8.317149]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 177 7 [D loss: 0.068373, acc: 98.44%] [G loss: 11.328422]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 177 8 [D loss: 0.053507, acc: 98.44%] [G loss: 11.176100]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 177 9 [D loss: 0.011208, acc: 100.00%] [G loss: 10.133022]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 177 10 [D loss: 0.122242, acc: 96.88%] [G loss: 8.873425]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 177 11 [D loss: 0.050377, acc: 98.44%] [G loss: 7.055584]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 177 12 [D loss: 0.098386, acc: 96.88%] [G loss: 5.129778]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "******* 177 13 [D loss: 0.109650, acc: 92.19%] [G loss: 7.404835]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 177 14 [D loss: 0.007322, acc: 100.00%] [G loss: 10.752562]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 177 15 [D loss: 0.007047, acc: 100.00%] [G loss: 12.395187]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 177 16 [D loss: 0.075510, acc: 96.88%] [G loss: 12.043722]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 177 17 [D loss: 0.138814, acc: 98.44%] [G loss: 9.703272]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 177 18 [D loss: 0.088914, acc: 95.31%] [G loss: 5.767543]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 177 19 [D loss: 0.140232, acc: 96.88%] [G loss: 6.011357]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 177 20 [D loss: 0.026887, acc: 98.44%] [G loss: 9.528029]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 177 21 [D loss: 0.016535, acc: 98.44%] [G loss: 11.922031]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 177 22 [D loss: 0.158267, acc: 96.88%] [G loss: 10.788965]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 178 0 [D loss: 0.052496, acc: 98.44%] [G loss: 8.848041]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 178 1 [D loss: 0.115150, acc: 93.75%] [G loss: 8.368579]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 178 2 [D loss: 0.004443, acc: 100.00%] [G loss: 9.516249]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "******* 178 3 [D loss: 0.030458, acc: 96.88%] [G loss: 8.796877]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "******* 178 4 [D loss: 0.037153, acc: 98.44%] [G loss: 7.771699]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 178 5 [D loss: 0.006668, acc: 100.00%] [G loss: 6.286227]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 178 6 [D loss: 0.010099, acc: 100.00%] [G loss: 7.224785]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 178 7 [D loss: 0.068807, acc: 96.88%] [G loss: 9.686590]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 178 8 [D loss: 0.012375, acc: 100.00%] [G loss: 13.819994]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 178 9 [D loss: 0.006594, acc: 100.00%] [G loss: 14.925341]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 178 10 [D loss: 0.035163, acc: 98.44%] [G loss: 16.210989]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 178 11 [D loss: 0.014929, acc: 100.00%] [G loss: 13.673847]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 178 12 [D loss: 0.005167, acc: 100.00%] [G loss: 9.591022]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 178 13 [D loss: 0.047942, acc: 98.44%] [G loss: 8.050552]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 178 14 [D loss: 0.014659, acc: 100.00%] [G loss: 10.320644]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 178 15 [D loss: 0.042981, acc: 98.44%] [G loss: 10.126051]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 178 16 [D loss: 0.029268, acc: 98.44%] [G loss: 10.067154]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 178 17 [D loss: 0.010384, acc: 100.00%] [G loss: 9.304478]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 178 18 [D loss: 0.053071, acc: 98.44%] [G loss: 8.858480]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 178 19 [D loss: 0.021309, acc: 100.00%] [G loss: 9.857559]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 178 20 [D loss: 0.072803, acc: 98.44%] [G loss: 7.366260]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 178 21 [D loss: 0.006136, acc: 100.00%] [G loss: 7.744449]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 178 22 [D loss: 0.227762, acc: 89.06%] [G loss: 10.430023]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 179 0 [D loss: 0.103911, acc: 98.44%] [G loss: 18.814501]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 179 1 [D loss: 0.391218, acc: 87.50%] [G loss: 10.501691]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 179 2 [D loss: 0.083302, acc: 98.44%] [G loss: 4.669752]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 179 3 [D loss: 0.990167, acc: 73.44%] [G loss: 16.451658]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 179 4 [D loss: 0.342356, acc: 98.44%] [G loss: 34.368294]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 179 5 [D loss: 0.648771, acc: 82.81%] [G loss: 36.832802]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 179 6 [D loss: 0.201583, acc: 92.19%] [G loss: 31.697277]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 179 7 [D loss: 0.094018, acc: 98.44%] [G loss: 26.041420]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 179 8 [D loss: 0.020419, acc: 98.44%] [G loss: 18.873257]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 179 9 [D loss: 0.000156, acc: 100.00%] [G loss: 14.906723]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 179 10 [D loss: 0.058004, acc: 98.44%] [G loss: 9.797828]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 179 11 [D loss: 0.090698, acc: 95.31%] [G loss: 7.000339]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 179 12 [D loss: 0.047046, acc: 98.44%] [G loss: 8.444461]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 179 13 [D loss: 0.001996, acc: 100.00%] [G loss: 9.973803]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 179 14 [D loss: 0.000788, acc: 100.00%] [G loss: 11.022683]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 179 15 [D loss: 0.008754, acc: 100.00%] [G loss: 11.750477]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 179 16 [D loss: 0.006048, acc: 100.00%] [G loss: 11.596707]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 179 17 [D loss: 0.062038, acc: 96.88%] [G loss: 11.323856]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 179 18 [D loss: 0.016241, acc: 98.44%] [G loss: 9.578508]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 179 19 [D loss: 0.129020, acc: 96.88%] [G loss: 9.007662]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 179 20 [D loss: 0.016627, acc: 98.44%] [G loss: 8.037093]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 179 21 [D loss: 0.074070, acc: 96.88%] [G loss: 6.301558]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 179 22 [D loss: 0.068787, acc: 96.88%] [G loss: 6.600880]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 180 0 [D loss: 0.058394, acc: 98.44%] [G loss: 8.086009]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 180 1 [D loss: 0.042397, acc: 98.44%] [G loss: 9.356230]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 180 2 [D loss: 0.005798, acc: 100.00%] [G loss: 10.185165]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 180 3 [D loss: 0.079908, acc: 96.88%] [G loss: 7.948981]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 180 4 [D loss: 0.021752, acc: 98.44%] [G loss: 8.082648]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 180 5 [D loss: 0.008820, acc: 100.00%] [G loss: 5.727199]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 180 6 [D loss: 0.039332, acc: 98.44%] [G loss: 5.113893]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 180 7 [D loss: 0.493624, acc: 89.06%] [G loss: 4.723351]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 180 8 [D loss: 0.012821, acc: 100.00%] [G loss: 9.080214]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 180 9 [D loss: 0.036258, acc: 96.88%] [G loss: 10.716185]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 180 10 [D loss: 0.016287, acc: 100.00%] [G loss: 12.509943]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 180 11 [D loss: 0.176963, acc: 92.19%] [G loss: 12.013069]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 180 12 [D loss: 0.011783, acc: 100.00%] [G loss: 8.685143]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 180 13 [D loss: 0.034342, acc: 98.44%] [G loss: 5.422383]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 180 14 [D loss: 0.022394, acc: 100.00%] [G loss: 6.859236]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 180 15 [D loss: 0.024948, acc: 100.00%] [G loss: 7.239603]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 180 16 [D loss: 0.003680, acc: 100.00%] [G loss: 7.883227]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 180 17 [D loss: 0.011595, acc: 100.00%] [G loss: 10.204400]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 180 18 [D loss: 0.066593, acc: 98.44%] [G loss: 10.396168]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 180 19 [D loss: 0.015864, acc: 98.44%] [G loss: 10.324251]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 180 20 [D loss: 0.073316, acc: 95.31%] [G loss: 7.639931]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 180 21 [D loss: 0.257013, acc: 95.31%] [G loss: 7.533449]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 180 22 [D loss: 0.025987, acc: 98.44%] [G loss: 8.590160]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 181 0 [D loss: 0.039408, acc: 98.44%] [G loss: 9.465199]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 181 1 [D loss: 0.020539, acc: 98.44%] [G loss: 9.446753]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 181 2 [D loss: 0.027953, acc: 98.44%] [G loss: 9.996402]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 181 3 [D loss: 0.036171, acc: 98.44%] [G loss: 9.567336]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 181 4 [D loss: 0.002897, acc: 100.00%] [G loss: 9.852775]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 181 5 [D loss: 0.009535, acc: 100.00%] [G loss: 9.465081]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 181 6 [D loss: 0.020932, acc: 98.44%] [G loss: 8.582933]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 181 7 [D loss: 0.056985, acc: 96.88%] [G loss: 8.291378]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 181 8 [D loss: 0.012688, acc: 100.00%] [G loss: 8.298050]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 181 9 [D loss: 0.033191, acc: 98.44%] [G loss: 8.783451]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 181 10 [D loss: 0.007507, acc: 100.00%] [G loss: 8.610384]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 181 11 [D loss: 0.015492, acc: 100.00%] [G loss: 10.063876]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 181 12 [D loss: 0.041073, acc: 98.44%] [G loss: 8.247975]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 181 13 [D loss: 0.238058, acc: 96.88%] [G loss: 7.241567]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 181 14 [D loss: 0.072838, acc: 98.44%] [G loss: 6.623560]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 181 15 [D loss: 0.014321, acc: 100.00%] [G loss: 8.348705]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 181 16 [D loss: 0.040059, acc: 98.44%] [G loss: 9.822138]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 181 17 [D loss: 0.079301, acc: 95.31%] [G loss: 10.932211]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 181 18 [D loss: 0.015304, acc: 100.00%] [G loss: 11.151176]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 181 19 [D loss: 0.007558, acc: 100.00%] [G loss: 10.690966]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 181 20 [D loss: 0.001758, acc: 100.00%] [G loss: 10.466693]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 181 21 [D loss: 0.014104, acc: 98.44%] [G loss: 9.398952]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 181 22 [D loss: 0.002468, acc: 100.00%] [G loss: 8.917429]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 182 0 [D loss: 0.028603, acc: 98.44%] [G loss: 7.248781]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 182 1 [D loss: 0.051020, acc: 98.44%] [G loss: 8.802963]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 182 2 [D loss: 0.004487, acc: 100.00%] [G loss: 10.479265]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 182 3 [D loss: 0.005070, acc: 100.00%] [G loss: 11.242855]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 182 4 [D loss: 0.068159, acc: 96.88%] [G loss: 9.933875]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 182 5 [D loss: 0.010898, acc: 100.00%] [G loss: 8.033312]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "******* 182 6 [D loss: 0.011978, acc: 100.00%] [G loss: 6.595692]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 182 7 [D loss: 0.051150, acc: 96.88%] [G loss: 5.961490]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 182 8 [D loss: 0.002847, acc: 100.00%] [G loss: 8.875625]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 182 9 [D loss: 0.013853, acc: 100.00%] [G loss: 10.336740]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 182 10 [D loss: 0.047065, acc: 96.88%] [G loss: 9.009296]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "******* 182 11 [D loss: 0.061336, acc: 98.44%] [G loss: 8.578218]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 182 12 [D loss: 0.021400, acc: 98.44%] [G loss: 8.982319]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 182 13 [D loss: 0.047030, acc: 98.44%] [G loss: 9.029549]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 182 14 [D loss: 0.007539, acc: 100.00%] [G loss: 8.718328]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 182 15 [D loss: 0.008073, acc: 100.00%] [G loss: 8.060193]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 182 16 [D loss: 0.026588, acc: 98.44%] [G loss: 8.817509]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 182 17 [D loss: 0.047194, acc: 96.88%] [G loss: 7.764342]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 182 18 [D loss: 0.014425, acc: 100.00%] [G loss: 7.808917]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 182 19 [D loss: 0.025351, acc: 98.44%] [G loss: 8.521158]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 182 20 [D loss: 0.034599, acc: 98.44%] [G loss: 9.143442]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 182 21 [D loss: 0.062773, acc: 96.88%] [G loss: 7.818327]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 182 22 [D loss: 0.071480, acc: 95.31%] [G loss: 6.526874]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 183 0 [D loss: 0.020945, acc: 98.44%] [G loss: 8.871822]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 183 1 [D loss: 0.005591, acc: 100.00%] [G loss: 10.963467]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 183 2 [D loss: 0.004082, acc: 100.00%] [G loss: 10.266336]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 183 3 [D loss: 0.040198, acc: 96.88%] [G loss: 10.207670]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 183 4 [D loss: 0.008867, acc: 100.00%] [G loss: 8.634226]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 183 5 [D loss: 0.039310, acc: 100.00%] [G loss: 7.958854]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 183 6 [D loss: 0.005328, acc: 100.00%] [G loss: 9.677557]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 183 7 [D loss: 0.003642, acc: 100.00%] [G loss: 12.103179]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 183 8 [D loss: 0.076249, acc: 98.44%] [G loss: 10.243999]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 183 9 [D loss: 0.025888, acc: 98.44%] [G loss: 7.123653]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 183 10 [D loss: 0.517194, acc: 95.31%] [G loss: 7.255821]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 183 11 [D loss: 0.001039, acc: 100.00%] [G loss: 11.418718]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 183 12 [D loss: 0.023868, acc: 98.44%] [G loss: 12.298925]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 183 13 [D loss: 0.007405, acc: 100.00%] [G loss: 10.022362]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 183 14 [D loss: 0.006191, acc: 100.00%] [G loss: 10.717935]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 183 15 [D loss: 0.004777, acc: 100.00%] [G loss: 10.629212]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 183 16 [D loss: 0.007170, acc: 100.00%] [G loss: 9.679384]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 183 17 [D loss: 0.000742, acc: 100.00%] [G loss: 9.349449]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 183 18 [D loss: 0.004914, acc: 100.00%] [G loss: 9.800690]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 183 19 [D loss: 0.002883, acc: 100.00%] [G loss: 10.509405]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 183 20 [D loss: 0.010518, acc: 100.00%] [G loss: 8.452070]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 183 21 [D loss: 0.001263, acc: 100.00%] [G loss: 10.039543]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "******* 183 22 [D loss: 0.004722, acc: 100.00%] [G loss: 8.346930]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 184 0 [D loss: 0.038042, acc: 98.44%] [G loss: 6.337591]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 184 1 [D loss: 0.084606, acc: 96.88%] [G loss: 6.059047]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 184 2 [D loss: 0.012213, acc: 100.00%] [G loss: 10.236768]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 184 3 [D loss: 0.031929, acc: 98.44%] [G loss: 10.068787]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 184 4 [D loss: 0.267715, acc: 90.62%] [G loss: 6.092625]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 184 5 [D loss: 0.157688, acc: 92.19%] [G loss: 6.482409]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 184 6 [D loss: 0.003165, acc: 100.00%] [G loss: 11.490803]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 184 7 [D loss: 0.110048, acc: 96.88%] [G loss: 13.764574]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 184 8 [D loss: 0.077167, acc: 96.88%] [G loss: 12.102353]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 184 9 [D loss: 0.006625, acc: 100.00%] [G loss: 11.043604]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 184 10 [D loss: 0.106757, acc: 95.31%] [G loss: 7.258615]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 184 11 [D loss: 0.070290, acc: 96.88%] [G loss: 4.985953]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 184 12 [D loss: 0.053198, acc: 98.44%] [G loss: 6.214405]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 184 13 [D loss: 0.002869, acc: 100.00%] [G loss: 8.628582]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 184 14 [D loss: 0.058949, acc: 98.44%] [G loss: 11.212515]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 184 15 [D loss: 0.010114, acc: 100.00%] [G loss: 12.009321]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 184 16 [D loss: 0.078544, acc: 96.88%] [G loss: 11.874950]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 184 17 [D loss: 0.015491, acc: 100.00%] [G loss: 8.801022]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 184 18 [D loss: 0.009746, acc: 100.00%] [G loss: 6.942087]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 184 19 [D loss: 0.007250, acc: 100.00%] [G loss: 5.943136]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 184 20 [D loss: 0.018197, acc: 100.00%] [G loss: 6.199532]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 184 21 [D loss: 0.008070, acc: 100.00%] [G loss: 7.827984]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 184 22 [D loss: 0.004138, acc: 100.00%] [G loss: 9.048176]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 185 0 [D loss: 0.017182, acc: 100.00%] [G loss: 9.248668]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "******* 185 1 [D loss: 0.060272, acc: 98.44%] [G loss: 7.930137]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 185 2 [D loss: 0.061910, acc: 98.44%] [G loss: 8.653334]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 185 3 [D loss: 0.017493, acc: 100.00%] [G loss: 11.252701]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 185 4 [D loss: 0.004851, acc: 100.00%] [G loss: 12.601805]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 185 5 [D loss: 0.031279, acc: 98.44%] [G loss: 11.498897]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 185 6 [D loss: 0.098793, acc: 95.31%] [G loss: 7.555908]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 185 7 [D loss: 0.356000, acc: 85.94%] [G loss: 15.164536]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "******* 185 8 [D loss: 0.012257, acc: 100.00%] [G loss: 29.493954]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 185 9 [D loss: 0.296353, acc: 92.19%] [G loss: 32.433075]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 185 10 [D loss: 1.078965, acc: 84.38%] [G loss: 23.367575]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 185 11 [D loss: 0.055274, acc: 98.44%] [G loss: 14.064807]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 185 12 [D loss: 0.772931, acc: 87.50%] [G loss: 13.729231]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 185 13 [D loss: 0.000392, acc: 100.00%] [G loss: 20.343807]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 185 14 [D loss: 0.000004, acc: 100.00%] [G loss: 24.682795]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 185 15 [D loss: 0.000090, acc: 100.00%] [G loss: 25.484005]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 185 16 [D loss: 0.000096, acc: 100.00%] [G loss: 26.322712]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 185 17 [D loss: 0.000040, acc: 100.00%] [G loss: 27.693583]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 185 18 [D loss: 0.002222, acc: 100.00%] [G loss: 27.271612]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 185 19 [D loss: 0.046946, acc: 98.44%] [G loss: 23.269497]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 185 20 [D loss: 0.061960, acc: 98.44%] [G loss: 19.661966]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 185 21 [D loss: 0.173979, acc: 96.88%] [G loss: 13.760883]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 185 22 [D loss: 0.000739, acc: 100.00%] [G loss: 9.704214]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 186 0 [D loss: 0.095744, acc: 98.44%] [G loss: 8.877441]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 186 1 [D loss: 0.127416, acc: 96.88%] [G loss: 9.289722]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 186 2 [D loss: 0.095351, acc: 96.88%] [G loss: 11.228157]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 186 3 [D loss: 0.003628, acc: 100.00%] [G loss: 13.342510]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 186 4 [D loss: 0.000879, acc: 100.00%] [G loss: 13.756033]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 186 5 [D loss: 0.026182, acc: 98.44%] [G loss: 12.605116]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 186 6 [D loss: 0.102427, acc: 96.88%] [G loss: 11.183393]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 186 7 [D loss: 0.003727, acc: 100.00%] [G loss: 10.015553]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 186 8 [D loss: 0.101802, acc: 95.31%] [G loss: 7.640069]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 186 9 [D loss: 0.080927, acc: 98.44%] [G loss: 6.006338]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 186 10 [D loss: 0.037890, acc: 98.44%] [G loss: 7.733912]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 186 11 [D loss: 0.066465, acc: 96.88%] [G loss: 8.573205]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 186 12 [D loss: 0.039188, acc: 98.44%] [G loss: 7.247209]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 186 13 [D loss: 0.022600, acc: 100.00%] [G loss: 7.327994]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 186 14 [D loss: 0.057259, acc: 98.44%] [G loss: 7.967272]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 186 15 [D loss: 0.134354, acc: 96.88%] [G loss: 7.998091]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 186 16 [D loss: 0.003381, acc: 100.00%] [G loss: 10.827280]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 186 17 [D loss: 0.098530, acc: 98.44%] [G loss: 10.167917]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 186 18 [D loss: 0.003428, acc: 100.00%] [G loss: 9.748848]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 186 19 [D loss: 0.004371, acc: 100.00%] [G loss: 9.276563]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 186 20 [D loss: 0.024632, acc: 98.44%] [G loss: 7.638318]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 186 21 [D loss: 0.010916, acc: 100.00%] [G loss: 6.542749]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 186 22 [D loss: 0.019994, acc: 100.00%] [G loss: 8.059834]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 187 0 [D loss: 0.039134, acc: 96.88%] [G loss: 7.583304]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 187 1 [D loss: 0.012985, acc: 100.00%] [G loss: 10.244894]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 187 2 [D loss: 0.001524, acc: 100.00%] [G loss: 10.302991]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 187 3 [D loss: 0.028065, acc: 100.00%] [G loss: 9.745957]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 187 4 [D loss: 0.038273, acc: 98.44%] [G loss: 9.184837]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 187 5 [D loss: 0.027128, acc: 100.00%] [G loss: 8.407675]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 187 6 [D loss: 0.087267, acc: 96.88%] [G loss: 6.573610]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 187 7 [D loss: 0.022753, acc: 100.00%] [G loss: 6.416120]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 187 8 [D loss: 0.077106, acc: 95.31%] [G loss: 7.436120]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 187 9 [D loss: 0.009921, acc: 100.00%] [G loss: 11.315701]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 187 10 [D loss: 0.043746, acc: 96.88%] [G loss: 11.774363]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 187 11 [D loss: 0.010878, acc: 100.00%] [G loss: 11.151377]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "******* 187 12 [D loss: 0.075284, acc: 96.88%] [G loss: 8.702479]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 187 13 [D loss: 0.014836, acc: 100.00%] [G loss: 7.622713]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 187 14 [D loss: 0.015315, acc: 100.00%] [G loss: 7.159243]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 187 15 [D loss: 0.072234, acc: 96.88%] [G loss: 7.463593]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 187 16 [D loss: 0.045783, acc: 98.44%] [G loss: 9.208805]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 187 17 [D loss: 0.010234, acc: 100.00%] [G loss: 10.958815]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "******* 187 18 [D loss: 0.039916, acc: 98.44%] [G loss: 11.515183]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 187 19 [D loss: 0.078735, acc: 96.88%] [G loss: 11.276861]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 187 20 [D loss: 0.006067, acc: 100.00%] [G loss: 12.498796]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 187 21 [D loss: 0.002455, acc: 100.00%] [G loss: 11.844579]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 187 22 [D loss: 0.001940, acc: 100.00%] [G loss: 12.636638]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 188 0 [D loss: 0.001344, acc: 100.00%] [G loss: 11.611202]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 188 1 [D loss: 0.001279, acc: 100.00%] [G loss: 10.768328]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 188 2 [D loss: 0.020620, acc: 98.44%] [G loss: 8.744554]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 188 3 [D loss: 0.021647, acc: 98.44%] [G loss: 7.479218]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 188 4 [D loss: 0.019179, acc: 100.00%] [G loss: 7.858431]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 188 5 [D loss: 0.019721, acc: 100.00%] [G loss: 10.095285]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 188 6 [D loss: 0.019147, acc: 100.00%] [G loss: 10.648478]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 188 7 [D loss: 0.051269, acc: 96.88%] [G loss: 9.332972]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 188 8 [D loss: 0.045224, acc: 98.44%] [G loss: 7.290336]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 188 9 [D loss: 0.008367, acc: 100.00%] [G loss: 7.278602]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 188 10 [D loss: 0.084903, acc: 96.88%] [G loss: 7.478110]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 188 11 [D loss: 0.060267, acc: 98.44%] [G loss: 8.579285]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 188 12 [D loss: 0.030137, acc: 98.44%] [G loss: 10.398363]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 188 13 [D loss: 0.115873, acc: 95.31%] [G loss: 6.629713]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 188 14 [D loss: 0.079741, acc: 96.88%] [G loss: 5.878022]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 188 15 [D loss: 0.064846, acc: 98.44%] [G loss: 5.929975]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 188 16 [D loss: 0.145497, acc: 96.88%] [G loss: 7.628426]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 188 17 [D loss: 0.011542, acc: 100.00%] [G loss: 6.824177]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "******* 188 18 [D loss: 0.009901, acc: 100.00%] [G loss: 8.671417]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 188 19 [D loss: 0.005342, acc: 100.00%] [G loss: 7.639113]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 188 20 [D loss: 0.028866, acc: 100.00%] [G loss: 7.400001]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 188 21 [D loss: 0.026583, acc: 100.00%] [G loss: 7.665765]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 188 22 [D loss: 0.136261, acc: 98.44%] [G loss: 5.837817]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 189 0 [D loss: 0.014338, acc: 100.00%] [G loss: 6.333958]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 189 1 [D loss: 0.095737, acc: 98.44%] [G loss: 8.452615]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 189 2 [D loss: 0.083286, acc: 95.31%] [G loss: 7.325472]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 189 3 [D loss: 0.043819, acc: 96.88%] [G loss: 7.155942]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 189 4 [D loss: 0.007618, acc: 100.00%] [G loss: 7.676633]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 189 5 [D loss: 0.016978, acc: 98.44%] [G loss: 8.222004]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 189 6 [D loss: 0.002472, acc: 100.00%] [G loss: 8.729981]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 189 7 [D loss: 0.006289, acc: 100.00%] [G loss: 7.888680]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 189 8 [D loss: 0.007579, acc: 100.00%] [G loss: 8.610037]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 189 9 [D loss: 0.072833, acc: 98.44%] [G loss: 8.425963]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 189 10 [D loss: 0.010415, acc: 100.00%] [G loss: 9.256464]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 189 11 [D loss: 0.006256, acc: 100.00%] [G loss: 8.608038]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 189 12 [D loss: 0.001067, acc: 100.00%] [G loss: 9.940979]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 189 13 [D loss: 0.008189, acc: 100.00%] [G loss: 10.825010]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 189 14 [D loss: 0.010735, acc: 100.00%] [G loss: 11.787107]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 189 15 [D loss: 0.001458, acc: 100.00%] [G loss: 12.432870]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 189 16 [D loss: 0.010775, acc: 100.00%] [G loss: 13.178910]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 189 17 [D loss: 0.003601, acc: 100.00%] [G loss: 13.086324]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 189 18 [D loss: 0.010878, acc: 100.00%] [G loss: 11.789806]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 189 19 [D loss: 0.001738, acc: 100.00%] [G loss: 9.211906]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 189 20 [D loss: 0.005336, acc: 100.00%] [G loss: 8.203025]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 189 21 [D loss: 0.019270, acc: 100.00%] [G loss: 7.295467]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 189 22 [D loss: 0.034665, acc: 100.00%] [G loss: 9.492165]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 190 0 [D loss: 0.006414, acc: 100.00%] [G loss: 12.725899]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 190 1 [D loss: 0.010043, acc: 100.00%] [G loss: 14.794958]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 190 2 [D loss: 0.086434, acc: 96.88%] [G loss: 9.854062]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 190 3 [D loss: 0.067131, acc: 98.44%] [G loss: 7.514067]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 190 4 [D loss: 0.130123, acc: 93.75%] [G loss: 8.253908]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 190 5 [D loss: 0.001871, acc: 100.00%] [G loss: 16.780596]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 190 6 [D loss: 0.011737, acc: 100.00%] [G loss: 17.775787]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 190 7 [D loss: 0.313101, acc: 87.50%] [G loss: 11.557348]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 190 8 [D loss: 0.084903, acc: 96.88%] [G loss: 7.110103]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 190 9 [D loss: 0.149156, acc: 93.75%] [G loss: 9.192575]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 190 10 [D loss: 0.000388, acc: 100.00%] [G loss: 14.295811]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 190 11 [D loss: 0.000387, acc: 100.00%] [G loss: 16.830654]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 190 12 [D loss: 0.087180, acc: 96.88%] [G loss: 16.397898]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 190 13 [D loss: 0.055297, acc: 98.44%] [G loss: 13.406933]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 190 14 [D loss: 0.003130, acc: 100.00%] [G loss: 9.428349]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 190 15 [D loss: 0.005265, acc: 100.00%] [G loss: 6.516366]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 190 16 [D loss: 0.072402, acc: 95.31%] [G loss: 6.135645]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 190 17 [D loss: 0.041391, acc: 98.44%] [G loss: 9.416479]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 190 18 [D loss: 0.044539, acc: 98.44%] [G loss: 11.069023]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 190 19 [D loss: 0.007516, acc: 100.00%] [G loss: 11.998880]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 190 20 [D loss: 0.100700, acc: 95.31%] [G loss: 8.890549]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 190 21 [D loss: 0.006449, acc: 100.00%] [G loss: 5.669766]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 190 22 [D loss: 0.398988, acc: 87.50%] [G loss: 8.756205]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 191 0 [D loss: 0.012557, acc: 100.00%] [G loss: 17.317644]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 191 1 [D loss: 0.031348, acc: 98.44%] [G loss: 22.016369]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 191 2 [D loss: 0.302976, acc: 90.62%] [G loss: 19.196035]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 191 3 [D loss: 0.066041, acc: 95.31%] [G loss: 12.685576]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 191 4 [D loss: 0.010925, acc: 100.00%] [G loss: 8.259823]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 191 5 [D loss: 0.151312, acc: 95.31%] [G loss: 7.046620]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 191 6 [D loss: 0.096953, acc: 95.31%] [G loss: 10.695908]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 191 7 [D loss: 0.000048, acc: 100.00%] [G loss: 18.040680]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 191 8 [D loss: 0.009778, acc: 100.00%] [G loss: 21.143984]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 191 9 [D loss: 0.053452, acc: 96.88%] [G loss: 21.864656]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 191 10 [D loss: 0.059343, acc: 98.44%] [G loss: 20.205648]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 191 11 [D loss: 0.013828, acc: 100.00%] [G loss: 18.481102]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 191 12 [D loss: 0.001759, acc: 100.00%] [G loss: 16.101051]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 191 13 [D loss: 0.006148, acc: 100.00%] [G loss: 14.348778]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 191 14 [D loss: 0.040923, acc: 98.44%] [G loss: 10.157907]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 191 15 [D loss: 0.036377, acc: 96.88%] [G loss: 9.826058]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 191 16 [D loss: 0.010757, acc: 100.00%] [G loss: 9.015091]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 191 17 [D loss: 0.015257, acc: 100.00%] [G loss: 8.146272]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 191 18 [D loss: 0.040931, acc: 98.44%] [G loss: 9.463442]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 191 19 [D loss: 0.005744, acc: 100.00%] [G loss: 12.483124]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 191 20 [D loss: 0.001484, acc: 100.00%] [G loss: 13.691486]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 191 21 [D loss: 0.008337, acc: 100.00%] [G loss: 13.738243]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 191 22 [D loss: 0.020990, acc: 100.00%] [G loss: 12.904852]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 192 0 [D loss: 0.039496, acc: 98.44%] [G loss: 11.684261]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 192 1 [D loss: 0.003814, acc: 100.00%] [G loss: 9.980818]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 192 2 [D loss: 0.050456, acc: 96.88%] [G loss: 8.319117]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 192 3 [D loss: 0.030057, acc: 98.44%] [G loss: 7.236237]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 192 4 [D loss: 0.021786, acc: 98.44%] [G loss: 8.071651]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 192 5 [D loss: 0.002828, acc: 100.00%] [G loss: 9.241522]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 192 6 [D loss: 0.000722, acc: 100.00%] [G loss: 11.082375]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 192 7 [D loss: 0.005678, acc: 100.00%] [G loss: 10.028831]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 192 8 [D loss: 0.096396, acc: 96.88%] [G loss: 7.957229]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 192 9 [D loss: 0.009235, acc: 100.00%] [G loss: 6.570727]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 192 10 [D loss: 0.110329, acc: 95.31%] [G loss: 7.882151]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 192 11 [D loss: 0.004037, acc: 100.00%] [G loss: 10.223603]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 192 12 [D loss: 0.085164, acc: 98.44%] [G loss: 11.990395]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 192 13 [D loss: 0.003858, acc: 100.00%] [G loss: 12.595886]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 192 14 [D loss: 0.020975, acc: 98.44%] [G loss: 11.751446]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 192 15 [D loss: 0.052006, acc: 98.44%] [G loss: 10.433980]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 192 16 [D loss: 0.006909, acc: 100.00%] [G loss: 8.778667]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 192 17 [D loss: 0.026817, acc: 98.44%] [G loss: 7.039350]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 192 18 [D loss: 0.003263, acc: 100.00%] [G loss: 8.212395]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 192 19 [D loss: 0.002426, acc: 100.00%] [G loss: 8.014892]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 192 20 [D loss: 0.012794, acc: 100.00%] [G loss: 9.221336]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 192 21 [D loss: 0.001234, acc: 100.00%] [G loss: 8.895328]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 192 22 [D loss: 0.000739, acc: 100.00%] [G loss: 10.505401]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 193 0 [D loss: 0.002769, acc: 100.00%] [G loss: 9.484509]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 193 1 [D loss: 0.003508, acc: 100.00%] [G loss: 8.708179]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 193 2 [D loss: 0.061328, acc: 95.31%] [G loss: 9.192786]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 193 3 [D loss: 0.033208, acc: 98.44%] [G loss: 9.355823]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 193 4 [D loss: 0.002466, acc: 100.00%] [G loss: 9.406425]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 193 5 [D loss: 0.000934, acc: 100.00%] [G loss: 11.197938]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 193 6 [D loss: 0.001484, acc: 100.00%] [G loss: 11.385452]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 193 7 [D loss: 0.008730, acc: 100.00%] [G loss: 11.425615]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 193 8 [D loss: 0.108207, acc: 96.88%] [G loss: 8.235373]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 193 9 [D loss: 0.213393, acc: 93.75%] [G loss: 7.215265]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 193 10 [D loss: 0.007839, acc: 100.00%] [G loss: 9.911418]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 193 11 [D loss: 0.000673, acc: 100.00%] [G loss: 12.070606]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 193 12 [D loss: 0.000230, acc: 100.00%] [G loss: 14.663222]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 193 13 [D loss: 0.040337, acc: 96.88%] [G loss: 15.615585]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 193 14 [D loss: 0.000888, acc: 100.00%] [G loss: 14.523611]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 193 15 [D loss: 0.000111, acc: 100.00%] [G loss: 15.876312]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 193 16 [D loss: 0.000155, acc: 100.00%] [G loss: 15.666191]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 193 17 [D loss: 0.018329, acc: 100.00%] [G loss: 12.472467]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 193 18 [D loss: 0.000814, acc: 100.00%] [G loss: 10.395900]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 193 19 [D loss: 0.022292, acc: 100.00%] [G loss: 9.484934]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 193 20 [D loss: 0.001138, acc: 100.00%] [G loss: 11.009333]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 193 21 [D loss: 0.016964, acc: 100.00%] [G loss: 10.479783]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 193 22 [D loss: 0.019788, acc: 100.00%] [G loss: 9.608303]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 194 0 [D loss: 0.001817, acc: 100.00%] [G loss: 9.454442]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 194 1 [D loss: 0.019086, acc: 100.00%] [G loss: 10.813284]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 194 2 [D loss: 0.020885, acc: 98.44%] [G loss: 11.125994]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 194 3 [D loss: 0.063732, acc: 98.44%] [G loss: 7.939134]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 194 4 [D loss: 0.006294, acc: 100.00%] [G loss: 7.591062]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 194 5 [D loss: 0.025995, acc: 100.00%] [G loss: 7.488950]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 194 6 [D loss: 0.001697, acc: 100.00%] [G loss: 7.958061]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 194 7 [D loss: 0.009690, acc: 100.00%] [G loss: 9.614000]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 194 8 [D loss: 0.059802, acc: 96.88%] [G loss: 11.226839]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 194 9 [D loss: 0.046864, acc: 98.44%] [G loss: 9.640132]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 194 10 [D loss: 0.019027, acc: 98.44%] [G loss: 7.287098]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 194 11 [D loss: 0.083893, acc: 96.88%] [G loss: 5.431969]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 194 12 [D loss: 0.021952, acc: 98.44%] [G loss: 6.436604]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 194 13 [D loss: 0.007184, acc: 100.00%] [G loss: 9.486056]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 194 14 [D loss: 0.000248, acc: 100.00%] [G loss: 11.274252]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 194 15 [D loss: 0.027667, acc: 98.44%] [G loss: 9.319967]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 194 16 [D loss: 0.018554, acc: 100.00%] [G loss: 8.982079]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 194 17 [D loss: 0.027123, acc: 98.44%] [G loss: 7.502863]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 194 18 [D loss: 0.035478, acc: 98.44%] [G loss: 8.393402]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 194 19 [D loss: 0.001114, acc: 100.00%] [G loss: 11.459019]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 194 20 [D loss: 0.000088, acc: 100.00%] [G loss: 13.197689]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 194 21 [D loss: 0.014867, acc: 98.44%] [G loss: 12.402602]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 194 22 [D loss: 0.035736, acc: 98.44%] [G loss: 9.754223]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 195 0 [D loss: 0.001511, acc: 100.00%] [G loss: 7.378896]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 195 1 [D loss: 0.119870, acc: 95.31%] [G loss: 9.510131]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 195 2 [D loss: 0.000347, acc: 100.00%] [G loss: 13.243589]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 195 3 [D loss: 0.000339, acc: 100.00%] [G loss: 14.865012]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 195 4 [D loss: 0.000345, acc: 100.00%] [G loss: 15.537946]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 195 5 [D loss: 0.032919, acc: 98.44%] [G loss: 14.785832]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 195 6 [D loss: 0.054262, acc: 96.88%] [G loss: 9.441622]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "******* 195 7 [D loss: 0.026021, acc: 98.44%] [G loss: 6.148180]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 195 8 [D loss: 0.062061, acc: 96.88%] [G loss: 8.113541]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 195 9 [D loss: 0.004904, acc: 100.00%] [G loss: 10.514556]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 195 10 [D loss: 0.029524, acc: 98.44%] [G loss: 12.059219]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 195 11 [D loss: 0.318078, acc: 98.44%] [G loss: 11.996850]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 195 12 [D loss: 0.248860, acc: 98.44%] [G loss: 8.262301]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 195 13 [D loss: 0.360935, acc: 95.31%] [G loss: 6.580742]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 195 14 [D loss: 0.459952, acc: 85.94%] [G loss: 12.354792]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 195 15 [D loss: 0.102191, acc: 95.31%] [G loss: 19.818417]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 195 16 [D loss: 0.620313, acc: 82.81%] [G loss: 15.159907]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 195 17 [D loss: 0.009919, acc: 100.00%] [G loss: 11.225074]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 195 18 [D loss: 0.055982, acc: 96.88%] [G loss: 7.355911]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 195 19 [D loss: 0.037446, acc: 98.44%] [G loss: 6.517608]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 195 20 [D loss: 0.021190, acc: 98.44%] [G loss: 9.947990]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 195 21 [D loss: 0.007000, acc: 100.00%] [G loss: 10.684568]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 195 22 [D loss: 0.000505, acc: 100.00%] [G loss: 12.482021]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 196 0 [D loss: 0.000952, acc: 100.00%] [G loss: 14.436110]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 196 1 [D loss: 0.001314, acc: 100.00%] [G loss: 12.663748]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 196 2 [D loss: 0.096793, acc: 95.31%] [G loss: 10.163618]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 196 3 [D loss: 0.167723, acc: 96.88%] [G loss: 8.987115]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 196 4 [D loss: 0.008550, acc: 100.00%] [G loss: 11.019436]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 196 5 [D loss: 0.002074, acc: 100.00%] [G loss: 11.546799]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 196 6 [D loss: 0.045907, acc: 98.44%] [G loss: 10.021027]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 196 7 [D loss: 0.006477, acc: 100.00%] [G loss: 9.713186]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 196 8 [D loss: 0.006974, acc: 100.00%] [G loss: 9.967920]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 196 9 [D loss: 0.032219, acc: 96.88%] [G loss: 8.520550]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 196 10 [D loss: 0.004806, acc: 100.00%] [G loss: 10.309023]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 196 11 [D loss: 0.040667, acc: 98.44%] [G loss: 10.093771]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 196 12 [D loss: 0.232118, acc: 90.62%] [G loss: 15.816162]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 196 13 [D loss: 0.101810, acc: 95.31%] [G loss: 22.080780]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 196 14 [D loss: 0.283409, acc: 95.31%] [G loss: 25.374794]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 196 15 [D loss: 0.024384, acc: 98.44%] [G loss: 22.708706]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 196 16 [D loss: 0.007112, acc: 100.00%] [G loss: 23.711674]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 196 17 [D loss: 0.000009, acc: 100.00%] [G loss: 22.368256]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 196 18 [D loss: 0.004699, acc: 100.00%] [G loss: 22.785177]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 196 19 [D loss: 0.100993, acc: 96.88%] [G loss: 17.482912]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 196 20 [D loss: 0.131055, acc: 98.44%] [G loss: 19.570539]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 196 21 [D loss: 0.000001, acc: 100.00%] [G loss: 25.774364]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 196 22 [D loss: 0.000003, acc: 100.00%] [G loss: 21.965853]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 197 0 [D loss: 0.000031, acc: 100.00%] [G loss: 22.113672]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 197 1 [D loss: 0.170225, acc: 98.44%] [G loss: 19.919245]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 197 2 [D loss: 0.000387, acc: 100.00%] [G loss: 15.890738]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 197 3 [D loss: 0.004309, acc: 100.00%] [G loss: 12.288633]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 197 4 [D loss: 0.007604, acc: 100.00%] [G loss: 8.952102]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 197 5 [D loss: 0.626605, acc: 79.69%] [G loss: 22.689007]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 197 6 [D loss: 0.001259, acc: 100.00%] [G loss: 41.833694]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 197 7 [D loss: 4.592539, acc: 70.31%] [G loss: 12.626270]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 197 8 [D loss: 2.452224, acc: 68.75%] [G loss: 15.542576]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 197 9 [D loss: 0.089253, acc: 96.88%] [G loss: 21.754005]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 197 10 [D loss: 0.099288, acc: 95.31%] [G loss: 21.407413]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 197 11 [D loss: 0.113488, acc: 98.44%] [G loss: 18.248575]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 197 12 [D loss: 0.242674, acc: 93.75%] [G loss: 23.144188]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 197 13 [D loss: 0.000470, acc: 100.00%] [G loss: 33.475975]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 197 14 [D loss: 0.488003, acc: 90.62%] [G loss: 27.669479]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 197 15 [D loss: 0.056761, acc: 98.44%] [G loss: 16.599148]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 197 16 [D loss: 0.289393, acc: 90.62%] [G loss: 19.360195]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 197 17 [D loss: 0.076482, acc: 98.44%] [G loss: 21.023985]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 197 18 [D loss: 0.035202, acc: 98.44%] [G loss: 21.291246]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 197 19 [D loss: 0.030047, acc: 98.44%] [G loss: 14.878098]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 197 20 [D loss: 0.103061, acc: 96.88%] [G loss: 12.327841]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 197 21 [D loss: 0.116361, acc: 95.31%] [G loss: 10.915548]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 197 22 [D loss: 0.003574, acc: 100.00%] [G loss: 16.474251]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 198 0 [D loss: 0.481613, acc: 96.88%] [G loss: 14.434846]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 198 1 [D loss: 0.213655, acc: 92.19%] [G loss: 10.373432]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 198 2 [D loss: 0.243113, acc: 93.75%] [G loss: 13.117613]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 198 3 [D loss: 0.221806, acc: 93.75%] [G loss: 10.282383]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 198 4 [D loss: 0.007590, acc: 100.00%] [G loss: 8.982846]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 198 5 [D loss: 0.034057, acc: 98.44%] [G loss: 9.389521]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 198 6 [D loss: 0.022497, acc: 98.44%] [G loss: 11.531211]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 198 7 [D loss: 0.032892, acc: 100.00%] [G loss: 11.690858]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 198 8 [D loss: 0.176795, acc: 96.88%] [G loss: 12.175713]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "******* 198 9 [D loss: 0.020144, acc: 98.44%] [G loss: 9.092241]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 198 10 [D loss: 0.006769, acc: 100.00%] [G loss: 8.499958]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 198 11 [D loss: 0.050857, acc: 96.88%] [G loss: 9.505817]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 198 12 [D loss: 0.124641, acc: 98.44%] [G loss: 12.894487]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 198 13 [D loss: 0.000083, acc: 100.00%] [G loss: 13.671375]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 198 14 [D loss: 0.001597, acc: 100.00%] [G loss: 16.514847]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 198 15 [D loss: 0.000586, acc: 100.00%] [G loss: 17.686888]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 198 16 [D loss: 0.331713, acc: 95.31%] [G loss: 13.504833]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 198 17 [D loss: 0.001939, acc: 100.00%] [G loss: 12.766521]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 198 18 [D loss: 0.017194, acc: 98.44%] [G loss: 10.231079]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 198 19 [D loss: 0.106615, acc: 98.44%] [G loss: 9.665922]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 198 20 [D loss: 0.005792, acc: 100.00%] [G loss: 10.930721]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 198 21 [D loss: 0.009716, acc: 100.00%] [G loss: 10.083095]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 198 22 [D loss: 0.003291, acc: 100.00%] [G loss: 10.287523]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 199 0 [D loss: 0.004603, acc: 100.00%] [G loss: 10.914455]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 199 1 [D loss: 0.000108, acc: 100.00%] [G loss: 9.874804]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 199 2 [D loss: 0.048621, acc: 96.88%] [G loss: 10.212080]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 199 3 [D loss: 0.007746, acc: 100.00%] [G loss: 8.223442]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 199 4 [D loss: 0.205285, acc: 96.88%] [G loss: 9.784185]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 199 5 [D loss: 0.035390, acc: 98.44%] [G loss: 13.969883]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 199 6 [D loss: 0.110624, acc: 96.88%] [G loss: 15.584786]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 199 7 [D loss: 0.045023, acc: 98.44%] [G loss: 13.423306]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 199 8 [D loss: 0.415236, acc: 93.75%] [G loss: 9.063534]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 199 9 [D loss: 0.145387, acc: 95.31%] [G loss: 6.592865]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 199 10 [D loss: 0.001214, acc: 100.00%] [G loss: 11.128252]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 199 11 [D loss: 0.032279, acc: 98.44%] [G loss: 13.700377]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 199 12 [D loss: 0.091132, acc: 95.31%] [G loss: 12.536579]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "******* 199 13 [D loss: 0.013430, acc: 98.44%] [G loss: 13.783509]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 199 14 [D loss: 0.199008, acc: 96.88%] [G loss: 12.997199]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 199 15 [D loss: 0.003967, acc: 100.00%] [G loss: 9.598103]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 199 16 [D loss: 0.040944, acc: 98.44%] [G loss: 8.595490]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 199 17 [D loss: 0.102497, acc: 95.31%] [G loss: 9.945463]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 199 18 [D loss: 0.024065, acc: 98.44%] [G loss: 11.692380]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 199 19 [D loss: 0.014883, acc: 98.44%] [G loss: 13.678276]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 199 20 [D loss: 0.122913, acc: 95.31%] [G loss: 12.585865]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 199 21 [D loss: 0.076265, acc: 98.44%] [G loss: 10.794938]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 199 22 [D loss: 0.043784, acc: 98.44%] [G loss: 13.457328]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 200 0 [D loss: 0.132290, acc: 93.75%] [G loss: 10.145456]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 200 1 [D loss: 0.278214, acc: 90.62%] [G loss: 20.855598]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 200 2 [D loss: 0.074000, acc: 96.88%] [G loss: 39.820099]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 200 3 [D loss: 0.756163, acc: 87.50%] [G loss: 35.891640]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 200 4 [D loss: 0.345438, acc: 92.19%] [G loss: 20.967421]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 200 5 [D loss: 0.411490, acc: 87.50%] [G loss: 20.229721]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 200 6 [D loss: 0.000005, acc: 100.00%] [G loss: 30.034473]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 200 7 [D loss: 0.000001, acc: 100.00%] [G loss: 35.720215]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 200 8 [D loss: 0.004156, acc: 100.00%] [G loss: 34.364071]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 200 9 [D loss: 0.012160, acc: 100.00%] [G loss: 32.872963]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 200 10 [D loss: 0.010155, acc: 100.00%] [G loss: 25.684544]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 200 11 [D loss: 0.103284, acc: 98.44%] [G loss: 22.904203]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 200 12 [D loss: 0.000766, acc: 100.00%] [G loss: 11.873455]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 200 13 [D loss: 0.454806, acc: 90.62%] [G loss: 25.195969]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 200 14 [D loss: 0.015840, acc: 100.00%] [G loss: 36.119102]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 200 15 [D loss: 0.809194, acc: 87.50%] [G loss: 26.953892]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 200 16 [D loss: 0.047295, acc: 98.44%] [G loss: 21.063385]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 200 17 [D loss: 0.014292, acc: 100.00%] [G loss: 12.327283]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 200 18 [D loss: 0.354540, acc: 90.62%] [G loss: 8.599366]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 200 19 [D loss: 0.117410, acc: 95.31%] [G loss: 14.041775]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 200 20 [D loss: 0.000531, acc: 100.00%] [G loss: 15.447877]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 200 21 [D loss: 0.232641, acc: 98.44%] [G loss: 16.248566]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 200 22 [D loss: 0.222624, acc: 95.31%] [G loss: 15.743368]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 201 0 [D loss: 0.047122, acc: 98.44%] [G loss: 10.733835]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "******* 201 1 [D loss: 0.019929, acc: 100.00%] [G loss: 8.687872]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 201 2 [D loss: 0.123236, acc: 96.88%] [G loss: 9.115705]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 201 3 [D loss: 0.047769, acc: 98.44%] [G loss: 10.175882]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 201 4 [D loss: 0.010084, acc: 100.00%] [G loss: 11.693542]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 201 5 [D loss: 0.018821, acc: 100.00%] [G loss: 13.228444]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 201 6 [D loss: 0.188230, acc: 96.88%] [G loss: 11.342242]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 201 7 [D loss: 0.135427, acc: 95.31%] [G loss: 9.961856]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 201 8 [D loss: 0.063175, acc: 98.44%] [G loss: 6.783347]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 201 9 [D loss: 0.303472, acc: 90.62%] [G loss: 7.585591]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 201 10 [D loss: 0.205317, acc: 92.19%] [G loss: 9.414331]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 201 11 [D loss: 0.007755, acc: 100.00%] [G loss: 10.544703]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 201 12 [D loss: 0.182223, acc: 98.44%] [G loss: 12.219924]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 201 13 [D loss: 0.039091, acc: 98.44%] [G loss: 9.489291]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 201 14 [D loss: 0.256304, acc: 93.75%] [G loss: 6.116604]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 201 15 [D loss: 0.370386, acc: 82.81%] [G loss: 8.321445]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 201 16 [D loss: 0.046942, acc: 98.44%] [G loss: 12.265515]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 201 17 [D loss: 0.197117, acc: 95.31%] [G loss: 12.118226]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 201 18 [D loss: 0.015527, acc: 100.00%] [G loss: 10.962847]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 201 19 [D loss: 0.242343, acc: 93.75%] [G loss: 5.806745]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 201 20 [D loss: 0.185090, acc: 89.06%] [G loss: 6.587317]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 201 21 [D loss: 0.034240, acc: 98.44%] [G loss: 8.858120]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 201 22 [D loss: 0.195525, acc: 93.75%] [G loss: 11.661858]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 202 0 [D loss: 0.182896, acc: 96.88%] [G loss: 12.976672]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 202 1 [D loss: 0.024380, acc: 98.44%] [G loss: 13.564430]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 202 2 [D loss: 0.066641, acc: 96.88%] [G loss: 9.659058]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 202 3 [D loss: 0.057379, acc: 96.88%] [G loss: 12.446982]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 202 4 [D loss: 0.017787, acc: 98.44%] [G loss: 18.888189]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 202 5 [D loss: 0.017095, acc: 98.44%] [G loss: 22.238747]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 202 6 [D loss: 0.005651, acc: 100.00%] [G loss: 27.403217]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 202 7 [D loss: 0.000094, acc: 100.00%] [G loss: 25.705891]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 202 8 [D loss: 0.000039, acc: 100.00%] [G loss: 25.005360]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 202 9 [D loss: 0.000020, acc: 100.00%] [G loss: 18.987123]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 202 10 [D loss: 0.045228, acc: 98.44%] [G loss: 15.056607]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 202 11 [D loss: 0.288959, acc: 93.75%] [G loss: 14.234204]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 202 12 [D loss: 0.017853, acc: 98.44%] [G loss: 19.517780]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 202 13 [D loss: 0.002163, acc: 100.00%] [G loss: 20.334515]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 202 14 [D loss: 0.020246, acc: 98.44%] [G loss: 16.658443]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 202 15 [D loss: 0.318665, acc: 92.19%] [G loss: 11.443608]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 202 16 [D loss: 0.303901, acc: 90.62%] [G loss: 7.180434]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 202 17 [D loss: 0.572234, acc: 87.50%] [G loss: 12.125191]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 202 18 [D loss: 0.088202, acc: 96.88%] [G loss: 18.477806]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 202 19 [D loss: 0.565283, acc: 89.06%] [G loss: 17.261728]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 202 20 [D loss: 0.139582, acc: 98.44%] [G loss: 13.457922]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 202 21 [D loss: 0.016682, acc: 100.00%] [G loss: 10.522596]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 202 22 [D loss: 0.144206, acc: 96.88%] [G loss: 14.177153]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 203 0 [D loss: 0.029171, acc: 98.44%] [G loss: 13.777383]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 203 1 [D loss: 0.000018, acc: 100.00%] [G loss: 17.242432]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 203 2 [D loss: 0.021589, acc: 98.44%] [G loss: 18.843067]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 203 3 [D loss: 0.146280, acc: 95.31%] [G loss: 18.969709]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 203 4 [D loss: 0.014613, acc: 98.44%] [G loss: 14.998363]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 203 5 [D loss: 0.110785, acc: 96.88%] [G loss: 9.616650]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 203 6 [D loss: 0.164252, acc: 98.44%] [G loss: 7.586709]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 203 7 [D loss: 0.403300, acc: 90.62%] [G loss: 11.676709]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 203 8 [D loss: 0.006561, acc: 100.00%] [G loss: 19.567486]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 203 9 [D loss: 0.000587, acc: 100.00%] [G loss: 24.152212]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 203 10 [D loss: 0.490612, acc: 95.31%] [G loss: 23.246939]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 203 11 [D loss: 0.136107, acc: 96.88%] [G loss: 19.356121]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 203 12 [D loss: 0.248534, acc: 98.44%] [G loss: 13.032847]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 203 13 [D loss: 0.038278, acc: 98.44%] [G loss: 8.930958]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 203 14 [D loss: 0.252525, acc: 92.19%] [G loss: 13.707968]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 203 15 [D loss: 0.000009, acc: 100.00%] [G loss: 19.201658]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 203 16 [D loss: 0.255324, acc: 95.31%] [G loss: 22.594604]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 203 17 [D loss: 0.030054, acc: 98.44%] [G loss: 20.533161]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 203 18 [D loss: 0.047846, acc: 98.44%] [G loss: 16.122368]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 203 19 [D loss: 0.055273, acc: 96.88%] [G loss: 10.589558]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 203 20 [D loss: 0.199519, acc: 93.75%] [G loss: 6.862611]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 203 21 [D loss: 0.313287, acc: 90.62%] [G loss: 10.109512]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 203 22 [D loss: 0.021952, acc: 98.44%] [G loss: 18.764252]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 204 0 [D loss: 0.009303, acc: 100.00%] [G loss: 23.245253]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 204 1 [D loss: 0.466247, acc: 89.06%] [G loss: 20.191004]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 204 2 [D loss: 0.269680, acc: 92.19%] [G loss: 12.229412]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "******* 204 3 [D loss: 0.141834, acc: 96.88%] [G loss: 7.332342]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 204 4 [D loss: 0.160954, acc: 95.31%] [G loss: 8.862955]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 204 5 [D loss: 0.001852, acc: 100.00%] [G loss: 12.531083]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 204 6 [D loss: 0.002071, acc: 100.00%] [G loss: 14.698174]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 204 7 [D loss: 0.000377, acc: 100.00%] [G loss: 12.583463]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 204 8 [D loss: 0.001244, acc: 100.00%] [G loss: 11.752347]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 204 9 [D loss: 0.007803, acc: 100.00%] [G loss: 12.681726]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 204 10 [D loss: 0.003285, acc: 100.00%] [G loss: 11.864635]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 204 11 [D loss: 0.106311, acc: 96.88%] [G loss: 12.634651]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 204 12 [D loss: 0.005808, acc: 100.00%] [G loss: 12.927454]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 204 13 [D loss: 0.058228, acc: 96.88%] [G loss: 12.381530]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 204 14 [D loss: 0.007272, acc: 100.00%] [G loss: 14.543009]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 204 15 [D loss: 0.323742, acc: 89.06%] [G loss: 10.772286]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 204 16 [D loss: 0.107125, acc: 96.88%] [G loss: 9.846012]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 204 17 [D loss: 0.164299, acc: 96.88%] [G loss: 7.006930]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 204 18 [D loss: 0.077773, acc: 95.31%] [G loss: 8.200281]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 204 19 [D loss: 0.143743, acc: 96.88%] [G loss: 10.938084]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 204 20 [D loss: 0.058500, acc: 96.88%] [G loss: 11.225601]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 204 21 [D loss: 0.078076, acc: 96.88%] [G loss: 9.663491]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 204 22 [D loss: 0.091476, acc: 98.44%] [G loss: 10.665453]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 205 0 [D loss: 0.018467, acc: 100.00%] [G loss: 11.952513]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 205 1 [D loss: 0.021391, acc: 98.44%] [G loss: 11.163952]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 205 2 [D loss: 0.218379, acc: 93.75%] [G loss: 11.404323]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 205 3 [D loss: 0.023766, acc: 98.44%] [G loss: 12.197515]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 205 4 [D loss: 0.042830, acc: 98.44%] [G loss: 13.186637]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 205 5 [D loss: 0.058560, acc: 98.44%] [G loss: 13.376774]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 205 6 [D loss: 0.038409, acc: 96.88%] [G loss: 9.842059]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 205 7 [D loss: 0.050815, acc: 98.44%] [G loss: 12.239733]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 205 8 [D loss: 0.020470, acc: 98.44%] [G loss: 11.498758]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 205 9 [D loss: 0.017339, acc: 98.44%] [G loss: 10.077843]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 205 10 [D loss: 0.053094, acc: 98.44%] [G loss: 9.949497]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 205 11 [D loss: 0.006235, acc: 100.00%] [G loss: 8.809587]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 205 12 [D loss: 0.173255, acc: 93.75%] [G loss: 8.781776]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 205 13 [D loss: 0.065123, acc: 96.88%] [G loss: 9.791007]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 205 14 [D loss: 0.066523, acc: 96.88%] [G loss: 10.775734]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 205 15 [D loss: 0.115851, acc: 95.31%] [G loss: 8.434566]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 205 16 [D loss: 0.104988, acc: 96.88%] [G loss: 6.500522]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 205 17 [D loss: 0.323819, acc: 89.06%] [G loss: 9.080297]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 205 18 [D loss: 0.000993, acc: 100.00%] [G loss: 16.242580]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 205 19 [D loss: 0.110599, acc: 96.88%] [G loss: 17.278770]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 205 20 [D loss: 0.122975, acc: 96.88%] [G loss: 19.274227]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 205 21 [D loss: 0.131678, acc: 95.31%] [G loss: 14.674166]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 205 22 [D loss: 0.002416, acc: 100.00%] [G loss: 11.278568]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 206 0 [D loss: 0.021644, acc: 100.00%] [G loss: 9.295899]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 206 1 [D loss: 0.027127, acc: 100.00%] [G loss: 8.112411]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 206 2 [D loss: 0.221024, acc: 98.44%] [G loss: 8.863642]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 206 3 [D loss: 0.014458, acc: 98.44%] [G loss: 10.853076]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 206 4 [D loss: 0.006444, acc: 100.00%] [G loss: 13.130124]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 206 5 [D loss: 0.021181, acc: 98.44%] [G loss: 13.548901]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 206 6 [D loss: 0.138353, acc: 95.31%] [G loss: 11.579113]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 206 7 [D loss: 0.005317, acc: 100.00%] [G loss: 9.420074]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 206 8 [D loss: 0.005457, acc: 100.00%] [G loss: 6.949953]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 206 9 [D loss: 0.131338, acc: 93.75%] [G loss: 7.551731]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "******* 206 10 [D loss: 0.007190, acc: 100.00%] [G loss: 8.576340]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 206 11 [D loss: 0.075709, acc: 96.88%] [G loss: 8.996957]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 206 12 [D loss: 0.000759, acc: 100.00%] [G loss: 10.789660]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 206 13 [D loss: 0.009965, acc: 100.00%] [G loss: 9.973825]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 206 14 [D loss: 0.119667, acc: 96.88%] [G loss: 9.771635]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 206 15 [D loss: 0.062928, acc: 98.44%] [G loss: 9.876620]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 206 16 [D loss: 0.025672, acc: 98.44%] [G loss: 11.291648]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 206 17 [D loss: 0.006164, acc: 100.00%] [G loss: 13.110504]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 206 18 [D loss: 0.046198, acc: 98.44%] [G loss: 11.154692]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 206 19 [D loss: 0.019850, acc: 98.44%] [G loss: 9.680316]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "******* 206 20 [D loss: 0.028889, acc: 100.00%] [G loss: 8.703785]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 206 21 [D loss: 0.046921, acc: 98.44%] [G loss: 8.499167]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 206 22 [D loss: 0.009115, acc: 100.00%] [G loss: 9.050270]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 207 0 [D loss: 0.091600, acc: 96.88%] [G loss: 8.845403]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 207 1 [D loss: 0.034293, acc: 96.88%] [G loss: 8.828037]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 207 2 [D loss: 0.194338, acc: 96.88%] [G loss: 7.954971]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 207 3 [D loss: 0.003869, acc: 100.00%] [G loss: 8.324409]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 207 4 [D loss: 0.293057, acc: 89.06%] [G loss: 8.470879]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 207 5 [D loss: 0.008498, acc: 100.00%] [G loss: 11.638576]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 207 6 [D loss: 0.018418, acc: 98.44%] [G loss: 13.445326]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 207 7 [D loss: 0.038008, acc: 98.44%] [G loss: 12.715144]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 207 8 [D loss: 0.180812, acc: 95.31%] [G loss: 10.002136]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 207 9 [D loss: 0.019263, acc: 100.00%] [G loss: 6.920281]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 207 10 [D loss: 0.055375, acc: 96.88%] [G loss: 5.851562]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 207 11 [D loss: 0.106901, acc: 98.44%] [G loss: 6.565369]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 207 12 [D loss: 0.032788, acc: 98.44%] [G loss: 8.912585]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 207 13 [D loss: 0.000799, acc: 100.00%] [G loss: 12.719391]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 207 14 [D loss: 0.042140, acc: 98.44%] [G loss: 14.410803]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 207 15 [D loss: 0.060697, acc: 98.44%] [G loss: 14.124399]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 207 16 [D loss: 0.002771, acc: 100.00%] [G loss: 13.106686]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 207 17 [D loss: 0.020553, acc: 98.44%] [G loss: 13.500496]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 207 18 [D loss: 0.000477, acc: 100.00%] [G loss: 12.046646]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 207 19 [D loss: 0.005651, acc: 100.00%] [G loss: 11.878416]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 207 20 [D loss: 0.016432, acc: 98.44%] [G loss: 12.716876]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 207 21 [D loss: 0.000927, acc: 100.00%] [G loss: 16.291580]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 207 22 [D loss: 0.005347, acc: 100.00%] [G loss: 17.561440]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 208 0 [D loss: 0.006772, acc: 100.00%] [G loss: 21.237091]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 208 1 [D loss: 0.000520, acc: 100.00%] [G loss: 22.995739]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 208 2 [D loss: 0.000288, acc: 100.00%] [G loss: 21.115810]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 208 3 [D loss: 0.000072, acc: 100.00%] [G loss: 19.043125]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 208 4 [D loss: 0.000079, acc: 100.00%] [G loss: 14.138891]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 208 5 [D loss: 0.081018, acc: 96.88%] [G loss: 11.812428]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 208 6 [D loss: 0.009687, acc: 100.00%] [G loss: 9.722664]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 208 7 [D loss: 0.056561, acc: 98.44%] [G loss: 10.159719]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 208 8 [D loss: 0.024186, acc: 100.00%] [G loss: 10.737902]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 208 9 [D loss: 0.061828, acc: 96.88%] [G loss: 8.666595]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 208 10 [D loss: 0.113198, acc: 96.88%] [G loss: 6.133304]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 208 11 [D loss: 0.117265, acc: 96.88%] [G loss: 5.118247]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 208 12 [D loss: 0.028235, acc: 100.00%] [G loss: 6.616601]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 208 13 [D loss: 0.059935, acc: 96.88%] [G loss: 8.245966]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 208 14 [D loss: 0.054723, acc: 98.44%] [G loss: 9.095996]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 208 15 [D loss: 0.034800, acc: 98.44%] [G loss: 8.177421]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 208 16 [D loss: 0.105152, acc: 93.75%] [G loss: 7.678103]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 208 17 [D loss: 0.037630, acc: 100.00%] [G loss: 6.414088]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 208 18 [D loss: 0.018770, acc: 100.00%] [G loss: 6.500535]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 208 19 [D loss: 0.030479, acc: 98.44%] [G loss: 6.781360]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 208 20 [D loss: 0.391262, acc: 95.31%] [G loss: 4.899929]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 208 21 [D loss: 0.050620, acc: 100.00%] [G loss: 4.284686]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 208 22 [D loss: 0.015674, acc: 100.00%] [G loss: 5.835058]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 209 0 [D loss: 0.002460, acc: 100.00%] [G loss: 7.051553]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 209 1 [D loss: 0.017642, acc: 100.00%] [G loss: 8.004244]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 209 2 [D loss: 0.016272, acc: 100.00%] [G loss: 7.610416]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 209 3 [D loss: 0.010152, acc: 100.00%] [G loss: 7.320296]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 209 4 [D loss: 0.001882, acc: 100.00%] [G loss: 6.911373]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 209 5 [D loss: 0.001421, acc: 100.00%] [G loss: 6.907803]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 209 6 [D loss: 0.003232, acc: 100.00%] [G loss: 6.713206]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 209 7 [D loss: 0.018201, acc: 100.00%] [G loss: 6.650863]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 209 8 [D loss: 0.006680, acc: 100.00%] [G loss: 7.278232]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 209 9 [D loss: 0.002600, acc: 100.00%] [G loss: 7.799137]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 209 10 [D loss: 0.008202, acc: 100.00%] [G loss: 8.729137]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 209 11 [D loss: 0.004566, acc: 100.00%] [G loss: 8.801595]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "******* 209 12 [D loss: 0.014198, acc: 100.00%] [G loss: 8.793927]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 209 13 [D loss: 0.010492, acc: 100.00%] [G loss: 7.738129]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 209 14 [D loss: 0.005895, acc: 100.00%] [G loss: 7.200019]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 209 15 [D loss: 0.018388, acc: 100.00%] [G loss: 7.238075]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 209 16 [D loss: 0.010368, acc: 100.00%] [G loss: 7.079237]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 209 17 [D loss: 0.004556, acc: 100.00%] [G loss: 7.926370]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 209 18 [D loss: 0.051946, acc: 98.44%] [G loss: 7.342632]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 209 19 [D loss: 0.025648, acc: 98.44%] [G loss: 6.760561]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 209 20 [D loss: 0.041478, acc: 98.44%] [G loss: 7.282551]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 209 21 [D loss: 0.011189, acc: 100.00%] [G loss: 8.437328]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 209 22 [D loss: 0.052225, acc: 98.44%] [G loss: 7.163777]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 210 0 [D loss: 0.013196, acc: 100.00%] [G loss: 7.597279]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 210 1 [D loss: 0.002997, acc: 100.00%] [G loss: 8.752048]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 210 2 [D loss: 0.002885, acc: 100.00%] [G loss: 8.145898]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 210 3 [D loss: 0.001071, acc: 100.00%] [G loss: 8.989315]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 210 4 [D loss: 0.001723, acc: 100.00%] [G loss: 8.429337]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 210 5 [D loss: 0.002344, acc: 100.00%] [G loss: 8.601698]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 210 6 [D loss: 0.012548, acc: 100.00%] [G loss: 7.090576]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 210 7 [D loss: 0.062584, acc: 98.44%] [G loss: 5.698218]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 210 8 [D loss: 0.029159, acc: 98.44%] [G loss: 7.140145]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 210 9 [D loss: 0.015635, acc: 100.00%] [G loss: 8.154335]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 210 10 [D loss: 0.025352, acc: 100.00%] [G loss: 8.801081]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 210 11 [D loss: 0.005937, acc: 100.00%] [G loss: 9.569593]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 210 12 [D loss: 0.019382, acc: 100.00%] [G loss: 7.885621]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 210 13 [D loss: 0.020140, acc: 100.00%] [G loss: 6.729527]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 210 14 [D loss: 0.015257, acc: 100.00%] [G loss: 5.186791]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 210 15 [D loss: 0.046517, acc: 96.88%] [G loss: 7.872620]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 210 16 [D loss: 0.100945, acc: 95.31%] [G loss: 7.715352]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 210 17 [D loss: 0.047641, acc: 96.88%] [G loss: 8.073267]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 210 18 [D loss: 0.011423, acc: 100.00%] [G loss: 8.721220]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 210 19 [D loss: 0.062209, acc: 98.44%] [G loss: 6.559986]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 210 20 [D loss: 0.047654, acc: 100.00%] [G loss: 5.957687]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 210 21 [D loss: 0.110354, acc: 95.31%] [G loss: 8.521425]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 210 22 [D loss: 0.074494, acc: 98.44%] [G loss: 9.027502]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 211 0 [D loss: 0.038074, acc: 98.44%] [G loss: 8.493448]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 211 1 [D loss: 0.033063, acc: 98.44%] [G loss: 5.624946]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 211 2 [D loss: 0.260192, acc: 93.75%] [G loss: 8.743883]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 211 3 [D loss: 0.026133, acc: 98.44%] [G loss: 16.018511]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 211 4 [D loss: 0.693010, acc: 84.38%] [G loss: 9.228947]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 211 5 [D loss: 0.129363, acc: 90.62%] [G loss: 7.265552]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 211 6 [D loss: 0.052840, acc: 96.88%] [G loss: 10.569867]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 211 7 [D loss: 0.000292, acc: 100.00%] [G loss: 12.202057]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 211 8 [D loss: 0.001174, acc: 100.00%] [G loss: 13.928488]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 211 9 [D loss: 0.000419, acc: 100.00%] [G loss: 17.291594]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 211 10 [D loss: 0.004242, acc: 100.00%] [G loss: 17.987570]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 211 11 [D loss: 0.012409, acc: 100.00%] [G loss: 16.144600]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 211 12 [D loss: 0.067915, acc: 96.88%] [G loss: 15.988156]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 211 13 [D loss: 0.006891, acc: 100.00%] [G loss: 11.692998]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 211 14 [D loss: 0.003237, acc: 100.00%] [G loss: 10.365007]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 211 15 [D loss: 0.003250, acc: 100.00%] [G loss: 9.046898]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "******* 211 16 [D loss: 0.012332, acc: 100.00%] [G loss: 7.700769]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 211 17 [D loss: 0.010796, acc: 100.00%] [G loss: 6.680889]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 211 18 [D loss: 0.033827, acc: 98.44%] [G loss: 6.053342]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 211 19 [D loss: 0.014203, acc: 100.00%] [G loss: 6.511367]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 211 20 [D loss: 0.001290, acc: 100.00%] [G loss: 7.666933]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 211 21 [D loss: 0.002431, acc: 100.00%] [G loss: 7.852206]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 211 22 [D loss: 0.006417, acc: 100.00%] [G loss: 7.462590]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 212 0 [D loss: 0.001954, acc: 100.00%] [G loss: 7.838643]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "******* 212 1 [D loss: 0.001525, acc: 100.00%] [G loss: 7.586817]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "******* 212 2 [D loss: 0.001651, acc: 100.00%] [G loss: 7.362220]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT7_Wk-TS_n2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f7de316-beff-434a-a408-491d4809ee2b"
      },
      "source": [
        "noise = np.random.normal(0, 1, (16, latent_dim))\n",
        "gen_imgs = generator.predict(noise)\n",
        "gen_imgs = (gen_imgs + 1) / 2.0\n",
        "# plt.imshow(gen_imgs[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 489ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbWAZ1v_TdJd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "dd7f2848-b4da-4237-8232-292ae9489b50"
      },
      "source": [
        "plt.imshow(gen_imgs[6])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa7a5295b90>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8YtpQpkRvRI"
      },
      "source": [
        "generator.save_weights(\"/content/drive/MyDrive/ColabNotebooks/models/generator1hour.h5\")\n",
        "discriminator.save_weights(\"/content/drive/MyDrive/ColabNotebooks/models/discriminator1hour.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po-jSQoN1Azl"
      },
      "source": [
        "### **8) Making GIF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPShgQpg1EMy"
      },
      "source": [
        "# Display a single image using the epoch number\n",
        "# def display_image(epoch_no):\n",
        "#   return PIL.Image.open('generated_images/%.8f.png'.format(epoch_no))\n",
        "\n",
        "anim_file = 'dcgan.gif'\n",
        "\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "  filenames = glob.glob('generated_images/*.png')\n",
        "  filenames = sorted(filenames)\n",
        "  for filename in filenames:\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "  image = imageio.imread(filename)\n",
        "  writer.append_data(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogrmQ73ZR_Wi"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}